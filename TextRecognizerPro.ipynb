{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextRecognizerPro.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXnm1ZVubsw3DECvXizJQa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amandahydar/text-recognizer/blob/main/TextRecognizerPro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqiBgYeFgpEA",
        "outputId": "8edd9249-5778-4590-d73a-de9d28465386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 20 15:45:45 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train an MLP on MNIST data"
      ],
      "metadata": {
        "id": "PN5u78ob1gbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FSDL Spring 2021 Setup\n",
        "!git clone https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2021-labs\n",
        "%cd fsdl-text-recognizer-2021-labs\n",
        "!pip3 install boltons wandb pytorch_lightning==1.1.4 pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 torchtext==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "%env PYTHONPATH=.:$PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I8sHDPlhmge",
        "outputId": "df6db003-ddf2-4491-9d84-600aedd8b4cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fsdl-text-recognizer-2021-labs'...\n",
            "remote: Enumerating objects: 798, done.\u001b[K\n",
            "remote: Counting objects: 100% (232/232), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 798 (delta 158), reused 144 (delta 140), pack-reused 566\u001b[K\n",
            "Receiving objects: 100% (798/798), 18.89 MiB | 24.73 MiB/s, done.\n",
            "Resolving deltas: 100% (394/394), done.\n",
            "/content/fsdl-text-recognizer-2021-labs\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting boltons\n",
            "  Downloading boltons-21.0.0-py2.py3-none-any.whl (193 kB)\n",
            "\u001b[K     |████████████████████████████████| 193 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.12.9-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 42.0 MB/s \n",
            "\u001b[?25hCollecting pytorch_lightning==1.1.4\n",
            "  Downloading pytorch_lightning-1.1.4-py3-none-any.whl (684 kB)\n",
            "\u001b[K     |████████████████████████████████| 684 kB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting install\n",
            "  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n",
            "Collecting torch==1.7.1+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8 MB)\n",
            "\u001b[K     |███████████████████████         | 834.1 MB 1.4 MB/s eta 0:03:48tcmalloc: large alloc 1147494400 bytes == 0x55cdc7558000 @  0x7f480920d615 0x55cd8dd454cc 0x55cd8de2547a 0x55cd8dd482ed 0x55cd8de39e1d 0x55cd8ddbbe99 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddbbd00 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddb8737 0x55cd8de3ac66 0x55cd8ddb7daf 0x55cd8de3ac66 0x55cd8ddb7daf 0x55cd8de3ac66 0x55cd8ddb7daf 0x55cd8dd4a039 0x55cd8dd8d409 0x55cd8dd48c52 0x55cd8ddbbc25 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddb8737 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddb7915 0x55cd8dd49afa 0x55cd8ddb7c0d 0x55cd8ddb69ee\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7 MB 1.4 MB/s eta 0:01:15tcmalloc: large alloc 1434370048 bytes == 0x55ce0bbae000 @  0x7f480920d615 0x55cd8dd454cc 0x55cd8de2547a 0x55cd8dd482ed 0x55cd8de39e1d 0x55cd8ddbbe99 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddbbd00 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddb8737 0x55cd8de3ac66 0x55cd8ddb7daf 0x55cd8de3ac66 0x55cd8ddb7daf 0x55cd8de3ac66 0x55cd8ddb7daf 0x55cd8dd4a039 0x55cd8dd8d409 0x55cd8dd48c52 0x55cd8ddbbc25 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddb8737 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddb7915 0x55cd8dd49afa 0x55cd8ddb7c0d 0x55cd8ddb69ee\n",
            "\u001b[K     |████████████████████████████████| 1156.7 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x55ce6139a000 @  0x7f480920d615 0x55cd8dd454cc 0x55cd8de2547a 0x55cd8dd482ed 0x55cd8de39e1d 0x55cd8ddbbe99 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddb7c0d 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddb7c0d 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddb7c0d 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddb7c0d 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddb7c0d 0x55cd8dd49afa 0x55cd8ddb7c0d 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddb8737 0x55cd8ddb69ee 0x55cd8dd49bda 0x55cd8ddb8737 0x55cd8ddb69ee 0x55cd8dd4a271\n",
            "\u001b[K     |████████████████████████████████| 1156.8 MB 14 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9 MB 38.5 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.7.2\n",
            "  Downloading torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 35.7 MB/s \n",
            "\u001b[?25hCollecting torchtext==0.8.1\n",
            "  Downloading torchtext-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 12.2 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=0.8.1\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (2.7.0)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (4.62.3)\n",
            "Collecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.10.0.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.37.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.3.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.42.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.1.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.1-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 45.4 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 48.7 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (2.0.8)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (21.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 44.4 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 32.5 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 52.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: future, subprocess32, pathtools\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=1a9918d056b532f08a6f6058eba5551a002315ae1d10bb91466a28b16bfab026\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=94993032e6663c863999a250804355d956d98b5c484eed7f171da04c1bfa32e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=90801776a46b09cdae8853a1594de36fed97a90bb97f9b4e6c7efc993b8f717a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built future subprocess32 pathtools\n",
            "Installing collected packages: multidict, frozenlist, yarl, smmap, asynctest, async-timeout, aiosignal, gitdb, fsspec, aiohttp, yaspin, torch, subprocess32, shortuuid, sentry-sdk, PyYAML, pathtools, GitPython, future, docker-pycreds, configparser, wandb, torchvision, torchtext, torchaudio, pytorch-lightning, install, boltons\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.10.0+cu111\n",
            "    Uninstalling torchaudio-0.10.0+cu111:\n",
            "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
            "Successfully installed GitPython-3.1.24 PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 boltons-21.0.0 configparser-5.2.0 docker-pycreds-0.4.0 frozenlist-1.2.0 fsspec-2021.11.1 future-0.18.2 gitdb-4.0.9 install-1.3.5 multidict-5.2.0 pathtools-0.1.2 pytorch-lightning-1.1.4 sentry-sdk-1.5.1 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 torch-1.7.1+cu110 torchaudio-0.7.2 torchtext-0.8.1 torchvision-0.8.2+cu110 wandb-0.12.9 yarl-1.7.2 yaspin-2.1.0\n",
            "env: PYTHONPATH=.:$PYTHONPATH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd lab1/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSHIQPLIi2Bq",
        "outputId": "daa79bba-4583-4352-9a37-94de3c8e29d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fsdl-text-recognizer-2021-labs/lab1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training/run_experiment.py --max_epochs=3 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBehQ9LBjIF_",
        "outputId": "4612092e-55fc-4608-e2ec-f529b36575fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: False\n",
            "TPU available: None, using: 0 TPU cores\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "9920512it [00:00, 39496688.80it/s]                 \n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "32768it [00:00, 884409.17it/s]\n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "1654784it [00:00, 18024757.38it/s]\n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "8192it [00:00, 213038.73it/s]\n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Processing...\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
            "Done!\n",
            "\n",
            "  | Name          | Type     | Params\n",
            "-------------------------------------------\n",
            "0 | model         | MLP      | 936 K \n",
            "1 | model.dropout | Dropout  | 0     \n",
            "2 | model.fc1     | Linear   | 803 K \n",
            "3 | model.fc2     | Linear   | 131 K \n",
            "4 | model.fc3     | Linear   | 1.3 K \n",
            "5 | train_acc     | Accuracy | 0     \n",
            "6 | val_acc       | Accuracy | 0     \n",
            "7 | test_acc      | Accuracy | 0     \n",
            "-------------------------------------------\n",
            "936 K     Trainable params\n",
            "0         Non-trainable params\n",
            "936 K     Total params\n",
            "Epoch 0:  91% 430/470 [00:24<00:02, 17.74it/s, loss=0.214, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  92% 432/470 [00:24<00:02, 17.80it/s, loss=0.214, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  93% 436/470 [00:24<00:01, 17.84it/s, loss=0.214, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Validating:  15% 6/40 [00:00<00:01, 23.80it/s]\u001b[A\n",
            "Epoch 0:  94% 440/470 [00:24<00:01, 17.88it/s, loss=0.214, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  94% 444/470 [00:24<00:01, 17.92it/s, loss=0.214, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  95% 448/470 [00:24<00:01, 17.97it/s, loss=0.214, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Validating:  45% 18/40 [00:00<00:00, 24.64it/s]\u001b[A\n",
            "Epoch 0:  96% 452/470 [00:25<00:00, 18.01it/s, loss=0.214, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  97% 456/470 [00:25<00:00, 18.05it/s, loss=0.214, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  98% 460/470 [00:25<00:00, 18.10it/s, loss=0.214, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Validating:  75% 30/40 [00:01<00:00, 24.87it/s]\u001b[A\n",
            "Epoch 0:  99% 464/470 [00:25<00:00, 18.14it/s, loss=0.214, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0: 100% 468/470 [00:25<00:00, 18.18it/s, loss=0.214, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0: 100% 470/470 [00:25<00:00, 18.17it/s, loss=0.214, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  91% 430/470 [00:25<00:02, 17.19it/s, loss=0.165, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  92% 432/470 [00:25<00:02, 17.24it/s, loss=0.165, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  93% 436/470 [00:25<00:01, 17.30it/s, loss=0.165, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Validating:  15% 6/40 [00:00<00:01, 24.45it/s]\u001b[A\n",
            "Epoch 1:  94% 440/470 [00:25<00:01, 17.34it/s, loss=0.165, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  94% 444/470 [00:25<00:01, 17.39it/s, loss=0.165, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  95% 448/470 [00:25<00:01, 17.44it/s, loss=0.165, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Validating:  45% 18/40 [00:00<00:00, 24.97it/s]\u001b[A\n",
            "Epoch 1:  96% 452/470 [00:25<00:01, 17.48it/s, loss=0.165, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  97% 456/470 [00:26<00:00, 17.51it/s, loss=0.165, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  98% 460/470 [00:26<00:00, 17.56it/s, loss=0.165, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Validating:  75% 30/40 [00:01<00:00, 23.67it/s]\u001b[A\n",
            "Epoch 1:  99% 464/470 [00:26<00:00, 17.60it/s, loss=0.165, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1: 100% 468/470 [00:26<00:00, 17.64it/s, loss=0.165, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1: 100% 470/470 [00:26<00:00, 17.63it/s, loss=0.165, v_num=0, val_loss=0.13, val_acc=0.963] \n",
            "Epoch 2:  91% 430/470 [00:25<00:02, 16.98it/s, loss=0.133, v_num=0, val_loss=0.13, val_acc=0.963]\n",
            "Epoch 2:  92% 432/470 [00:25<00:02, 17.03it/s, loss=0.133, v_num=0, val_loss=0.13, val_acc=0.963]\n",
            "Epoch 2:  93% 436/470 [00:25<00:01, 17.06it/s, loss=0.133, v_num=0, val_loss=0.13, val_acc=0.963]\n",
            "Validating:  15% 6/40 [00:00<00:01, 21.75it/s]\u001b[A\n",
            "Epoch 2:  94% 440/470 [00:25<00:01, 17.10it/s, loss=0.133, v_num=0, val_loss=0.13, val_acc=0.963]\n",
            "Epoch 2:  94% 444/470 [00:25<00:01, 17.14it/s, loss=0.133, v_num=0, val_loss=0.13, val_acc=0.963]\n",
            "Epoch 2:  95% 448/470 [00:26<00:01, 17.19it/s, loss=0.133, v_num=0, val_loss=0.13, val_acc=0.963]\n",
            "Validating:  45% 18/40 [00:00<00:00, 23.83it/s]\u001b[A\n",
            "Epoch 2:  96% 452/470 [00:26<00:01, 17.23it/s, loss=0.133, v_num=0, val_loss=0.13, val_acc=0.963]\n",
            "Epoch 2:  97% 456/470 [00:26<00:00, 17.28it/s, loss=0.133, v_num=0, val_loss=0.13, val_acc=0.963]\n",
            "Epoch 2:  98% 460/470 [00:26<00:00, 17.33it/s, loss=0.133, v_num=0, val_loss=0.13, val_acc=0.963]\n",
            "Validating:  75% 30/40 [00:01<00:00, 24.49it/s]\u001b[A\n",
            "Epoch 2:  99% 464/470 [00:26<00:00, 17.37it/s, loss=0.133, v_num=0, val_loss=0.13, val_acc=0.963]\n",
            "Epoch 2: 100% 468/470 [00:26<00:00, 17.41it/s, loss=0.133, v_num=0, val_loss=0.13, val_acc=0.963]\n",
            "Epoch 2: 100% 470/470 [00:27<00:00, 17.40it/s, loss=0.133, v_num=0, val_loss=0.105, val_acc=0.969]\n",
            "Epoch 2: 100% 470/470 [00:27<00:00, 17.38it/s, loss=0.133, v_num=0, val_loss=0.105, val_acc=0.969]\n",
            "Testing: 100% 79/79 [00:03<00:00, 24.74it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.9709)}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training/run_experiment.py --max_epochs=3 --gpus=-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WUl9svhjo7Q",
        "outputId": "21495e9d-19ef-4d2a-fa67-44b0ca0406c1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name          | Type     | Params\n",
            "-------------------------------------------\n",
            "0 | model         | MLP      | 936 K \n",
            "1 | model.dropout | Dropout  | 0     \n",
            "2 | model.fc1     | Linear   | 803 K \n",
            "3 | model.fc2     | Linear   | 131 K \n",
            "4 | model.fc3     | Linear   | 1.3 K \n",
            "5 | train_acc     | Accuracy | 0     \n",
            "6 | val_acc       | Accuracy | 0     \n",
            "7 | test_acc      | Accuracy | 0     \n",
            "-------------------------------------------\n",
            "936 K     Trainable params\n",
            "0         Non-trainable params\n",
            "936 K     Total params\n",
            "Epoch 0:  91% 430/470 [00:18<00:01, 22.95it/s, loss=0.221, v_num=1, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  92% 433/470 [00:18<00:01, 23.01it/s, loss=0.221, v_num=1, val_loss=2.33, val_acc=0.0664]\n",
            "Validating:   8% 3/40 [00:00<00:01, 26.91it/s]\u001b[A\n",
            "Epoch 0:  93% 438/470 [00:19<00:01, 23.05it/s, loss=0.221, v_num=1, val_loss=2.33, val_acc=0.0664]\n",
            "Validating:  22% 9/40 [00:00<00:01, 26.33it/s]\u001b[A\n",
            "Epoch 0:  94% 443/470 [00:19<00:01, 23.08it/s, loss=0.221, v_num=1, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  95% 448/470 [00:19<00:00, 23.10it/s, loss=0.221, v_num=1, val_loss=2.33, val_acc=0.0664]\n",
            "Validating:  45% 18/40 [00:00<00:00, 25.72it/s]\u001b[A\n",
            "Epoch 0:  96% 453/470 [00:19<00:00, 23.14it/s, loss=0.221, v_num=1, val_loss=2.33, val_acc=0.0664]\n",
            "Validating:  60% 24/40 [00:00<00:00, 25.73it/s]\u001b[A\n",
            "Epoch 0:  97% 458/470 [00:19<00:00, 23.14it/s, loss=0.221, v_num=1, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  99% 463/470 [00:19<00:00, 23.16it/s, loss=0.221, v_num=1, val_loss=2.33, val_acc=0.0664]\n",
            "Validating:  82% 33/40 [00:01<00:00, 24.97it/s]\u001b[A\n",
            "Epoch 0: 100% 468/470 [00:20<00:00, 23.19it/s, loss=0.221, v_num=1, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0: 100% 470/470 [00:20<00:00, 23.12it/s, loss=0.221, v_num=1, val_loss=0.157, val_acc=0.956]\n",
            "Epoch 1:  91% 430/470 [00:18<00:01, 22.98it/s, loss=0.159, v_num=1, val_loss=0.157, val_acc=0.956]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  93% 435/470 [00:18<00:01, 23.04it/s, loss=0.159, v_num=1, val_loss=0.157, val_acc=0.956]\n",
            "Validating:  15% 6/40 [00:00<00:01, 25.36it/s]\u001b[A\n",
            "Epoch 1:  94% 440/470 [00:19<00:01, 23.06it/s, loss=0.159, v_num=1, val_loss=0.157, val_acc=0.956]\n",
            "Epoch 1:  95% 445/470 [00:19<00:01, 23.10it/s, loss=0.159, v_num=1, val_loss=0.157, val_acc=0.956]\n",
            "Validating:  38% 15/40 [00:00<00:00, 26.00it/s]\u001b[A\n",
            "Epoch 1:  96% 450/470 [00:19<00:00, 23.13it/s, loss=0.159, v_num=1, val_loss=0.157, val_acc=0.956]\n",
            "Validating:  52% 21/40 [00:00<00:00, 25.83it/s]\u001b[A\n",
            "Epoch 1:  97% 455/470 [00:19<00:00, 23.16it/s, loss=0.159, v_num=1, val_loss=0.157, val_acc=0.956]\n",
            "Epoch 1:  98% 460/470 [00:19<00:00, 23.16it/s, loss=0.159, v_num=1, val_loss=0.157, val_acc=0.956]\n",
            "Validating:  75% 30/40 [00:01<00:00, 24.64it/s]\u001b[A\n",
            "Epoch 1:  99% 465/470 [00:20<00:00, 23.19it/s, loss=0.159, v_num=1, val_loss=0.157, val_acc=0.956]\n",
            "Validating:  90% 36/40 [00:01<00:00, 25.43it/s]\u001b[A\n",
            "Epoch 1: 100% 470/470 [00:20<00:00, 23.16it/s, loss=0.159, v_num=1, val_loss=0.124, val_acc=0.963]\n",
            "Epoch 2:  91% 430/470 [00:18<00:01, 22.77it/s, loss=0.144, v_num=1, val_loss=0.124, val_acc=0.963]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  93% 435/470 [00:19<00:01, 22.83it/s, loss=0.144, v_num=1, val_loss=0.124, val_acc=0.963]\n",
            "Validating:  15% 6/40 [00:00<00:01, 23.05it/s]\u001b[A\n",
            "Epoch 2:  94% 440/470 [00:19<00:01, 22.85it/s, loss=0.144, v_num=1, val_loss=0.124, val_acc=0.963]\n",
            "Epoch 2:  95% 445/470 [00:19<00:01, 22.89it/s, loss=0.144, v_num=1, val_loss=0.124, val_acc=0.963]\n",
            "Validating:  38% 15/40 [00:00<00:00, 26.00it/s]\u001b[A\n",
            "Epoch 2:  96% 450/470 [00:19<00:00, 22.92it/s, loss=0.144, v_num=1, val_loss=0.124, val_acc=0.963]\n",
            "Validating:  52% 21/40 [00:00<00:00, 25.96it/s]\u001b[A\n",
            "Epoch 2:  97% 455/470 [00:19<00:00, 22.95it/s, loss=0.144, v_num=1, val_loss=0.124, val_acc=0.963]\n",
            "Epoch 2:  98% 460/470 [00:20<00:00, 22.96it/s, loss=0.144, v_num=1, val_loss=0.124, val_acc=0.963]\n",
            "Validating:  75% 30/40 [00:01<00:00, 24.97it/s]\u001b[A\n",
            "Epoch 2:  99% 465/470 [00:20<00:00, 22.98it/s, loss=0.144, v_num=1, val_loss=0.124, val_acc=0.963]\n",
            "Validating:  90% 36/40 [00:01<00:00, 24.36it/s]\u001b[A\n",
            "Epoch 2: 100% 470/470 [00:20<00:00, 22.94it/s, loss=0.144, v_num=1, val_loss=0.108, val_acc=0.969]\n",
            "Epoch 2: 100% 470/470 [00:20<00:00, 22.87it/s, loss=0.144, v_num=1, val_loss=0.108, val_acc=0.969]\n",
            "Testing: 100% 79/79 [00:03<00:00, 26.11it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.9702, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate synthetic handwritten lines, and train CNNs"
      ],
      "metadata": {
        "id": "1d6JrFlx2D1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/fsdl-text-recognizer-2021-labs/lab2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNO0N7LUlXBS",
        "outputId": "e5d97e90-b97d-4fc3-e7d0-d31e681115a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fsdl-text-recognizer-2021-labs/lab2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 training/run_experiment.py --max_epochs=5 --gpus=1 --data_class=EMNIST --model_class=CNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvPdi2CltrHH",
        "outputId": "38f546bc-7dd0-4d73-b568-b0a601557058"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Downloading raw dataset from https://s3-us-west-2.amazonaws.com/fsdl-public-assets/matlab.zip to /content/fsdl-text-recognizer-2021-labs/data/downloaded/emnist/matlab.zip...\n",
            "709MB [00:16, 44.7MB/s]               \n",
            "Computing SHA-256...\n",
            "Unzipping EMNIST...\n",
            "Loading training data from .mat file\n",
            "Balancing classes to reduce amount of data\n",
            "Saving to HDF5 in a compressed format...\n",
            "Saving essential dataset parameters to text_recognizer/datasets...\n",
            "Cleaning up...\n",
            "\n",
            "   | Name             | Type      | Params\n",
            "------------------------------------------------\n",
            "0  | model            | CNN       | 1.7 M \n",
            "1  | model.conv1      | ConvBlock | 640   \n",
            "2  | model.conv1.conv | Conv2d    | 640   \n",
            "3  | model.conv1.relu | ReLU      | 0     \n",
            "4  | model.conv2      | ConvBlock | 36.9 K\n",
            "5  | model.conv2.conv | Conv2d    | 36.9 K\n",
            "6  | model.conv2.relu | ReLU      | 0     \n",
            "7  | model.dropout    | Dropout   | 0     \n",
            "8  | model.max_pool   | MaxPool2d | 0     \n",
            "9  | model.fc1        | Linear    | 1.6 M \n",
            "10 | model.fc2        | Linear    | 10.7 K\n",
            "11 | train_acc        | Accuracy  | 0     \n",
            "12 | val_acc          | Accuracy  | 0     \n",
            "13 | test_acc         | Accuracy  | 0     \n",
            "------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  80% 2033/2542 [00:56<00:14, 35.71it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  80% 2042/2542 [00:57<00:13, 35.79it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2051/2542 [00:57<00:13, 35.88it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2060/2542 [00:57<00:13, 35.96it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2069/2542 [00:57<00:13, 36.05it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  82% 2078/2542 [00:57<00:12, 36.14it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  82% 2087/2542 [00:57<00:12, 36.22it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  82% 2096/2542 [00:57<00:12, 36.30it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  83% 2105/2542 [00:57<00:12, 36.39it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  83% 2114/2542 [00:57<00:11, 36.47it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2123/2542 [00:58<00:11, 36.54it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2132/2542 [00:58<00:11, 36.63it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2141/2542 [00:58<00:10, 36.71it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  21% 108/509 [00:01<00:05, 77.08it/s]\u001b[A\n",
            "Epoch 0:  85% 2150/2542 [00:58<00:10, 36.79it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  85% 2159/2542 [00:58<00:10, 36.87it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  85% 2168/2542 [00:58<00:10, 36.95it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  86% 2177/2542 [00:58<00:09, 37.02it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  86% 2186/2542 [00:58<00:09, 37.10it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  86% 2195/2542 [00:59<00:09, 37.18it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  87% 2204/2542 [00:59<00:09, 37.26it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  87% 2213/2542 [00:59<00:08, 37.34it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  87% 2222/2542 [00:59<00:08, 37.42it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  88% 2231/2542 [00:59<00:08, 37.50it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  88% 2240/2542 [00:59<00:08, 37.58it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  88% 2249/2542 [00:59<00:07, 37.66it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  89% 2258/2542 [00:59<00:07, 37.74it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  44% 225/509 [00:02<00:03, 77.88it/s]\u001b[A\n",
            "Epoch 0:  89% 2267/2542 [00:59<00:07, 37.81it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  90% 2276/2542 [01:00<00:07, 37.89it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  90% 2285/2542 [01:00<00:06, 37.96it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  90% 2294/2542 [01:00<00:06, 38.04it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2303/2542 [01:00<00:06, 38.12it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2312/2542 [01:00<00:06, 38.20it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2321/2542 [01:00<00:05, 38.27it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  92% 2330/2542 [01:00<00:05, 38.35it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  92% 2339/2542 [01:00<00:05, 38.42it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  92% 2348/2542 [01:00<00:05, 38.50it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  62% 315/509 [00:04<00:02, 78.41it/s]\u001b[A\n",
            "Epoch 0:  93% 2357/2542 [01:01<00:04, 38.57it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  93% 2366/2542 [01:01<00:04, 38.64it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  93% 2375/2542 [01:01<00:04, 38.72it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2384/2542 [01:01<00:04, 38.79it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2393/2542 [01:01<00:03, 38.86it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2402/2542 [01:01<00:03, 38.93it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  95% 2411/2542 [01:01<00:03, 39.01it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  95% 2420/2542 [01:01<00:03, 39.08it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2429/2542 [01:02<00:02, 39.15it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2438/2542 [01:02<00:02, 39.22it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2447/2542 [01:02<00:02, 39.29it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  81% 414/509 [00:05<00:01, 75.32it/s]\u001b[A\n",
            "Epoch 0:  97% 2456/2542 [01:02<00:02, 39.36it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  97% 2465/2542 [01:02<00:01, 39.43it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  97% 2474/2542 [01:02<00:01, 39.50it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  98% 2483/2542 [01:02<00:01, 39.56it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  98% 2492/2542 [01:02<00:01, 39.63it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  98% 2501/2542 [01:03<00:01, 39.70it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  99% 2510/2542 [01:03<00:00, 39.76it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  99% 2519/2542 [01:03<00:00, 39.82it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  95% 486/509 [00:06<00:00, 71.86it/s]\u001b[A\n",
            "Epoch 0:  99% 2528/2542 [01:03<00:00, 39.89it/s, loss=0.603, v_num=0, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0: 100% 2542/2542 [01:03<00:00, 39.91it/s, loss=0.603, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  80% 2034/2542 [00:59<00:14, 34.12it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  80% 2043/2542 [00:59<00:14, 34.21it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  81% 2052/2542 [00:59<00:14, 34.29it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  81% 2061/2542 [00:59<00:13, 34.37it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  81% 2070/2542 [01:00<00:13, 34.46it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  82% 2079/2542 [01:00<00:13, 34.54it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  82% 2088/2542 [01:00<00:13, 34.62it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  82% 2097/2542 [01:00<00:12, 34.71it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  83% 2106/2542 [01:00<00:12, 34.79it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Validating:  14% 73/509 [00:00<00:05, 76.28it/s]\u001b[A\n",
            "Epoch 1:  83% 2115/2542 [01:00<00:12, 34.87it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  84% 2124/2542 [01:00<00:11, 34.95it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  84% 2133/2542 [01:00<00:11, 35.04it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  84% 2142/2542 [01:00<00:11, 35.12it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  85% 2151/2542 [01:01<00:11, 35.20it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  85% 2160/2542 [01:01<00:10, 35.28it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  85% 2169/2542 [01:01<00:10, 35.37it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  86% 2178/2542 [01:01<00:10, 35.45it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  86% 2187/2542 [01:01<00:09, 35.52it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  86% 2196/2542 [01:01<00:09, 35.61it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  87% 2205/2542 [01:01<00:09, 35.69it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  87% 2214/2542 [01:01<00:09, 35.77it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  87% 2223/2542 [01:02<00:08, 35.85it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  88% 2232/2542 [01:02<00:08, 35.93it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  88% 2241/2542 [01:02<00:08, 36.01it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  89% 2250/2542 [01:02<00:08, 36.09it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  89% 2259/2542 [01:02<00:07, 36.16it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  89% 2268/2542 [01:02<00:07, 36.23it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Validating:  46% 235/509 [00:03<00:03, 75.73it/s]\u001b[A\n",
            "Epoch 1:  90% 2277/2542 [01:02<00:07, 36.31it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  90% 2286/2542 [01:02<00:07, 36.38it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  90% 2295/2542 [01:02<00:06, 36.46it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  91% 2304/2542 [01:03<00:06, 36.53it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  91% 2313/2542 [01:03<00:06, 36.61it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  91% 2322/2542 [01:03<00:05, 36.68it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  92% 2331/2542 [01:03<00:05, 36.76it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  92% 2340/2542 [01:03<00:05, 36.83it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Validating:  60% 307/509 [00:03<00:02, 77.58it/s]\u001b[A\n",
            "Epoch 1:  92% 2349/2542 [01:03<00:05, 36.90it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  93% 2358/2542 [01:03<00:04, 36.97it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  93% 2367/2542 [01:03<00:04, 37.05it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  93% 2376/2542 [01:04<00:04, 37.12it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  94% 2385/2542 [01:04<00:04, 37.19it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  94% 2394/2542 [01:04<00:03, 37.27it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  95% 2403/2542 [01:04<00:03, 37.34it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  95% 2412/2542 [01:04<00:03, 37.41it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Validating:  74% 379/509 [00:04<00:01, 77.34it/s]\u001b[A\n",
            "Epoch 1:  95% 2421/2542 [01:04<00:03, 37.48it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  96% 2430/2542 [01:04<00:02, 37.55it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  96% 2439/2542 [01:04<00:02, 37.62it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  96% 2448/2542 [01:04<00:02, 37.69it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  97% 2457/2542 [01:05<00:02, 37.76it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  97% 2466/2542 [01:05<00:02, 37.83it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  97% 2475/2542 [01:05<00:01, 37.89it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  98% 2484/2542 [01:05<00:01, 37.96it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Validating:  89% 451/509 [00:05<00:00, 75.21it/s]\u001b[A\n",
            "Epoch 1:  98% 2493/2542 [01:05<00:01, 38.03it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  98% 2502/2542 [01:05<00:01, 38.09it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  99% 2511/2542 [01:05<00:00, 38.16it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  99% 2520/2542 [01:05<00:00, 38.22it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1:  99% 2529/2542 [01:06<00:00, 38.28it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1: 100% 2538/2542 [01:06<00:00, 38.35it/s, loss=0.532, v_num=0, val_loss=0.576, val_acc=0.788]\n",
            "Epoch 1: 100% 2542/2542 [01:06<00:00, 38.32it/s, loss=0.532, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  80% 2034/2542 [00:54<00:13, 37.38it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  80% 2043/2542 [00:54<00:13, 37.46it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  81% 2052/2542 [00:54<00:13, 37.55it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  81% 2061/2542 [00:54<00:12, 37.63it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  81% 2070/2542 [00:54<00:12, 37.72it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  82% 2079/2542 [00:54<00:12, 37.81it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  82% 2088/2542 [00:55<00:11, 37.89it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  82% 2097/2542 [00:55<00:11, 37.96it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  83% 2106/2542 [00:55<00:11, 38.04it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  83% 2115/2542 [00:55<00:11, 38.12it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  84% 2124/2542 [00:55<00:10, 38.21it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Validating:  18% 91/509 [00:01<00:05, 76.85it/s]\u001b[A\n",
            "Epoch 2:  84% 2133/2542 [00:55<00:10, 38.29it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  84% 2142/2542 [00:55<00:10, 38.37it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  85% 2151/2542 [00:55<00:10, 38.45it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  85% 2160/2542 [00:56<00:09, 38.54it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  85% 2169/2542 [00:56<00:09, 38.62it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  86% 2178/2542 [00:56<00:09, 38.69it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  86% 2187/2542 [00:56<00:09, 38.77it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  86% 2196/2542 [00:56<00:08, 38.86it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  87% 2205/2542 [00:56<00:08, 38.94it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  87% 2214/2542 [00:56<00:08, 39.01it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Validating:  36% 181/509 [00:02<00:04, 77.92it/s]\u001b[A\n",
            "Epoch 2:  87% 2223/2542 [00:56<00:08, 39.09it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  88% 2232/2542 [00:56<00:07, 39.17it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  88% 2241/2542 [00:57<00:07, 39.25it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  89% 2250/2542 [00:57<00:07, 39.32it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  89% 2259/2542 [00:57<00:07, 39.40it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  89% 2268/2542 [00:57<00:06, 39.47it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  90% 2277/2542 [00:57<00:06, 39.54it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  90% 2286/2542 [00:57<00:06, 39.62it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Validating:  50% 253/509 [00:03<00:03, 76.20it/s]\u001b[A\n",
            "Epoch 2:  90% 2295/2542 [00:57<00:06, 39.69it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  91% 2304/2542 [00:57<00:05, 39.77it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  91% 2313/2542 [00:58<00:05, 39.84it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  91% 2322/2542 [00:58<00:05, 39.92it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  92% 2331/2542 [00:58<00:05, 39.99it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  92% 2340/2542 [00:58<00:05, 40.06it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  92% 2349/2542 [00:58<00:04, 40.13it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  93% 2358/2542 [00:58<00:04, 40.20it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  93% 2367/2542 [00:58<00:04, 40.27it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Validating:  66% 334/509 [00:04<00:02, 75.17it/s]\u001b[A\n",
            "Epoch 2:  93% 2376/2542 [00:58<00:04, 40.35it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  94% 2385/2542 [00:59<00:03, 40.42it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  94% 2394/2542 [00:59<00:03, 40.49it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  95% 2403/2542 [00:59<00:03, 40.55it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  95% 2412/2542 [00:59<00:03, 40.62it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  95% 2421/2542 [00:59<00:02, 40.69it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  96% 2430/2542 [00:59<00:02, 40.75it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  96% 2439/2542 [00:59<00:02, 40.81it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Validating:  80% 406/509 [00:05<00:01, 69.69it/s]\u001b[A\n",
            "Epoch 2:  96% 2448/2542 [00:59<00:02, 40.87it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  97% 2457/2542 [01:00<00:02, 40.94it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  97% 2466/2542 [01:00<00:01, 41.01it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  97% 2475/2542 [01:00<00:01, 41.07it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  98% 2484/2542 [01:00<00:01, 41.14it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  98% 2493/2542 [01:00<00:01, 41.20it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  98% 2502/2542 [01:00<00:00, 41.27it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  99% 2511/2542 [01:00<00:00, 41.33it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Validating:  94% 478/509 [00:06<00:00, 73.06it/s]\u001b[A\n",
            "Epoch 2:  99% 2520/2542 [01:00<00:00, 41.39it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2:  99% 2529/2542 [01:00<00:00, 41.46it/s, loss=0.473, v_num=0, val_loss=0.529, val_acc=0.799]\n",
            "Epoch 2: 100% 2542/2542 [01:01<00:00, 41.49it/s, loss=0.473, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  80% 2034/2542 [00:59<00:14, 34.32it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3:  80% 2043/2542 [00:59<00:14, 34.40it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  81% 2052/2542 [00:59<00:14, 34.49it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  81% 2061/2542 [00:59<00:13, 34.57it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  81% 2070/2542 [00:59<00:13, 34.66it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  82% 2079/2542 [00:59<00:13, 34.74it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  82% 2088/2542 [00:59<00:13, 34.82it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  82% 2097/2542 [01:00<00:12, 34.91it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  83% 2106/2542 [01:00<00:12, 34.98it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  83% 2115/2542 [01:00<00:12, 35.07it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  84% 2124/2542 [01:00<00:11, 35.15it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  84% 2133/2542 [01:00<00:11, 35.23it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  84% 2142/2542 [01:00<00:11, 35.31it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Validating:  21% 109/509 [00:01<00:05, 77.35it/s]\u001b[A\n",
            "Epoch 3:  85% 2151/2542 [01:00<00:11, 35.38it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  85% 2160/2542 [01:00<00:10, 35.46it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  85% 2169/2542 [01:01<00:10, 35.54it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  86% 2178/2542 [01:01<00:10, 35.62it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  86% 2187/2542 [01:01<00:09, 35.70it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  86% 2196/2542 [01:01<00:09, 35.77it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  87% 2205/2542 [01:01<00:09, 35.85it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  87% 2214/2542 [01:01<00:09, 35.92it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Validating:  36% 181/509 [00:02<00:04, 73.80it/s]\u001b[A\n",
            "Epoch 3:  87% 2223/2542 [01:01<00:08, 36.00it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  88% 2232/2542 [01:01<00:08, 36.08it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  88% 2241/2542 [01:01<00:08, 36.15it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  89% 2250/2542 [01:02<00:08, 36.23it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  89% 2259/2542 [01:02<00:07, 36.30it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  89% 2268/2542 [01:02<00:07, 36.37it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  90% 2277/2542 [01:02<00:07, 36.45it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  90% 2286/2542 [01:02<00:07, 36.52it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Validating:  50% 253/509 [00:03<00:03, 73.43it/s]\u001b[A\n",
            "Epoch 3:  90% 2295/2542 [01:02<00:06, 36.59it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  91% 2304/2542 [01:02<00:06, 36.67it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  91% 2313/2542 [01:02<00:06, 36.74it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  91% 2322/2542 [01:03<00:05, 36.81it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  92% 2331/2542 [01:03<00:05, 36.89it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  92% 2340/2542 [01:03<00:05, 36.96it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  92% 2349/2542 [01:03<00:05, 37.03it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  93% 2358/2542 [01:03<00:04, 37.10it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Validating:  64% 325/509 [00:04<00:02, 74.18it/s]\u001b[A\n",
            "Epoch 3:  93% 2367/2542 [01:03<00:04, 37.17it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  93% 2376/2542 [01:03<00:04, 37.24it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  94% 2385/2542 [01:03<00:04, 37.31it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  94% 2394/2542 [01:04<00:03, 37.38it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  95% 2403/2542 [01:04<00:03, 37.45it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  95% 2412/2542 [01:04<00:03, 37.51it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  95% 2421/2542 [01:04<00:03, 37.57it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  96% 2430/2542 [01:04<00:02, 37.64it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Validating:  78% 397/509 [00:05<00:01, 70.13it/s]\u001b[A\n",
            "Epoch 3:  96% 2439/2542 [01:04<00:02, 37.70it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  96% 2448/2542 [01:04<00:02, 37.76it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  97% 2457/2542 [01:04<00:02, 37.83it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  97% 2466/2542 [01:05<00:02, 37.89it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  97% 2475/2542 [01:05<00:01, 37.95it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  98% 2484/2542 [01:05<00:01, 38.01it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Validating:  89% 452/509 [00:06<00:00, 68.77it/s]\u001b[A\n",
            "Epoch 3:  98% 2493/2542 [01:05<00:01, 38.07it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  98% 2502/2542 [01:05<00:01, 38.13it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  99% 2511/2542 [01:05<00:00, 38.19it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3:  99% 2520/2542 [01:05<00:00, 38.25it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Validating:  96% 487/509 [00:06<00:00, 67.88it/s]\u001b[A\n",
            "Epoch 3:  99% 2529/2542 [01:06<00:00, 38.31it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3: 100% 2538/2542 [01:06<00:00, 38.37it/s, loss=0.464, v_num=0, val_loss=0.513, val_acc=0.798]\n",
            "Epoch 3: 100% 2542/2542 [01:06<00:00, 38.34it/s, loss=0.464, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  80% 2034/2542 [00:54<00:13, 37.44it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 4:  80% 2043/2542 [00:54<00:13, 37.53it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  81% 2052/2542 [00:54<00:13, 37.61it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  81% 2061/2542 [00:54<00:12, 37.70it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  81% 2070/2542 [00:54<00:12, 37.78it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  82% 2079/2542 [00:54<00:12, 37.87it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  82% 2088/2542 [00:55<00:11, 37.95it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  82% 2097/2542 [00:55<00:11, 38.02it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  83% 2106/2542 [00:55<00:11, 38.10it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  83% 2115/2542 [00:55<00:11, 38.18it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  84% 2124/2542 [00:55<00:10, 38.27it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Validating:  18% 91/509 [00:01<00:05, 76.73it/s]\u001b[A\n",
            "Epoch 4:  84% 2133/2542 [00:55<00:10, 38.35it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  84% 2142/2542 [00:55<00:10, 38.43it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  85% 2151/2542 [00:55<00:10, 38.52it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  85% 2160/2542 [00:55<00:09, 38.59it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  85% 2169/2542 [00:56<00:09, 38.67it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  86% 2178/2542 [00:56<00:09, 38.74it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  86% 2187/2542 [00:56<00:09, 38.82it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  86% 2196/2542 [00:56<00:08, 38.90it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  87% 2205/2542 [00:56<00:08, 38.97it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Validating:  34% 172/509 [00:02<00:04, 74.20it/s]\u001b[A\n",
            "Epoch 4:  87% 2214/2542 [00:56<00:08, 39.05it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  87% 2223/2542 [00:56<00:08, 39.13it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  88% 2232/2542 [00:56<00:07, 39.21it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  88% 2241/2542 [00:57<00:07, 39.29it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  89% 2250/2542 [00:57<00:07, 39.36it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  89% 2259/2542 [00:57<00:07, 39.44it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  89% 2268/2542 [00:57<00:06, 39.51it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  90% 2277/2542 [00:57<00:06, 39.58it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Validating:  48% 244/509 [00:03<00:03, 75.37it/s]\u001b[A\n",
            "Epoch 4:  90% 2286/2542 [00:57<00:06, 39.66it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  90% 2295/2542 [00:57<00:06, 39.73it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  91% 2304/2542 [00:57<00:05, 39.81it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  91% 2313/2542 [00:57<00:05, 39.88it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  91% 2322/2542 [00:58<00:05, 39.95it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  92% 2331/2542 [00:58<00:05, 40.02it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  92% 2340/2542 [00:58<00:05, 40.09it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  92% 2349/2542 [00:58<00:04, 40.16it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Validating:  62% 316/509 [00:04<00:02, 74.64it/s]\u001b[A\n",
            "Epoch 4:  93% 2358/2542 [00:58<00:04, 40.23it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  93% 2367/2542 [00:58<00:04, 40.31it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  93% 2376/2542 [00:58<00:04, 40.38it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  94% 2385/2542 [00:58<00:03, 40.45it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  94% 2394/2542 [00:59<00:03, 40.52it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  95% 2403/2542 [00:59<00:03, 40.59it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  95% 2412/2542 [00:59<00:03, 40.66it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  95% 2421/2542 [00:59<00:02, 40.72it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Validating:  76% 388/509 [00:05<00:01, 73.61it/s]\u001b[A\n",
            "Epoch 4:  96% 2430/2542 [00:59<00:02, 40.79it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  96% 2439/2542 [00:59<00:02, 40.86it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  96% 2448/2542 [00:59<00:02, 40.92it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  97% 2457/2542 [00:59<00:02, 40.98it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  97% 2466/2542 [01:00<00:01, 41.05it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  97% 2475/2542 [01:00<00:01, 41.10it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  98% 2484/2542 [01:00<00:01, 41.17it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  98% 2493/2542 [01:00<00:01, 41.23it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Validating:  90% 460/509 [00:06<00:00, 70.68it/s]\u001b[A\n",
            "Epoch 4:  98% 2502/2542 [01:00<00:00, 41.30it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  99% 2511/2542 [01:00<00:00, 41.36it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  99% 2520/2542 [01:00<00:00, 41.42it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4:  99% 2529/2542 [01:00<00:00, 41.48it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4: 100% 2538/2542 [01:01<00:00, 41.53it/s, loss=0.477, v_num=0, val_loss=0.497, val_acc=0.809]\n",
            "Epoch 4: 100% 2542/2542 [01:01<00:00, 41.50it/s, loss=0.477, v_num=0, val_loss=0.495, val_acc=0.808]\n",
            "Epoch 4: 100% 2542/2542 [01:01<00:00, 41.29it/s, loss=0.477, v_num=0, val_loss=0.495, val_acc=0.808]\n",
            "Testing: 100% 422/422 [00:05<00:00, 70.90it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.8059, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 training/run_experiment.py --max_epochs=50 --gpus=1 --num_workers=4 --data_class=EMNIST --model_class=CNN --overfit_batches=2 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYhYAXr2vZ67",
        "outputId": "d0bf7c21-d747-4dc4-fd43-79667fc74274"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "   | Name             | Type      | Params\n",
            "------------------------------------------------\n",
            "0  | model            | CNN       | 1.7 M \n",
            "1  | model.conv1      | ConvBlock | 640   \n",
            "2  | model.conv1.conv | Conv2d    | 640   \n",
            "3  | model.conv1.relu | ReLU      | 0     \n",
            "4  | model.conv2      | ConvBlock | 36.9 K\n",
            "5  | model.conv2.conv | Conv2d    | 36.9 K\n",
            "6  | model.conv2.relu | ReLU      | 0     \n",
            "7  | model.dropout    | Dropout   | 0     \n",
            "8  | model.max_pool   | MaxPool2d | 0     \n",
            "9  | model.fc1        | Linear    | 1.6 M \n",
            "10 | model.fc2        | Linear    | 10.7 K\n",
            "11 | train_acc        | Accuracy  | 0     \n",
            "12 | val_acc          | Accuracy  | 0     \n",
            "13 | test_acc         | Accuracy  | 0     \n",
            "------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You requested to overfit but enabled test/val dataloader shuffling. We are turning it off for you.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Validation sanity check:  50% 1/2 [00:00<00:00,  1.42it/s]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You requested to overfit but enabled training dataloader shuffling. We are turning it off for you.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Epoch 0:  50% 2/4 [00:00<00:00,  6.65it/s, loss=4.39, v_num=1, val_loss=4.42, val_acc=0.00391]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 4/4 [00:00<00:00,  5.34it/s, loss=4.39, v_num=1, val_loss=4.17, val_acc=0.0273] \n",
            "Epoch 1:  75% 3/4 [00:00<00:00, 10.57it/s, loss=4.26, v_num=1, val_loss=4.17, val_acc=0.0273]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1: 100% 4/4 [00:00<00:00,  4.96it/s, loss=4.26, v_num=1, val_loss=3.86, val_acc=0.0859]\n",
            "Epoch 2:  75% 3/4 [00:00<00:00, 10.29it/s, loss=4.1, v_num=1, val_loss=3.86, val_acc=0.0859]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 4/4 [00:00<00:00,  4.94it/s, loss=4.1, v_num=1, val_loss=3.45, val_acc=0.285] \n",
            "Epoch 3:  75% 3/4 [00:00<00:00, 10.18it/s, loss=3.91, v_num=1, val_loss=3.45, val_acc=0.285]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 4/4 [00:00<00:00,  5.03it/s, loss=3.91, v_num=1, val_loss=2.97, val_acc=0.387]\n",
            "Epoch 4:  75% 3/4 [00:00<00:00, 10.70it/s, loss=3.7, v_num=1, val_loss=2.97, val_acc=0.387]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 4: 100% 4/4 [00:00<00:00,  5.15it/s, loss=3.7, v_num=1, val_loss=2.48, val_acc=0.484]\n",
            "Epoch 5:  75% 3/4 [00:00<00:00, 10.40it/s, loss=3.48, v_num=1, val_loss=2.48, val_acc=0.484]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:  50% 1/2 [00:00<00:00,  4.26it/s]\u001b[ATraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Epoch 5: 100% 4/4 [00:00<00:00,  5.14it/s, loss=3.48, v_num=1, val_loss=1.99, val_acc=0.582]\n",
            "Epoch 6:  75% 3/4 [00:00<00:00,  9.88it/s, loss=3.26, v_num=1, val_loss=1.99, val_acc=0.582]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 6: 100% 4/4 [00:00<00:00,  5.07it/s, loss=3.26, v_num=1, val_loss=1.55, val_acc=0.648]\n",
            "Epoch 7:  75% 3/4 [00:00<00:00, 10.20it/s, loss=3.04, v_num=1, val_loss=1.55, val_acc=0.648]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:  50% 1/2 [00:00<00:00,  4.26it/s]\u001b[ATraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Epoch 7: 100% 4/4 [00:00<00:00,  5.01it/s, loss=3.04, v_num=1, val_loss=1.18, val_acc=0.75] \n",
            "Epoch 8:  75% 3/4 [00:00<00:00,  9.88it/s, loss=2.82, v_num=1, val_loss=1.18, val_acc=0.75]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 8: 100% 4/4 [00:00<00:00,  5.07it/s, loss=2.82, v_num=1, val_loss=0.856, val_acc=0.82]\n",
            "Epoch 9:  75% 3/4 [00:00<00:00, 10.53it/s, loss=2.62, v_num=1, val_loss=0.856, val_acc=0.82]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 9: 100% 4/4 [00:00<00:00,  5.14it/s, loss=2.62, v_num=1, val_loss=0.603, val_acc=0.863]\n",
            "Epoch 10:  75% 3/4 [00:00<00:00, 10.21it/s, loss=2.24, v_num=1, val_loss=0.603, val_acc=0.863]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 10: 100% 4/4 [00:00<00:00,  5.01it/s, loss=2.24, v_num=1, val_loss=0.403, val_acc=0.922]\n",
            "Epoch 11:  75% 3/4 [00:00<00:00, 10.42it/s, loss=1.86, v_num=1, val_loss=0.403, val_acc=0.922]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 11: 100% 4/4 [00:00<00:00,  5.08it/s, loss=1.86, v_num=1, val_loss=0.256, val_acc=0.949]\n",
            "Epoch 12:  75% 3/4 [00:00<00:00, 10.24it/s, loss=1.51, v_num=1, val_loss=0.256, val_acc=0.949]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 12: 100% 4/4 [00:00<00:00,  5.13it/s, loss=1.51, v_num=1, val_loss=0.16, val_acc=0.977] \n",
            "Epoch 13:  75% 3/4 [00:00<00:00,  9.86it/s, loss=1.19, v_num=1, val_loss=0.16, val_acc=0.977]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 13: 100% 4/4 [00:00<00:00,  5.06it/s, loss=1.19, v_num=1, val_loss=0.103, val_acc=0.984]\n",
            "Epoch 14:  75% 3/4 [00:00<00:00, 10.11it/s, loss=0.915, v_num=1, val_loss=0.103, val_acc=0.984]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 14: 100% 4/4 [00:00<00:00,  5.15it/s, loss=0.915, v_num=1, val_loss=0.0666, val_acc=0.996]\n",
            "Epoch 15:  75% 3/4 [00:00<00:00, 10.17it/s, loss=0.685, v_num=1, val_loss=0.0666, val_acc=0.996]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 15: 100% 4/4 [00:00<00:00,  5.01it/s, loss=0.685, v_num=1, val_loss=0.047, val_acc=0.996] \n",
            "Epoch 16:  75% 3/4 [00:00<00:00, 10.02it/s, loss=0.498, v_num=1, val_loss=0.047, val_acc=0.996]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 16: 100% 4/4 [00:00<00:00,  5.05it/s, loss=0.498, v_num=1, val_loss=0.0382, val_acc=0.98]\n",
            "Epoch 17:  75% 3/4 [00:00<00:00, 10.35it/s, loss=0.353, v_num=1, val_loss=0.0382, val_acc=0.98]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 17: 100% 4/4 [00:00<00:00,  5.11it/s, loss=0.353, v_num=1, val_loss=0.0245, val_acc=1]   \n",
            "Epoch 18:  75% 3/4 [00:00<00:00, 10.35it/s, loss=0.245, v_num=1, val_loss=0.0245, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 18: 100% 4/4 [00:00<00:00,  5.14it/s, loss=0.245, v_num=1, val_loss=0.0107, val_acc=1]\n",
            "Epoch 19:  75% 3/4 [00:00<00:00,  9.94it/s, loss=0.165, v_num=1, val_loss=0.0107, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 19: 100% 4/4 [00:00<00:00,  6.18it/s, loss=0.165, v_num=1, val_loss=0.0209, val_acc=0.988]\n",
            "Epoch 20:  75% 3/4 [00:00<00:00,  9.64it/s, loss=0.111, v_num=1, val_loss=0.0209, val_acc=0.988]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 20: 100% 4/4 [00:00<00:00,  6.00it/s, loss=0.111, v_num=1, val_loss=0.021, val_acc=0.992] \n",
            "Epoch 21:  75% 3/4 [00:00<00:00, 10.37it/s, loss=0.0752, v_num=1, val_loss=0.021, val_acc=0.992]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 21: 100% 4/4 [00:00<00:00,  4.96it/s, loss=0.0752, v_num=1, val_loss=0.0048, val_acc=1]   \n",
            "Epoch 22:  75% 3/4 [00:00<00:00,  9.99it/s, loss=0.0509, v_num=1, val_loss=0.0048, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 22: 100% 4/4 [00:00<00:00,  6.18it/s, loss=0.0509, v_num=1, val_loss=0.0136, val_acc=0.992]\n",
            "Epoch 23:  75% 3/4 [00:00<00:00, 10.18it/s, loss=0.0363, v_num=1, val_loss=0.0136, val_acc=0.992]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 23: 100% 4/4 [00:00<00:00,  5.03it/s, loss=0.0363, v_num=1, val_loss=0.00422, val_acc=1]   \n",
            "Epoch 24:  75% 3/4 [00:00<00:00, 10.46it/s, loss=0.0267, v_num=1, val_loss=0.00422, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 24: 100% 4/4 [00:00<00:00,  6.24it/s, loss=0.0267, v_num=1, val_loss=0.00721, val_acc=1]\n",
            "Epoch 25:  75% 3/4 [00:00<00:00, 10.24it/s, loss=0.0209, v_num=1, val_loss=0.00721, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 25: 100% 4/4 [00:00<00:00,  5.11it/s, loss=0.0209, v_num=1, val_loss=0.0023, val_acc=1] \n",
            "Epoch 26:  75% 3/4 [00:00<00:00, 10.37it/s, loss=0.0163, v_num=1, val_loss=0.0023, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 26: 100% 4/4 [00:00<00:00,  6.19it/s, loss=0.0163, v_num=1, val_loss=0.0032, val_acc=1]\n",
            "Epoch 27:  75% 3/4 [00:00<00:00, 10.18it/s, loss=0.0132, v_num=1, val_loss=0.0032, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 27: 100% 4/4 [00:00<00:00,  4.95it/s, loss=0.0132, v_num=1, val_loss=0.00149, val_acc=1]\n",
            "Epoch 28:  75% 3/4 [00:00<00:00, 10.24it/s, loss=0.0104, v_num=1, val_loss=0.00149, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 28: 100% 4/4 [00:00<00:00,  6.15it/s, loss=0.0104, v_num=1, val_loss=0.00263, val_acc=1]\n",
            "Epoch 29:  75% 3/4 [00:00<00:00,  9.97it/s, loss=0.00941, v_num=1, val_loss=0.00263, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 29: 100% 4/4 [00:00<00:00,  6.03it/s, loss=0.00941, v_num=1, val_loss=0.00222, val_acc=1]\n",
            "Epoch 30:  75% 3/4 [00:00<00:00, 10.12it/s, loss=0.00739, v_num=1, val_loss=0.00222, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:  50% 1/2 [00:00<00:00,  4.66it/s]\u001b[ATraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Epoch 30: 100% 4/4 [00:00<00:00,  4.90it/s, loss=0.00739, v_num=1, val_loss=0.00127, val_acc=1]\n",
            "Epoch 31:  75% 3/4 [00:00<00:00, 10.11it/s, loss=0.00555, v_num=1, val_loss=0.00127, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 31: 100% 4/4 [00:00<00:00,  5.95it/s, loss=0.00555, v_num=1, val_loss=0.00244, val_acc=1]\n",
            "Epoch 32:  75% 3/4 [00:00<00:00, 10.15it/s, loss=0.00521, v_num=1, val_loss=0.00244, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 32: 100% 4/4 [00:00<00:00,  6.30it/s, loss=0.00521, v_num=1, val_loss=0.00367, val_acc=1]\n",
            "Epoch 33:  75% 3/4 [00:00<00:00, 10.27it/s, loss=0.0044, v_num=1, val_loss=0.00367, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:  50% 1/2 [00:00<00:00,  4.80it/s]\u001b[ATraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Epoch 33: 100% 4/4 [00:00<00:00,  6.35it/s, loss=0.0044, v_num=1, val_loss=0.00154, val_acc=1]\n",
            "Epoch 34:  75% 3/4 [00:00<00:00, 10.50it/s, loss=0.00406, v_num=1, val_loss=0.00154, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 34: 100% 4/4 [00:00<00:00,  6.08it/s, loss=0.00406, v_num=1, val_loss=0.00474, val_acc=1]\n",
            "Epoch 35:  75% 3/4 [00:00<00:00, 10.17it/s, loss=0.00377, v_num=1, val_loss=0.00474, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 35: 100% 4/4 [00:00<00:00,  5.12it/s, loss=0.00377, v_num=1, val_loss=0.0009, val_acc=1] \n",
            "Epoch 36:  75% 3/4 [00:00<00:00, 10.56it/s, loss=0.00368, v_num=1, val_loss=0.0009, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:  50% 1/2 [00:00<00:00,  4.30it/s]\u001b[ATraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Epoch 36: 100% 4/4 [00:00<00:00,  6.31it/s, loss=0.00368, v_num=1, val_loss=0.00165, val_acc=1]\n",
            "Epoch 37:  75% 3/4 [00:00<00:00, 10.24it/s, loss=0.00343, v_num=1, val_loss=0.00165, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 37: 100% 4/4 [00:00<00:00,  5.03it/s, loss=0.00343, v_num=1, val_loss=0.000603, val_acc=1]\n",
            "Epoch 38:  75% 3/4 [00:00<00:00,  9.61it/s, loss=0.00338, v_num=1, val_loss=0.000603, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:  50% 1/2 [00:00<00:00,  4.89it/s]\u001b[ATraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Epoch 38: 100% 4/4 [00:00<00:00,  6.00it/s, loss=0.00338, v_num=1, val_loss=0.00163, val_acc=1] \n",
            "Epoch 39:  75% 3/4 [00:00<00:00, 10.50it/s, loss=0.00328, v_num=1, val_loss=0.00163, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 39: 100% 4/4 [00:00<00:00,  6.19it/s, loss=0.00328, v_num=1, val_loss=0.00962, val_acc=0.992]\n",
            "Epoch 40:  75% 3/4 [00:00<00:00, 10.01it/s, loss=0.0034, v_num=1, val_loss=0.00962, val_acc=0.992]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 40: 100% 4/4 [00:00<00:00,  5.01it/s, loss=0.0034, v_num=1, val_loss=0.000574, val_acc=1]   \n",
            "Epoch 41:  75% 3/4 [00:00<00:00, 10.07it/s, loss=0.00322, v_num=1, val_loss=0.000574, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 41: 100% 4/4 [00:00<00:00,  6.16it/s, loss=0.00322, v_num=1, val_loss=0.00204, val_acc=1] \n",
            "Epoch 42:  75% 3/4 [00:00<00:00,  9.85it/s, loss=0.00335, v_num=1, val_loss=0.00204, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 42: 100% 4/4 [00:00<00:00,  6.27it/s, loss=0.00335, v_num=1, val_loss=0.00127, val_acc=1]\n",
            "Epoch 43:  75% 3/4 [00:00<00:00, 10.25it/s, loss=0.00299, v_num=1, val_loss=0.00127, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 43: 100% 4/4 [00:00<00:00,  4.98it/s, loss=0.00299, v_num=1, val_loss=0.000342, val_acc=1]\n",
            "Epoch 44:  75% 3/4 [00:00<00:00, 10.49it/s, loss=0.00273, v_num=1, val_loss=0.000342, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 44: 100% 4/4 [00:00<00:00,  6.20it/s, loss=0.00273, v_num=1, val_loss=0.000594, val_acc=1]\n",
            "Epoch 45:  75% 3/4 [00:00<00:00,  9.94it/s, loss=0.00234, v_num=1, val_loss=0.000594, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 45: 100% 4/4 [00:00<00:00,  6.11it/s, loss=0.00234, v_num=1, val_loss=0.00195, val_acc=1] \n",
            "Epoch 46:  75% 3/4 [00:00<00:00, 10.10it/s, loss=0.00231, v_num=1, val_loss=0.00195, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 46: 100% 4/4 [00:00<00:00,  6.15it/s, loss=0.00231, v_num=1, val_loss=0.000979, val_acc=1]\n",
            "Epoch 47:  75% 3/4 [00:00<00:00,  9.35it/s, loss=0.00195, v_num=1, val_loss=0.000979, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:  50% 1/2 [00:00<00:00,  4.36it/s]\u001b[ATraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Epoch 47: 100% 4/4 [00:00<00:00,  4.89it/s, loss=0.00195, v_num=1, val_loss=0.000278, val_acc=1]\n",
            "Epoch 48:  75% 3/4 [00:00<00:00, 10.22it/s, loss=0.00184, v_num=1, val_loss=0.000278, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 48: 100% 4/4 [00:00<00:00,  6.13it/s, loss=0.00184, v_num=1, val_loss=0.000281, val_acc=1]\n",
            "Epoch 49:  75% 3/4 [00:00<00:00, 10.26it/s, loss=0.00168, v_num=1, val_loss=0.000281, val_acc=1]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 49: 100% 4/4 [00:00<00:00,  6.06it/s, loss=0.00168, v_num=1, val_loss=0.000675, val_acc=1]\n",
            "Epoch 49: 100% 4/4 [00:00<00:00,  5.23it/s, loss=0.00168, v_num=1, val_loss=0.000675, val_acc=1]\n",
            "Testing: 100% 2/2 [00:00<00:00,  5.56it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(1., device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using CNN + LSTM with CTC loss for line text recognition"
      ],
      "metadata": {
        "id": "gmMCYC8H2QGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/fsdl-text-recognizer-2021-labs/lab3/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZwBs0T92V_h",
        "outputId": "ce5191d8-b2ac-4dbb-fe9b-45ba62e1d358"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fsdl-text-recognizer-2021-labs/lab3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training/run_experiment.py --max_epochs=10 --gpus=1 --num_workers=4 --data_class=EMNISTLines --min_overlap=0 --max_overlap=0 --model_class=LineCNNSimple --window_width=28 --window_stride=28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G81mGhrK5Pw2",
        "outputId": "ea983e27-0c84-4eac-ab2a-959e039c225c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "EMNISTLinesDataset generating data for train...\n",
            "[nltk_data] Downloading package brown to /content/fsdl-text-\n",
            "[nltk_data]     recognizer-2021-labs/data/downloaded/nltk...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "EMNISTLinesDataset generating data for val...\n",
            "EMNISTLinesDataset generating data for test...\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "\n",
            "   | Name                 | Type          | Params\n",
            "--------------------------------------------------------\n",
            "0  | model                | LineCNNSimple | 1.7 M \n",
            "1  | model.cnn            | CNN           | 1.7 M \n",
            "2  | model.cnn.conv1      | ConvBlock     | 640   \n",
            "3  | model.cnn.conv1.conv | Conv2d        | 640   \n",
            "4  | model.cnn.conv1.relu | ReLU          | 0     \n",
            "5  | model.cnn.conv2      | ConvBlock     | 36.9 K\n",
            "6  | model.cnn.conv2.conv | Conv2d        | 36.9 K\n",
            "7  | model.cnn.conv2.relu | ReLU          | 0     \n",
            "8  | model.cnn.dropout    | Dropout       | 0     \n",
            "9  | model.cnn.max_pool   | MaxPool2d     | 0     \n",
            "10 | model.cnn.fc1        | Linear        | 1.6 M \n",
            "11 | model.cnn.fc2        | Linear        | 10.7 K\n",
            "12 | train_acc            | Accuracy      | 0     \n",
            "13 | val_acc              | Accuracy      | 0     \n",
            "14 | test_acc             | Accuracy      | 0     \n",
            "--------------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  83% 79/95 [00:45<00:09,  1.73it/s, loss=0.537, v_num=0, val_loss=4.46, val_acc=0.00708]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  85% 81/95 [00:46<00:07,  1.75it/s, loss=0.537, v_num=0, val_loss=4.46, val_acc=0.00708]\n",
            "Validating:  12% 2/16 [00:00<00:04,  3.11it/s]\u001b[A\n",
            "Epoch 0:  87% 83/95 [00:46<00:06,  1.78it/s, loss=0.537, v_num=0, val_loss=4.46, val_acc=0.00708]\n",
            "Validating:  25% 4/16 [00:01<00:02,  4.26it/s]\u001b[A\n",
            "Epoch 0:  89% 85/95 [00:46<00:05,  1.81it/s, loss=0.537, v_num=0, val_loss=4.46, val_acc=0.00708]\n",
            "Validating:  38% 6/16 [00:01<00:02,  4.75it/s]\u001b[A\n",
            "Epoch 0:  92% 87/95 [00:47<00:04,  1.84it/s, loss=0.537, v_num=0, val_loss=4.46, val_acc=0.00708]\n",
            "Validating:  50% 8/16 [00:01<00:01,  4.99it/s]\u001b[A\n",
            "Epoch 0:  94% 89/95 [00:47<00:03,  1.87it/s, loss=0.537, v_num=0, val_loss=4.46, val_acc=0.00708]\n",
            "Validating:  62% 10/16 [00:02<00:01,  5.08it/s]\u001b[A\n",
            "Epoch 0:  96% 91/95 [00:48<00:02,  1.89it/s, loss=0.537, v_num=0, val_loss=4.46, val_acc=0.00708]\n",
            "Validating:  75% 12/16 [00:02<00:00,  5.14it/s]\u001b[A\n",
            "Epoch 0:  98% 93/95 [00:48<00:01,  1.92it/s, loss=0.537, v_num=0, val_loss=4.46, val_acc=0.00708]\n",
            "Validating:  88% 14/16 [00:03<00:00,  5.12it/s]\u001b[A\n",
            "Epoch 0: 100% 95/95 [00:48<00:00,  1.94it/s, loss=0.537, v_num=0, val_loss=4.46, val_acc=0.00708]\n",
            "Epoch 0: 100% 95/95 [00:49<00:00,  1.93it/s, loss=0.537, v_num=0, val_loss=0.494, val_acc=0.717] \n",
            "Epoch 1:  84% 80/95 [00:46<00:08,  1.73it/s, loss=0.398, v_num=0, val_loss=0.494, val_acc=0.717]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:07,  1.97it/s]\u001b[A\n",
            "Epoch 1:  86% 82/95 [00:46<00:07,  1.75it/s, loss=0.398, v_num=0, val_loss=0.494, val_acc=0.717]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.77it/s]\u001b[A\n",
            "Epoch 1:  88% 84/95 [00:47<00:06,  1.78it/s, loss=0.398, v_num=0, val_loss=0.494, val_acc=0.717]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.43it/s]\u001b[A\n",
            "Epoch 1:  91% 86/95 [00:47<00:04,  1.81it/s, loss=0.398, v_num=0, val_loss=0.494, val_acc=0.717]\n",
            "Validating:  44% 7/16 [00:01<00:01,  4.80it/s]\u001b[A\n",
            "Epoch 1:  93% 88/95 [00:48<00:03,  1.83it/s, loss=0.398, v_num=0, val_loss=0.494, val_acc=0.717]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.93it/s]\u001b[A\n",
            "Epoch 1:  95% 90/95 [00:48<00:02,  1.86it/s, loss=0.398, v_num=0, val_loss=0.494, val_acc=0.717]\n",
            "Validating:  69% 11/16 [00:02<00:00,  5.02it/s]\u001b[A\n",
            "Epoch 1:  97% 92/95 [00:48<00:01,  1.89it/s, loss=0.398, v_num=0, val_loss=0.494, val_acc=0.717]\n",
            "Validating:  81% 13/16 [00:02<00:00,  5.04it/s]\u001b[A\n",
            "Epoch 1:  99% 94/95 [00:49<00:00,  1.91it/s, loss=0.398, v_num=0, val_loss=0.494, val_acc=0.717]\n",
            "Validating:  94% 15/16 [00:03<00:00,  5.09it/s]\u001b[A\n",
            "Epoch 1: 100% 95/95 [00:49<00:00,  1.91it/s, loss=0.398, v_num=0, val_loss=0.381, val_acc=0.811]\n",
            "Epoch 2:  84% 80/95 [00:46<00:08,  1.72it/s, loss=0.357, v_num=0, val_loss=0.381, val_acc=0.811]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:08,  1.78it/s]\u001b[A\n",
            "Epoch 2:  86% 82/95 [00:47<00:07,  1.74it/s, loss=0.357, v_num=0, val_loss=0.381, val_acc=0.811]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.58it/s]\u001b[A\n",
            "Epoch 2:  88% 84/95 [00:47<00:06,  1.77it/s, loss=0.357, v_num=0, val_loss=0.381, val_acc=0.811]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.42it/s]\u001b[A\n",
            "Epoch 2:  91% 86/95 [00:47<00:05,  1.79it/s, loss=0.357, v_num=0, val_loss=0.381, val_acc=0.811]\n",
            "Validating:  44% 7/16 [00:01<00:01,  4.69it/s]\u001b[A\n",
            "Epoch 2:  93% 88/95 [00:48<00:03,  1.82it/s, loss=0.357, v_num=0, val_loss=0.381, val_acc=0.811]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.95it/s]\u001b[A\n",
            "Epoch 2:  95% 90/95 [00:48<00:02,  1.85it/s, loss=0.357, v_num=0, val_loss=0.381, val_acc=0.811]\n",
            "Validating:  69% 11/16 [00:02<00:01,  4.96it/s]\u001b[A\n",
            "Epoch 2:  97% 92/95 [00:49<00:01,  1.87it/s, loss=0.357, v_num=0, val_loss=0.381, val_acc=0.811]\n",
            "Validating:  81% 13/16 [00:02<00:00,  5.08it/s]\u001b[A\n",
            "Epoch 2:  99% 94/95 [00:49<00:00,  1.90it/s, loss=0.357, v_num=0, val_loss=0.381, val_acc=0.811]\n",
            "Validating:  94% 15/16 [00:03<00:00,  5.04it/s]\u001b[A\n",
            "Epoch 2: 100% 95/95 [00:50<00:00,  1.89it/s, loss=0.357, v_num=0, val_loss=0.347, val_acc=0.823]\n",
            "Epoch 3:  84% 80/95 [00:46<00:08,  1.73it/s, loss=0.339, v_num=0, val_loss=0.347, val_acc=0.823]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:09,  1.56it/s]\u001b[A\n",
            "Epoch 3:  86% 82/95 [00:47<00:07,  1.74it/s, loss=0.339, v_num=0, val_loss=0.347, val_acc=0.823]\n",
            "Validating:  19% 3/16 [00:01<00:03,  3.38it/s]\u001b[A\n",
            "Epoch 3:  88% 84/95 [00:47<00:06,  1.77it/s, loss=0.339, v_num=0, val_loss=0.347, val_acc=0.823]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.27it/s]\u001b[A\n",
            "Epoch 3:  91% 86/95 [00:47<00:05,  1.80it/s, loss=0.339, v_num=0, val_loss=0.347, val_acc=0.823]\n",
            "Validating:  44% 7/16 [00:01<00:01,  4.69it/s]\u001b[A\n",
            "Epoch 3:  93% 88/95 [00:48<00:03,  1.82it/s, loss=0.339, v_num=0, val_loss=0.347, val_acc=0.823]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.89it/s]\u001b[A\n",
            "Epoch 3:  95% 90/95 [00:48<00:02,  1.85it/s, loss=0.339, v_num=0, val_loss=0.347, val_acc=0.823]\n",
            "Validating:  69% 11/16 [00:02<00:01,  4.98it/s]\u001b[A\n",
            "Epoch 3:  97% 92/95 [00:49<00:01,  1.87it/s, loss=0.339, v_num=0, val_loss=0.347, val_acc=0.823]\n",
            "Validating:  81% 13/16 [00:02<00:00,  5.04it/s]\u001b[A\n",
            "Epoch 3:  99% 94/95 [00:49<00:00,  1.90it/s, loss=0.339, v_num=0, val_loss=0.347, val_acc=0.823]\n",
            "Validating:  94% 15/16 [00:03<00:00,  5.05it/s]\u001b[A\n",
            "Epoch 3: 100% 95/95 [00:50<00:00,  1.90it/s, loss=0.339, v_num=0, val_loss=0.339, val_acc=0.827]\n",
            "Epoch 4:  84% 80/95 [00:46<00:08,  1.73it/s, loss=0.325, v_num=0, val_loss=0.339, val_acc=0.827]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:08,  1.77it/s]\u001b[A\n",
            "Epoch 4:  86% 82/95 [00:47<00:07,  1.74it/s, loss=0.325, v_num=0, val_loss=0.339, val_acc=0.827]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.64it/s]\u001b[A\n",
            "Epoch 4:  88% 84/95 [00:47<00:06,  1.77it/s, loss=0.325, v_num=0, val_loss=0.339, val_acc=0.827]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.38it/s]\u001b[A\n",
            "Epoch 4:  91% 86/95 [00:47<00:05,  1.80it/s, loss=0.325, v_num=0, val_loss=0.339, val_acc=0.827]\n",
            "Validating:  44% 7/16 [00:01<00:01,  4.79it/s]\u001b[A\n",
            "Epoch 4:  93% 88/95 [00:48<00:03,  1.82it/s, loss=0.325, v_num=0, val_loss=0.339, val_acc=0.827]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.91it/s]\u001b[A\n",
            "Epoch 4:  95% 90/95 [00:48<00:02,  1.85it/s, loss=0.325, v_num=0, val_loss=0.339, val_acc=0.827]\n",
            "Validating:  69% 11/16 [00:02<00:00,  5.05it/s]\u001b[A\n",
            "Epoch 4:  97% 92/95 [00:49<00:01,  1.88it/s, loss=0.325, v_num=0, val_loss=0.339, val_acc=0.827]\n",
            "Validating:  81% 13/16 [00:02<00:00,  5.03it/s]\u001b[A\n",
            "Epoch 4:  99% 94/95 [00:49<00:00,  1.90it/s, loss=0.325, v_num=0, val_loss=0.339, val_acc=0.827]\n",
            "Validating:  94% 15/16 [00:03<00:00,  5.10it/s]\u001b[A\n",
            "Epoch 4: 100% 95/95 [00:50<00:00,  1.90it/s, loss=0.325, v_num=0, val_loss=0.323, val_acc=0.826]\n",
            "Epoch 5:  84% 80/95 [00:45<00:08,  1.74it/s, loss=0.315, v_num=0, val_loss=0.323, val_acc=0.826]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:07,  2.05it/s]\u001b[A\n",
            "Epoch 5:  86% 82/95 [00:46<00:07,  1.76it/s, loss=0.315, v_num=0, val_loss=0.323, val_acc=0.826]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.75it/s]\u001b[A\n",
            "Epoch 5:  88% 84/95 [00:46<00:06,  1.79it/s, loss=0.315, v_num=0, val_loss=0.323, val_acc=0.826]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.45it/s]\u001b[A\n",
            "Epoch 5:  91% 86/95 [00:47<00:04,  1.82it/s, loss=0.315, v_num=0, val_loss=0.323, val_acc=0.826]\n",
            "Validating:  44% 7/16 [00:01<00:01,  4.81it/s]\u001b[A\n",
            "Epoch 5:  93% 88/95 [00:47<00:03,  1.84it/s, loss=0.315, v_num=0, val_loss=0.323, val_acc=0.826]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.95it/s]\u001b[A\n",
            "Epoch 5:  95% 90/95 [00:48<00:02,  1.87it/s, loss=0.315, v_num=0, val_loss=0.323, val_acc=0.826]\n",
            "Validating:  69% 11/16 [00:02<00:00,  5.06it/s]\u001b[A\n",
            "Epoch 5:  97% 92/95 [00:48<00:01,  1.90it/s, loss=0.315, v_num=0, val_loss=0.323, val_acc=0.826]\n",
            "Validating:  81% 13/16 [00:02<00:00,  5.08it/s]\u001b[A\n",
            "Epoch 5:  99% 94/95 [00:48<00:00,  1.92it/s, loss=0.315, v_num=0, val_loss=0.323, val_acc=0.826]\n",
            "Validating:  94% 15/16 [00:03<00:00,  5.11it/s]\u001b[A\n",
            "Epoch 5: 100% 95/95 [00:49<00:00,  1.92it/s, loss=0.315, v_num=0, val_loss=0.32, val_acc=0.827] \n",
            "Epoch 6:  84% 80/95 [00:45<00:08,  1.75it/s, loss=0.309, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:07,  1.89it/s]\u001b[A\n",
            "Epoch 6:  86% 82/95 [00:46<00:07,  1.76it/s, loss=0.309, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.71it/s]\u001b[A\n",
            "Epoch 6:  88% 84/95 [00:46<00:06,  1.79it/s, loss=0.309, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.50it/s]\u001b[A\n",
            "Epoch 6:  91% 86/95 [00:47<00:04,  1.82it/s, loss=0.309, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Validating:  44% 7/16 [00:01<00:01,  4.78it/s]\u001b[A\n",
            "Epoch 6:  93% 88/95 [00:47<00:03,  1.85it/s, loss=0.309, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Validating:  56% 9/16 [00:02<00:01,  5.00it/s]\u001b[A\n",
            "Epoch 6:  95% 90/95 [00:48<00:02,  1.87it/s, loss=0.309, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Validating:  69% 11/16 [00:02<00:00,  5.03it/s]\u001b[A\n",
            "Epoch 6:  97% 92/95 [00:48<00:01,  1.90it/s, loss=0.309, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Validating:  81% 13/16 [00:02<00:00,  5.12it/s]\u001b[A\n",
            "Epoch 6:  99% 94/95 [00:48<00:00,  1.92it/s, loss=0.309, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Validating:  94% 15/16 [00:03<00:00,  5.08it/s]\u001b[A\n",
            "Epoch 6: 100% 95/95 [00:49<00:00,  1.92it/s, loss=0.309, v_num=0, val_loss=0.317, val_acc=0.828]\n",
            "Epoch 7:  84% 80/95 [00:45<00:08,  1.75it/s, loss=0.303, v_num=0, val_loss=0.317, val_acc=0.828]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:07,  1.93it/s]\u001b[A\n",
            "Epoch 7:  86% 82/95 [00:46<00:07,  1.77it/s, loss=0.303, v_num=0, val_loss=0.317, val_acc=0.828]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.75it/s]\u001b[A\n",
            "Epoch 7:  88% 84/95 [00:46<00:06,  1.80it/s, loss=0.303, v_num=0, val_loss=0.317, val_acc=0.828]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.51it/s]\u001b[A\n",
            "Epoch 7:  91% 86/95 [00:47<00:04,  1.82it/s, loss=0.303, v_num=0, val_loss=0.317, val_acc=0.828]\n",
            "Validating:  44% 7/16 [00:01<00:01,  4.82it/s]\u001b[A\n",
            "Epoch 7:  93% 88/95 [00:47<00:03,  1.85it/s, loss=0.303, v_num=0, val_loss=0.317, val_acc=0.828]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.98it/s]\u001b[A\n",
            "Epoch 7:  95% 90/95 [00:47<00:02,  1.88it/s, loss=0.303, v_num=0, val_loss=0.317, val_acc=0.828]\n",
            "Validating:  69% 11/16 [00:02<00:00,  5.04it/s]\u001b[A\n",
            "Epoch 7:  97% 92/95 [00:48<00:01,  1.90it/s, loss=0.303, v_num=0, val_loss=0.317, val_acc=0.828]\n",
            "Validating:  81% 13/16 [00:02<00:00,  5.10it/s]\u001b[A\n",
            "Epoch 7:  99% 94/95 [00:48<00:00,  1.93it/s, loss=0.303, v_num=0, val_loss=0.317, val_acc=0.828]\n",
            "Validating:  94% 15/16 [00:03<00:00,  5.09it/s]\u001b[A\n",
            "Epoch 7: 100% 95/95 [00:49<00:00,  1.93it/s, loss=0.303, v_num=0, val_loss=0.311, val_acc=0.824]\n",
            "Epoch 8:  84% 80/95 [00:45<00:08,  1.75it/s, loss=0.299, v_num=0, val_loss=0.311, val_acc=0.824]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:08,  1.71it/s]\u001b[A\n",
            "Epoch 8:  86% 82/95 [00:46<00:07,  1.76it/s, loss=0.299, v_num=0, val_loss=0.311, val_acc=0.824]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.59it/s]\u001b[A\n",
            "Epoch 8:  88% 84/95 [00:46<00:06,  1.79it/s, loss=0.299, v_num=0, val_loss=0.311, val_acc=0.824]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.36it/s]\u001b[A\n",
            "Epoch 8:  91% 86/95 [00:47<00:04,  1.82it/s, loss=0.299, v_num=0, val_loss=0.311, val_acc=0.824]\n",
            "Validating:  44% 7/16 [00:01<00:01,  4.79it/s]\u001b[A\n",
            "Epoch 8:  93% 88/95 [00:47<00:03,  1.85it/s, loss=0.299, v_num=0, val_loss=0.311, val_acc=0.824]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.90it/s]\u001b[A\n",
            "Epoch 8:  95% 90/95 [00:48<00:02,  1.87it/s, loss=0.299, v_num=0, val_loss=0.311, val_acc=0.824]\n",
            "Validating:  69% 11/16 [00:02<00:00,  5.05it/s]\u001b[A\n",
            "Epoch 8:  97% 92/95 [00:48<00:01,  1.90it/s, loss=0.299, v_num=0, val_loss=0.311, val_acc=0.824]\n",
            "Validating:  81% 13/16 [00:02<00:00,  5.02it/s]\u001b[A\n",
            "Epoch 8:  99% 94/95 [00:48<00:00,  1.93it/s, loss=0.299, v_num=0, val_loss=0.311, val_acc=0.824]\n",
            "Validating:  94% 15/16 [00:03<00:00,  5.10it/s]\u001b[A\n",
            "Epoch 8: 100% 95/95 [00:49<00:00,  1.92it/s, loss=0.299, v_num=0, val_loss=0.306, val_acc=0.819]\n",
            "Epoch 9:  84% 80/95 [00:45<00:08,  1.75it/s, loss=0.295, v_num=0, val_loss=0.306, val_acc=0.819]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:08,  1.69it/s]\u001b[A\n",
            "Epoch 9:  86% 82/95 [00:46<00:07,  1.77it/s, loss=0.295, v_num=0, val_loss=0.306, val_acc=0.819]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.55it/s]\u001b[A\n",
            "Epoch 9:  88% 84/95 [00:46<00:06,  1.79it/s, loss=0.295, v_num=0, val_loss=0.306, val_acc=0.819]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.36it/s]\u001b[A\n",
            "Epoch 9:  91% 86/95 [00:47<00:04,  1.82it/s, loss=0.295, v_num=0, val_loss=0.306, val_acc=0.819]\n",
            "Validating:  44% 7/16 [00:01<00:01,  4.76it/s]\u001b[A\n",
            "Epoch 9:  93% 88/95 [00:47<00:03,  1.85it/s, loss=0.295, v_num=0, val_loss=0.306, val_acc=0.819]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.93it/s]\u001b[A\n",
            "Epoch 9:  95% 90/95 [00:48<00:02,  1.87it/s, loss=0.295, v_num=0, val_loss=0.306, val_acc=0.819]\n",
            "Validating:  69% 11/16 [00:02<00:00,  5.03it/s]\u001b[A\n",
            "Epoch 9:  97% 92/95 [00:48<00:01,  1.90it/s, loss=0.295, v_num=0, val_loss=0.306, val_acc=0.819]\n",
            "Validating:  81% 13/16 [00:02<00:00,  5.08it/s]\u001b[A\n",
            "Epoch 9:  99% 94/95 [00:48<00:00,  1.93it/s, loss=0.295, v_num=0, val_loss=0.306, val_acc=0.819]\n",
            "Validating:  94% 15/16 [00:03<00:00,  5.10it/s]\u001b[A\n",
            "Epoch 9: 100% 95/95 [00:49<00:00,  1.92it/s, loss=0.295, v_num=0, val_loss=0.304, val_acc=0.816]\n",
            "Epoch 9: 100% 95/95 [00:49<00:00,  1.92it/s, loss=0.295, v_num=0, val_loss=0.304, val_acc=0.816]\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "Testing: 100% 16/16 [00:03<00:00,  4.39it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.8035, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training/run_experiment.py --max_epochs=10 --gpus=1 --num_workers=4 --data_class=EMNISTLines --min_overlap=0.25 --max_overlap=0.25 --model_class=LineCNNSimple --window_width=28 --window_stride=20 --limit_output_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtPw7UlO7qkV",
        "outputId": "088caef3-c6da-4d30-b92a-19c60919251b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "EMNISTLinesDataset generating data for train...\n",
            "EMNISTLinesDataset generating data for val...\n",
            "EMNISTLinesDataset generating data for test...\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "\n",
            "   | Name                 | Type          | Params\n",
            "--------------------------------------------------------\n",
            "0  | model                | LineCNNSimple | 1.7 M \n",
            "1  | model.cnn            | CNN           | 1.7 M \n",
            "2  | model.cnn.conv1      | ConvBlock     | 640   \n",
            "3  | model.cnn.conv1.conv | Conv2d        | 640   \n",
            "4  | model.cnn.conv1.relu | ReLU          | 0     \n",
            "5  | model.cnn.conv2      | ConvBlock     | 36.9 K\n",
            "6  | model.cnn.conv2.conv | Conv2d        | 36.9 K\n",
            "7  | model.cnn.conv2.relu | ReLU          | 0     \n",
            "8  | model.cnn.dropout    | Dropout       | 0     \n",
            "9  | model.cnn.max_pool   | MaxPool2d     | 0     \n",
            "10 | model.cnn.fc1        | Linear        | 1.6 M \n",
            "11 | model.cnn.fc2        | Linear        | 10.7 K\n",
            "12 | train_acc            | Accuracy      | 0     \n",
            "13 | val_acc              | Accuracy      | 0     \n",
            "14 | test_acc             | Accuracy      | 0     \n",
            "--------------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  83% 79/95 [01:01<00:12,  1.29it/s, loss=1.03, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  85% 81/95 [01:01<00:10,  1.31it/s, loss=1.03, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  12% 2/16 [00:00<00:05,  2.49it/s]\u001b[A\n",
            "Epoch 0:  87% 83/95 [01:02<00:09,  1.33it/s, loss=1.03, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  25% 4/16 [00:01<00:03,  3.21it/s]\u001b[A\n",
            "Epoch 0:  89% 85/95 [01:02<00:07,  1.35it/s, loss=1.03, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  38% 6/16 [00:01<00:02,  3.50it/s]\u001b[A\n",
            "Epoch 0:  92% 87/95 [01:03<00:05,  1.37it/s, loss=1.03, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  50% 8/16 [00:02<00:02,  3.64it/s]\u001b[A\n",
            "Epoch 0:  94% 89/95 [01:03<00:04,  1.39it/s, loss=1.03, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  62% 10/16 [00:03<00:01,  3.70it/s]\u001b[A\n",
            "Epoch 0:  96% 91/95 [01:04<00:02,  1.41it/s, loss=1.03, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  75% 12/16 [00:03<00:01,  3.73it/s]\u001b[A\n",
            "Epoch 0:  98% 93/95 [01:04<00:01,  1.43it/s, loss=1.03, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  88% 14/16 [00:04<00:00,  3.75it/s]\u001b[A\n",
            "Epoch 0: 100% 95/95 [01:05<00:00,  1.45it/s, loss=1.03, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Epoch 0: 100% 95/95 [01:05<00:00,  1.44it/s, loss=1.03, v_num=1, val_loss=0.999, val_acc=0.518] \n",
            "Epoch 1:  84% 80/95 [01:01<00:11,  1.30it/s, loss=0.86, v_num=1, val_loss=0.999, val_acc=0.518]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:08,  1.68it/s]\u001b[A\n",
            "Epoch 1:  86% 82/95 [01:02<00:09,  1.32it/s, loss=0.86, v_num=1, val_loss=0.999, val_acc=0.518]\n",
            "Validating:  19% 3/16 [00:01<00:04,  2.95it/s]\u001b[A\n",
            "Epoch 1:  88% 84/95 [01:02<00:08,  1.34it/s, loss=0.86, v_num=1, val_loss=0.999, val_acc=0.518]\n",
            "Validating:  31% 5/16 [00:01<00:03,  3.41it/s]\u001b[A\n",
            "Epoch 1:  91% 86/95 [01:03<00:06,  1.36it/s, loss=0.86, v_num=1, val_loss=0.999, val_acc=0.518]\n",
            "Validating:  44% 7/16 [00:02<00:02,  3.58it/s]\u001b[A\n",
            "Epoch 1:  93% 88/95 [01:03<00:05,  1.38it/s, loss=0.86, v_num=1, val_loss=0.999, val_acc=0.518]\n",
            "Validating:  56% 9/16 [00:02<00:01,  3.67it/s]\u001b[A\n",
            "Epoch 1:  95% 90/95 [01:04<00:03,  1.40it/s, loss=0.86, v_num=1, val_loss=0.999, val_acc=0.518]\n",
            "Validating:  69% 11/16 [00:03<00:01,  3.71it/s]\u001b[A\n",
            "Epoch 1:  97% 92/95 [01:05<00:02,  1.41it/s, loss=0.86, v_num=1, val_loss=0.999, val_acc=0.518]\n",
            "Validating:  81% 13/16 [00:03<00:00,  3.73it/s]\u001b[A\n",
            "Epoch 1:  99% 94/95 [01:05<00:00,  1.43it/s, loss=0.86, v_num=1, val_loss=0.999, val_acc=0.518]\n",
            "Validating:  94% 15/16 [00:04<00:00,  3.75it/s]\u001b[A\n",
            "Epoch 1: 100% 95/95 [01:06<00:00,  1.43it/s, loss=0.86, v_num=1, val_loss=0.831, val_acc=0.499]\n",
            "Epoch 2:  84% 80/95 [01:01<00:11,  1.30it/s, loss=0.75, v_num=1, val_loss=0.831, val_acc=0.499]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:08,  1.84it/s]\u001b[A\n",
            "Epoch 2:  86% 82/95 [01:02<00:09,  1.32it/s, loss=0.75, v_num=1, val_loss=0.831, val_acc=0.499]\n",
            "Validating:  19% 3/16 [00:01<00:04,  3.04it/s]\u001b[A\n",
            "Epoch 2:  88% 84/95 [01:02<00:08,  1.34it/s, loss=0.75, v_num=1, val_loss=0.831, val_acc=0.499]\n",
            "Validating:  31% 5/16 [00:01<00:03,  3.44it/s]\u001b[A\n",
            "Epoch 2:  91% 86/95 [01:03<00:06,  1.36it/s, loss=0.75, v_num=1, val_loss=0.831, val_acc=0.499]\n",
            "Validating:  44% 7/16 [00:02<00:02,  3.60it/s]\u001b[A\n",
            "Epoch 2:  93% 88/95 [01:03<00:05,  1.38it/s, loss=0.75, v_num=1, val_loss=0.831, val_acc=0.499]\n",
            "Validating:  56% 9/16 [00:02<00:01,  3.67it/s]\u001b[A\n",
            "Epoch 2:  95% 90/95 [01:04<00:03,  1.40it/s, loss=0.75, v_num=1, val_loss=0.831, val_acc=0.499]\n",
            "Validating:  69% 11/16 [00:03<00:01,  3.72it/s]\u001b[A\n",
            "Epoch 2:  97% 92/95 [01:04<00:02,  1.42it/s, loss=0.75, v_num=1, val_loss=0.831, val_acc=0.499]\n",
            "Validating:  81% 13/16 [00:03<00:00,  3.74it/s]\u001b[A\n",
            "Epoch 2:  99% 94/95 [01:05<00:00,  1.44it/s, loss=0.75, v_num=1, val_loss=0.831, val_acc=0.499]\n",
            "Validating:  94% 15/16 [00:04<00:00,  3.76it/s]\u001b[A\n",
            "Epoch 2: 100% 95/95 [01:06<00:00,  1.44it/s, loss=0.75, v_num=1, val_loss=0.755, val_acc=0.553]\n",
            "Epoch 3:  84% 80/95 [01:01<00:11,  1.30it/s, loss=0.729, v_num=1, val_loss=0.755, val_acc=0.553]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:09,  1.52it/s]\u001b[A\n",
            "Epoch 3:  86% 82/95 [01:02<00:09,  1.32it/s, loss=0.729, v_num=1, val_loss=0.755, val_acc=0.553]\n",
            "Validating:  19% 3/16 [00:01<00:04,  2.83it/s]\u001b[A\n",
            "Epoch 3:  88% 84/95 [01:02<00:08,  1.34it/s, loss=0.729, v_num=1, val_loss=0.755, val_acc=0.553]\n",
            "Validating:  31% 5/16 [00:01<00:03,  3.31it/s]\u001b[A\n",
            "Epoch 3:  91% 86/95 [01:03<00:06,  1.36it/s, loss=0.729, v_num=1, val_loss=0.755, val_acc=0.553]\n",
            "Validating:  44% 7/16 [00:02<00:02,  3.55it/s]\u001b[A\n",
            "Epoch 3:  93% 88/95 [01:03<00:05,  1.38it/s, loss=0.729, v_num=1, val_loss=0.755, val_acc=0.553]\n",
            "Validating:  56% 9/16 [00:02<00:01,  3.65it/s]\u001b[A\n",
            "Epoch 3:  95% 90/95 [01:04<00:03,  1.40it/s, loss=0.729, v_num=1, val_loss=0.755, val_acc=0.553]\n",
            "Validating:  69% 11/16 [00:03<00:01,  3.70it/s]\u001b[A\n",
            "Epoch 3:  97% 92/95 [01:05<00:02,  1.42it/s, loss=0.729, v_num=1, val_loss=0.755, val_acc=0.553]\n",
            "Validating:  81% 13/16 [00:03<00:00,  3.73it/s]\u001b[A\n",
            "Epoch 3:  99% 94/95 [01:05<00:00,  1.43it/s, loss=0.729, v_num=1, val_loss=0.755, val_acc=0.553]\n",
            "Validating:  94% 15/16 [00:04<00:00,  3.75it/s]\u001b[A\n",
            "Epoch 3: 100% 95/95 [01:06<00:00,  1.43it/s, loss=0.729, v_num=1, val_loss=0.7, val_acc=0.504]  \n",
            "Epoch 4:  84% 80/95 [01:01<00:11,  1.30it/s, loss=0.681, v_num=1, val_loss=0.7, val_acc=0.504]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:10,  1.49it/s]\u001b[A\n",
            "Epoch 4:  86% 82/95 [01:02<00:09,  1.31it/s, loss=0.681, v_num=1, val_loss=0.7, val_acc=0.504]\n",
            "Validating:  19% 3/16 [00:01<00:04,  2.79it/s]\u001b[A\n",
            "Epoch 4:  88% 84/95 [01:03<00:08,  1.33it/s, loss=0.681, v_num=1, val_loss=0.7, val_acc=0.504]\n",
            "Validating:  31% 5/16 [00:01<00:03,  3.28it/s]\u001b[A\n",
            "Epoch 4:  91% 86/95 [01:03<00:06,  1.35it/s, loss=0.681, v_num=1, val_loss=0.7, val_acc=0.504]\n",
            "Validating:  44% 7/16 [00:02<00:02,  3.51it/s]\u001b[A\n",
            "Epoch 4:  93% 88/95 [01:04<00:05,  1.37it/s, loss=0.681, v_num=1, val_loss=0.7, val_acc=0.504]\n",
            "Validating:  56% 9/16 [00:02<00:01,  3.64it/s]\u001b[A\n",
            "Epoch 4:  95% 90/95 [01:04<00:03,  1.39it/s, loss=0.681, v_num=1, val_loss=0.7, val_acc=0.504]\n",
            "Validating:  69% 11/16 [00:03<00:01,  3.68it/s]\u001b[A\n",
            "Epoch 4:  97% 92/95 [01:05<00:02,  1.41it/s, loss=0.681, v_num=1, val_loss=0.7, val_acc=0.504]\n",
            "Validating:  81% 13/16 [00:03<00:00,  3.72it/s]\u001b[A\n",
            "Epoch 4:  99% 94/95 [01:05<00:00,  1.43it/s, loss=0.681, v_num=1, val_loss=0.7, val_acc=0.504]\n",
            "Validating:  94% 15/16 [00:04<00:00,  3.72it/s]\u001b[A\n",
            "Epoch 4: 100% 95/95 [01:06<00:00,  1.43it/s, loss=0.681, v_num=1, val_loss=0.668, val_acc=0.523]\n",
            "Epoch 5:  84% 80/95 [01:02<00:11,  1.29it/s, loss=0.654, v_num=1, val_loss=0.668, val_acc=0.523]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:08,  1.79it/s]\u001b[A\n",
            "Epoch 5:  86% 82/95 [01:02<00:09,  1.30it/s, loss=0.654, v_num=1, val_loss=0.668, val_acc=0.523]\n",
            "Validating:  19% 3/16 [00:01<00:04,  3.01it/s]\u001b[A\n",
            "Epoch 5:  88% 84/95 [01:03<00:08,  1.32it/s, loss=0.654, v_num=1, val_loss=0.668, val_acc=0.523]\n",
            "Validating:  31% 5/16 [00:01<00:03,  3.43it/s]\u001b[A\n",
            "Epoch 5:  91% 86/95 [01:04<00:06,  1.34it/s, loss=0.654, v_num=1, val_loss=0.668, val_acc=0.523]\n",
            "Validating:  44% 7/16 [00:02<00:02,  3.61it/s]\u001b[A\n",
            "Epoch 5:  93% 88/95 [01:04<00:05,  1.36it/s, loss=0.654, v_num=1, val_loss=0.668, val_acc=0.523]\n",
            "Validating:  56% 9/16 [00:02<00:01,  3.69it/s]\u001b[A\n",
            "Epoch 5:  95% 90/95 [01:05<00:03,  1.38it/s, loss=0.654, v_num=1, val_loss=0.668, val_acc=0.523]\n",
            "Validating:  69% 11/16 [00:03<00:01,  3.72it/s]\u001b[A\n",
            "Epoch 5:  97% 92/95 [01:05<00:02,  1.40it/s, loss=0.654, v_num=1, val_loss=0.668, val_acc=0.523]\n",
            "Validating:  81% 13/16 [00:03<00:00,  3.72it/s]\u001b[A\n",
            "Epoch 5:  99% 94/95 [01:06<00:00,  1.42it/s, loss=0.654, v_num=1, val_loss=0.668, val_acc=0.523]\n",
            "Validating:  94% 15/16 [00:04<00:00,  3.73it/s]\u001b[A\n",
            "Epoch 5: 100% 95/95 [01:06<00:00,  1.42it/s, loss=0.654, v_num=1, val_loss=0.645, val_acc=0.597]\n",
            "Epoch 6:  84% 80/95 [01:01<00:11,  1.30it/s, loss=0.637, v_num=1, val_loss=0.645, val_acc=0.597]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:09,  1.59it/s]\u001b[A\n",
            "Epoch 6:  86% 82/95 [01:02<00:09,  1.31it/s, loss=0.637, v_num=1, val_loss=0.645, val_acc=0.597]\n",
            "Validating:  19% 3/16 [00:01<00:04,  2.86it/s]\u001b[A\n",
            "Epoch 6:  88% 84/95 [01:03<00:08,  1.33it/s, loss=0.637, v_num=1, val_loss=0.645, val_acc=0.597]\n",
            "Validating:  31% 5/16 [00:01<00:03,  3.33it/s]\u001b[A\n",
            "Epoch 6:  91% 86/95 [01:03<00:06,  1.35it/s, loss=0.637, v_num=1, val_loss=0.645, val_acc=0.597]\n",
            "Validating:  44% 7/16 [00:02<00:02,  3.52it/s]\u001b[A\n",
            "Epoch 6:  93% 88/95 [01:04<00:05,  1.37it/s, loss=0.637, v_num=1, val_loss=0.645, val_acc=0.597]\n",
            "Validating:  56% 9/16 [00:02<00:01,  3.63it/s]\u001b[A\n",
            "Epoch 6:  95% 90/95 [01:04<00:03,  1.39it/s, loss=0.637, v_num=1, val_loss=0.645, val_acc=0.597]\n",
            "Validating:  69% 11/16 [00:03<00:01,  3.69it/s]\u001b[A\n",
            "Epoch 6:  97% 92/95 [01:05<00:02,  1.41it/s, loss=0.637, v_num=1, val_loss=0.645, val_acc=0.597]\n",
            "Validating:  81% 13/16 [00:03<00:00,  3.71it/s]\u001b[A\n",
            "Epoch 6:  99% 94/95 [01:05<00:00,  1.43it/s, loss=0.637, v_num=1, val_loss=0.645, val_acc=0.597]\n",
            "Validating:  94% 15/16 [00:04<00:00,  3.71it/s]\u001b[A\n",
            "Epoch 6: 100% 95/95 [01:06<00:00,  1.43it/s, loss=0.637, v_num=1, val_loss=0.626, val_acc=0.574]\n",
            "Epoch 7:  84% 80/95 [01:02<00:11,  1.29it/s, loss=0.617, v_num=1, val_loss=0.626, val_acc=0.574]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:10,  1.48it/s]\u001b[A\n",
            "Epoch 7:  86% 82/95 [01:03<00:09,  1.30it/s, loss=0.617, v_num=1, val_loss=0.626, val_acc=0.574]\n",
            "Validating:  19% 3/16 [00:01<00:04,  2.79it/s]\u001b[A\n",
            "Epoch 7:  88% 84/95 [01:03<00:08,  1.32it/s, loss=0.617, v_num=1, val_loss=0.626, val_acc=0.574]\n",
            "Validating:  31% 5/16 [00:01<00:03,  3.29it/s]\u001b[A\n",
            "Epoch 7:  91% 86/95 [01:04<00:06,  1.34it/s, loss=0.617, v_num=1, val_loss=0.626, val_acc=0.574]\n",
            "Validating:  44% 7/16 [00:02<00:02,  3.53it/s]\u001b[A\n",
            "Epoch 7:  93% 88/95 [01:04<00:05,  1.36it/s, loss=0.617, v_num=1, val_loss=0.626, val_acc=0.574]\n",
            "Validating:  56% 9/16 [00:02<00:01,  3.64it/s]\u001b[A\n",
            "Epoch 7:  95% 90/95 [01:05<00:03,  1.38it/s, loss=0.617, v_num=1, val_loss=0.626, val_acc=0.574]\n",
            "Validating:  69% 11/16 [00:03<00:01,  3.70it/s]\u001b[A\n",
            "Epoch 7:  97% 92/95 [01:05<00:02,  1.40it/s, loss=0.617, v_num=1, val_loss=0.626, val_acc=0.574]\n",
            "Validating:  81% 13/16 [00:03<00:00,  3.72it/s]\u001b[A\n",
            "Epoch 7:  99% 94/95 [01:06<00:00,  1.42it/s, loss=0.617, v_num=1, val_loss=0.626, val_acc=0.574]\n",
            "Validating:  94% 15/16 [00:04<00:00,  3.74it/s]\u001b[A\n",
            "Epoch 7: 100% 95/95 [01:07<00:00,  1.42it/s, loss=0.617, v_num=1, val_loss=0.613, val_acc=0.581]\n",
            "Epoch 8:  84% 80/95 [01:02<00:11,  1.29it/s, loss=0.59, v_num=1, val_loss=0.613, val_acc=0.581]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:08,  1.70it/s]\u001b[A\n",
            "Epoch 8:  86% 82/95 [01:02<00:09,  1.30it/s, loss=0.59, v_num=1, val_loss=0.613, val_acc=0.581]\n",
            "Validating:  19% 3/16 [00:01<00:04,  2.94it/s]\u001b[A\n",
            "Epoch 8:  88% 84/95 [01:03<00:08,  1.32it/s, loss=0.59, v_num=1, val_loss=0.613, val_acc=0.581]\n",
            "Validating:  31% 5/16 [00:01<00:03,  3.38it/s]\u001b[A\n",
            "Epoch 8:  91% 86/95 [01:03<00:06,  1.34it/s, loss=0.59, v_num=1, val_loss=0.613, val_acc=0.581]\n",
            "Validating:  44% 7/16 [00:02<00:02,  3.58it/s]\u001b[A\n",
            "Epoch 8:  93% 88/95 [01:04<00:05,  1.36it/s, loss=0.59, v_num=1, val_loss=0.613, val_acc=0.581]\n",
            "Validating:  56% 9/16 [00:02<00:01,  3.67it/s]\u001b[A\n",
            "Epoch 8:  95% 90/95 [01:05<00:03,  1.38it/s, loss=0.59, v_num=1, val_loss=0.613, val_acc=0.581]\n",
            "Validating:  69% 11/16 [00:03<00:01,  3.70it/s]\u001b[A\n",
            "Epoch 8:  97% 92/95 [01:05<00:02,  1.40it/s, loss=0.59, v_num=1, val_loss=0.613, val_acc=0.581]\n",
            "Validating:  81% 13/16 [00:03<00:00,  3.72it/s]\u001b[A\n",
            "Epoch 8:  99% 94/95 [01:06<00:00,  1.42it/s, loss=0.59, v_num=1, val_loss=0.613, val_acc=0.581]\n",
            "Validating:  94% 15/16 [00:04<00:00,  3.73it/s]\u001b[A\n",
            "Epoch 8: 100% 95/95 [01:06<00:00,  1.42it/s, loss=0.59, v_num=1, val_loss=0.605, val_acc=0.597]\n",
            "Epoch 9:  84% 80/95 [01:01<00:11,  1.29it/s, loss=0.57, v_num=1, val_loss=0.605, val_acc=0.597]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:09,  1.60it/s]\u001b[A\n",
            "Epoch 9:  86% 82/95 [01:02<00:09,  1.31it/s, loss=0.57, v_num=1, val_loss=0.605, val_acc=0.597]\n",
            "Validating:  19% 3/16 [00:01<00:04,  2.87it/s]\u001b[A\n",
            "Epoch 9:  88% 84/95 [01:03<00:08,  1.33it/s, loss=0.57, v_num=1, val_loss=0.605, val_acc=0.597]\n",
            "Validating:  31% 5/16 [00:01<00:03,  3.34it/s]\u001b[A\n",
            "Epoch 9:  91% 86/95 [01:03<00:06,  1.35it/s, loss=0.57, v_num=1, val_loss=0.605, val_acc=0.597]\n",
            "Validating:  44% 7/16 [00:02<00:02,  3.54it/s]\u001b[A\n",
            "Epoch 9:  93% 88/95 [01:04<00:05,  1.37it/s, loss=0.57, v_num=1, val_loss=0.605, val_acc=0.597]\n",
            "Validating:  56% 9/16 [00:02<00:01,  3.65it/s]\u001b[A\n",
            "Epoch 9:  95% 90/95 [01:04<00:03,  1.39it/s, loss=0.57, v_num=1, val_loss=0.605, val_acc=0.597]\n",
            "Validating:  69% 11/16 [00:03<00:01,  3.69it/s]\u001b[A\n",
            "Epoch 9:  97% 92/95 [01:05<00:02,  1.40it/s, loss=0.57, v_num=1, val_loss=0.605, val_acc=0.597]\n",
            "Validating:  81% 13/16 [00:03<00:00,  3.72it/s]\u001b[A\n",
            "Epoch 9:  99% 94/95 [01:06<00:00,  1.42it/s, loss=0.57, v_num=1, val_loss=0.605, val_acc=0.597]\n",
            "Validating:  94% 15/16 [00:04<00:00,  3.73it/s]\u001b[A\n",
            "Epoch 9: 100% 95/95 [01:06<00:00,  1.42it/s, loss=0.57, v_num=1, val_loss=0.594, val_acc=0.521]\n",
            "Epoch 9: 100% 95/95 [01:06<00:00,  1.42it/s, loss=0.57, v_num=1, val_loss=0.594, val_acc=0.521]\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "Testing: 100% 16/16 [00:04<00:00,  3.32it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.5098, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training/run_experiment.py --max_epochs=10 --gpus=1 --num_workers=4 --data_class=EMNISTLines --min_overlap=0.25 --max_overlap=0.25 --model_class=LineCNN --window_width=28 --window_stride=20 --limit_output_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqnjubaR-tiL",
        "outputId": "1ae2c4f5-93bf-4672-8f92-5b3bdc52c8fc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "\n",
            "   | Name               | Type       | Params\n",
            "---------------------------------------------------\n",
            "0  | model              | LineCNN    | 1.2 M \n",
            "1  | model.convs        | Sequential | 895 K \n",
            "2  | model.convs.0      | ConvBlock  | 320   \n",
            "3  | model.convs.0.conv | Conv2d     | 320   \n",
            "4  | model.convs.0.relu | ReLU       | 0     \n",
            "5  | model.convs.1      | ConvBlock  | 9.2 K \n",
            "6  | model.convs.1.conv | Conv2d     | 9.2 K \n",
            "7  | model.convs.1.relu | ReLU       | 0     \n",
            "8  | model.convs.2      | ConvBlock  | 9.2 K \n",
            "9  | model.convs.2.conv | Conv2d     | 9.2 K \n",
            "10 | model.convs.2.relu | ReLU       | 0     \n",
            "11 | model.convs.3      | ConvBlock  | 9.2 K \n",
            "12 | model.convs.3.conv | Conv2d     | 9.2 K \n",
            "13 | model.convs.3.relu | ReLU       | 0     \n",
            "14 | model.convs.4      | ConvBlock  | 18.5 K\n",
            "15 | model.convs.4.conv | Conv2d     | 18.5 K\n",
            "16 | model.convs.4.relu | ReLU       | 0     \n",
            "17 | model.convs.5      | ConvBlock  | 36.9 K\n",
            "18 | model.convs.5.conv | Conv2d     | 36.9 K\n",
            "19 | model.convs.5.relu | ReLU       | 0     \n",
            "20 | model.convs.6      | ConvBlock  | 73.9 K\n",
            "21 | model.convs.6.conv | Conv2d     | 73.9 K\n",
            "22 | model.convs.6.relu | ReLU       | 0     \n",
            "23 | model.convs.7      | ConvBlock  | 147 K \n",
            "24 | model.convs.7.conv | Conv2d     | 147 K \n",
            "25 | model.convs.7.relu | ReLU       | 0     \n",
            "26 | model.convs.8      | ConvBlock  | 590 K \n",
            "27 | model.convs.8.conv | Conv2d     | 590 K \n",
            "28 | model.convs.8.relu | ReLU       | 0     \n",
            "29 | model.fc1          | Linear     | 262 K \n",
            "30 | model.dropout      | Dropout    | 0     \n",
            "31 | model.fc2          | Linear     | 42.6 K\n",
            "32 | train_acc          | Accuracy   | 0     \n",
            "33 | val_acc            | Accuracy   | 0     \n",
            "34 | test_acc           | Accuracy   | 0     \n",
            "---------------------------------------------------\n",
            "1.2 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.2 M     Total params\n",
            "Epoch 0:  83% 79/95 [00:59<00:12,  1.33it/s, loss=1.79, v_num=2, val_loss=4.44, val_acc=0.0072]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  85% 81/95 [00:59<00:10,  1.35it/s, loss=1.79, v_num=2, val_loss=4.44, val_acc=0.0072]\n",
            "Validating:  12% 2/16 [00:00<00:04,  2.99it/s]\u001b[A\n",
            "Epoch 0:  87% 83/95 [01:00<00:08,  1.38it/s, loss=1.79, v_num=2, val_loss=4.44, val_acc=0.0072]\n",
            "Validating:  25% 4/16 [00:01<00:03,  3.83it/s]\u001b[A\n",
            "Epoch 0:  89% 85/95 [01:00<00:07,  1.40it/s, loss=1.79, v_num=2, val_loss=4.44, val_acc=0.0072]\n",
            "Validating:  38% 6/16 [00:01<00:02,  4.25it/s]\u001b[A\n",
            "Epoch 0:  92% 87/95 [01:01<00:05,  1.42it/s, loss=1.79, v_num=2, val_loss=4.44, val_acc=0.0072]\n",
            "Validating:  50% 8/16 [00:02<00:01,  4.38it/s]\u001b[A\n",
            "Epoch 0:  94% 89/95 [01:01<00:04,  1.45it/s, loss=1.79, v_num=2, val_loss=4.44, val_acc=0.0072]\n",
            "Validating:  62% 10/16 [00:02<00:01,  4.49it/s]\u001b[A\n",
            "Epoch 0:  96% 91/95 [01:02<00:02,  1.47it/s, loss=1.79, v_num=2, val_loss=4.44, val_acc=0.0072]\n",
            "Validating:  75% 12/16 [00:02<00:00,  4.56it/s]\u001b[A\n",
            "Epoch 0:  98% 93/95 [01:02<00:01,  1.49it/s, loss=1.79, v_num=2, val_loss=4.44, val_acc=0.0072]\n",
            "Validating:  88% 14/16 [00:03<00:00,  4.57it/s]\u001b[A\n",
            "Epoch 0: 100% 95/95 [01:02<00:00,  1.51it/s, loss=1.79, v_num=2, val_loss=4.44, val_acc=0.0072]\n",
            "Epoch 0: 100% 95/95 [01:03<00:00,  1.50it/s, loss=1.79, v_num=2, val_loss=1.74, val_acc=0.366] \n",
            "Epoch 1:  84% 80/95 [01:00<00:11,  1.33it/s, loss=1.69, v_num=2, val_loss=1.74, val_acc=0.366]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:08,  1.87it/s]\u001b[A\n",
            "Epoch 1:  86% 82/95 [01:00<00:09,  1.35it/s, loss=1.69, v_num=2, val_loss=1.74, val_acc=0.366]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.47it/s]\u001b[A\n",
            "Epoch 1:  88% 84/95 [01:01<00:08,  1.37it/s, loss=1.69, v_num=2, val_loss=1.74, val_acc=0.366]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.05it/s]\u001b[A\n",
            "Epoch 1:  91% 86/95 [01:01<00:06,  1.39it/s, loss=1.69, v_num=2, val_loss=1.74, val_acc=0.366]\n",
            "Validating:  44% 7/16 [00:01<00:02,  4.33it/s]\u001b[A\n",
            "Epoch 1:  93% 88/95 [01:02<00:04,  1.41it/s, loss=1.69, v_num=2, val_loss=1.74, val_acc=0.366]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.47it/s]\u001b[A\n",
            "Epoch 1:  95% 90/95 [01:02<00:03,  1.44it/s, loss=1.69, v_num=2, val_loss=1.74, val_acc=0.366]\n",
            "Validating:  69% 11/16 [00:02<00:01,  4.53it/s]\u001b[A\n",
            "Epoch 1:  97% 92/95 [01:03<00:02,  1.46it/s, loss=1.69, v_num=2, val_loss=1.74, val_acc=0.366]\n",
            "Validating:  81% 13/16 [00:03<00:00,  4.55it/s]\u001b[A\n",
            "Epoch 1:  99% 94/95 [01:03<00:00,  1.48it/s, loss=1.69, v_num=2, val_loss=1.74, val_acc=0.366]\n",
            "Validating:  94% 15/16 [00:03<00:00,  4.60it/s]\u001b[A\n",
            "Epoch 1: 100% 95/95 [01:04<00:00,  1.48it/s, loss=1.69, v_num=2, val_loss=1.65, val_acc=0.372]\n",
            "Epoch 2:  84% 80/95 [01:00<00:11,  1.32it/s, loss=1.58, v_num=2, val_loss=1.65, val_acc=0.372]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:08,  1.76it/s]\u001b[A\n",
            "Epoch 2:  86% 82/95 [01:01<00:09,  1.34it/s, loss=1.58, v_num=2, val_loss=1.65, val_acc=0.372]\n",
            "Validating:  19% 3/16 [00:01<00:03,  3.37it/s]\u001b[A\n",
            "Epoch 2:  88% 84/95 [01:01<00:08,  1.36it/s, loss=1.58, v_num=2, val_loss=1.65, val_acc=0.372]\n",
            "Validating:  31% 5/16 [00:01<00:02,  3.98it/s]\u001b[A\n",
            "Epoch 2:  91% 86/95 [01:02<00:06,  1.39it/s, loss=1.58, v_num=2, val_loss=1.65, val_acc=0.372]\n",
            "Validating:  44% 7/16 [00:01<00:02,  4.26it/s]\u001b[A\n",
            "Epoch 2:  93% 88/95 [01:02<00:04,  1.41it/s, loss=1.58, v_num=2, val_loss=1.65, val_acc=0.372]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.40it/s]\u001b[A\n",
            "Epoch 2:  95% 90/95 [01:02<00:03,  1.43it/s, loss=1.58, v_num=2, val_loss=1.65, val_acc=0.372]\n",
            "Validating:  69% 11/16 [00:02<00:01,  4.52it/s]\u001b[A\n",
            "Epoch 2:  97% 92/95 [01:03<00:02,  1.45it/s, loss=1.58, v_num=2, val_loss=1.65, val_acc=0.372]\n",
            "Validating:  81% 13/16 [00:03<00:00,  4.49it/s]\u001b[A\n",
            "Epoch 2:  99% 94/95 [01:03<00:00,  1.47it/s, loss=1.58, v_num=2, val_loss=1.65, val_acc=0.372]\n",
            "Validating:  94% 15/16 [00:03<00:00,  4.55it/s]\u001b[A\n",
            "Epoch 2: 100% 95/95 [01:04<00:00,  1.48it/s, loss=1.58, v_num=2, val_loss=1.53, val_acc=0.404]\n",
            "Epoch 3:  84% 80/95 [01:00<00:11,  1.32it/s, loss=1.52, v_num=2, val_loss=1.53, val_acc=0.404]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:08,  1.83it/s]\u001b[A\n",
            "Epoch 3:  86% 82/95 [01:01<00:09,  1.34it/s, loss=1.52, v_num=2, val_loss=1.53, val_acc=0.404]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.42it/s]\u001b[A\n",
            "Epoch 3:  88% 84/95 [01:01<00:08,  1.36it/s, loss=1.52, v_num=2, val_loss=1.53, val_acc=0.404]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.03it/s]\u001b[A\n",
            "Epoch 3:  91% 86/95 [01:02<00:06,  1.38it/s, loss=1.52, v_num=2, val_loss=1.53, val_acc=0.404]\n",
            "Validating:  44% 7/16 [00:01<00:02,  4.30it/s]\u001b[A\n",
            "Epoch 3:  93% 88/95 [01:02<00:04,  1.41it/s, loss=1.52, v_num=2, val_loss=1.53, val_acc=0.404]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.41it/s]\u001b[A\n",
            "Epoch 3:  95% 90/95 [01:03<00:03,  1.43it/s, loss=1.52, v_num=2, val_loss=1.53, val_acc=0.404]\n",
            "Validating:  69% 11/16 [00:02<00:01,  4.52it/s]\u001b[A\n",
            "Epoch 3:  97% 92/95 [01:03<00:02,  1.45it/s, loss=1.52, v_num=2, val_loss=1.53, val_acc=0.404]\n",
            "Validating:  81% 13/16 [00:03<00:00,  4.54it/s]\u001b[A\n",
            "Epoch 3:  99% 94/95 [01:03<00:00,  1.47it/s, loss=1.52, v_num=2, val_loss=1.53, val_acc=0.404]\n",
            "Validating:  94% 15/16 [00:03<00:00,  4.57it/s]\u001b[A\n",
            "Epoch 3: 100% 95/95 [01:04<00:00,  1.47it/s, loss=1.52, v_num=2, val_loss=1.51, val_acc=0.407]\n",
            "Epoch 4:  84% 80/95 [01:00<00:11,  1.32it/s, loss=1.48, v_num=2, val_loss=1.51, val_acc=0.407]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:07,  1.88it/s]\u001b[A\n",
            "Epoch 4:  86% 82/95 [01:01<00:09,  1.34it/s, loss=1.48, v_num=2, val_loss=1.51, val_acc=0.407]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.48it/s]\u001b[A\n",
            "Epoch 4:  88% 84/95 [01:01<00:08,  1.36it/s, loss=1.48, v_num=2, val_loss=1.51, val_acc=0.407]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.02it/s]\u001b[A\n",
            "Epoch 4:  91% 86/95 [01:02<00:06,  1.38it/s, loss=1.48, v_num=2, val_loss=1.51, val_acc=0.407]\n",
            "Validating:  44% 7/16 [00:01<00:02,  4.30it/s]\u001b[A\n",
            "Epoch 4:  93% 88/95 [01:02<00:04,  1.41it/s, loss=1.48, v_num=2, val_loss=1.51, val_acc=0.407]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.45it/s]\u001b[A\n",
            "Epoch 4:  95% 90/95 [01:03<00:03,  1.43it/s, loss=1.48, v_num=2, val_loss=1.51, val_acc=0.407]\n",
            "Validating:  69% 11/16 [00:02<00:01,  4.52it/s]\u001b[A\n",
            "Epoch 4:  97% 92/95 [01:03<00:02,  1.45it/s, loss=1.48, v_num=2, val_loss=1.51, val_acc=0.407]\n",
            "Validating:  81% 13/16 [00:03<00:00,  4.56it/s]\u001b[A\n",
            "Epoch 4:  99% 94/95 [01:03<00:00,  1.47it/s, loss=1.48, v_num=2, val_loss=1.51, val_acc=0.407]\n",
            "Validating:  94% 15/16 [00:03<00:00,  4.60it/s]\u001b[A\n",
            "Epoch 4: 100% 95/95 [01:04<00:00,  1.47it/s, loss=1.48, v_num=2, val_loss=1.47, val_acc=0.42] \n",
            "Epoch 5:  84% 80/95 [01:00<00:11,  1.33it/s, loss=1.44, v_num=2, val_loss=1.47, val_acc=0.42]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:07,  2.00it/s]\u001b[A\n",
            "Epoch 5:  86% 82/95 [01:00<00:09,  1.35it/s, loss=1.44, v_num=2, val_loss=1.47, val_acc=0.42]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.56it/s]\u001b[A\n",
            "Epoch 5:  88% 84/95 [01:01<00:08,  1.37it/s, loss=1.44, v_num=2, val_loss=1.47, val_acc=0.42]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.11it/s]\u001b[A\n",
            "Epoch 5:  91% 86/95 [01:01<00:06,  1.39it/s, loss=1.44, v_num=2, val_loss=1.47, val_acc=0.42]\n",
            "Validating:  44% 7/16 [00:01<00:02,  4.33it/s]\u001b[A\n",
            "Epoch 5:  93% 88/95 [01:02<00:04,  1.41it/s, loss=1.44, v_num=2, val_loss=1.47, val_acc=0.42]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.49it/s]\u001b[A\n",
            "Epoch 5:  95% 90/95 [01:02<00:03,  1.44it/s, loss=1.44, v_num=2, val_loss=1.47, val_acc=0.42]\n",
            "Validating:  69% 11/16 [00:02<00:01,  4.57it/s]\u001b[A\n",
            "Epoch 5:  97% 92/95 [01:03<00:02,  1.46it/s, loss=1.44, v_num=2, val_loss=1.47, val_acc=0.42]\n",
            "Validating:  81% 13/16 [00:03<00:00,  4.57it/s]\u001b[A\n",
            "Epoch 5:  99% 94/95 [01:03<00:00,  1.48it/s, loss=1.44, v_num=2, val_loss=1.47, val_acc=0.42]\n",
            "Validating:  94% 15/16 [00:03<00:00,  4.62it/s]\u001b[A\n",
            "Epoch 5: 100% 95/95 [01:04<00:00,  1.48it/s, loss=1.44, v_num=2, val_loss=1.45, val_acc=0.42]\n",
            "Epoch 6:  84% 80/95 [01:00<00:11,  1.33it/s, loss=1.41, v_num=2, val_loss=1.45, val_acc=0.42]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:08,  1.85it/s]\u001b[A\n",
            "Epoch 6:  86% 82/95 [01:01<00:09,  1.34it/s, loss=1.41, v_num=2, val_loss=1.45, val_acc=0.42]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.43it/s]\u001b[A\n",
            "Epoch 6:  88% 84/95 [01:01<00:08,  1.37it/s, loss=1.41, v_num=2, val_loss=1.45, val_acc=0.42]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.01it/s]\u001b[A\n",
            "Epoch 6:  91% 86/95 [01:01<00:06,  1.39it/s, loss=1.41, v_num=2, val_loss=1.45, val_acc=0.42]\n",
            "Validating:  44% 7/16 [00:01<00:02,  4.27it/s]\u001b[A\n",
            "Epoch 6:  93% 88/95 [01:02<00:04,  1.41it/s, loss=1.41, v_num=2, val_loss=1.45, val_acc=0.42]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.41it/s]\u001b[A\n",
            "Epoch 6:  95% 90/95 [01:02<00:03,  1.43it/s, loss=1.41, v_num=2, val_loss=1.45, val_acc=0.42]\n",
            "Validating:  69% 11/16 [00:02<00:01,  4.49it/s]\u001b[A\n",
            "Epoch 6:  97% 92/95 [01:03<00:02,  1.45it/s, loss=1.41, v_num=2, val_loss=1.45, val_acc=0.42]\n",
            "Validating:  81% 13/16 [00:03<00:00,  4.54it/s]\u001b[A\n",
            "Epoch 6:  99% 94/95 [01:03<00:00,  1.48it/s, loss=1.41, v_num=2, val_loss=1.45, val_acc=0.42]\n",
            "Validating:  94% 15/16 [00:03<00:00,  4.56it/s]\u001b[A\n",
            "Epoch 6: 100% 95/95 [01:04<00:00,  1.48it/s, loss=1.41, v_num=2, val_loss=1.44, val_acc=0.426]\n",
            "Epoch 7:  84% 80/95 [01:00<00:11,  1.32it/s, loss=1.41, v_num=2, val_loss=1.44, val_acc=0.426]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:07,  1.94it/s]\u001b[A\n",
            "Epoch 7:  86% 82/95 [01:01<00:09,  1.34it/s, loss=1.41, v_num=2, val_loss=1.44, val_acc=0.426]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.48it/s]\u001b[A\n",
            "Epoch 7:  88% 84/95 [01:01<00:08,  1.36it/s, loss=1.41, v_num=2, val_loss=1.44, val_acc=0.426]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.04it/s]\u001b[A\n",
            "Epoch 7:  91% 86/95 [01:02<00:06,  1.38it/s, loss=1.41, v_num=2, val_loss=1.44, val_acc=0.426]\n",
            "Validating:  44% 7/16 [00:01<00:02,  4.31it/s]\u001b[A\n",
            "Epoch 7:  93% 88/95 [01:02<00:04,  1.41it/s, loss=1.41, v_num=2, val_loss=1.44, val_acc=0.426]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.41it/s]\u001b[A\n",
            "Epoch 7:  95% 90/95 [01:03<00:03,  1.43it/s, loss=1.41, v_num=2, val_loss=1.44, val_acc=0.426]\n",
            "Validating:  69% 11/16 [00:02<00:01,  4.51it/s]\u001b[A\n",
            "Epoch 7:  97% 92/95 [01:03<00:02,  1.45it/s, loss=1.41, v_num=2, val_loss=1.44, val_acc=0.426]\n",
            "Validating:  81% 13/16 [00:03<00:00,  4.56it/s]\u001b[A\n",
            "Epoch 7:  99% 94/95 [01:03<00:00,  1.47it/s, loss=1.41, v_num=2, val_loss=1.44, val_acc=0.426]\n",
            "Validating:  94% 15/16 [00:03<00:00,  4.53it/s]\u001b[A\n",
            "Epoch 7: 100% 95/95 [01:04<00:00,  1.47it/s, loss=1.41, v_num=2, val_loss=1.43, val_acc=0.425]\n",
            "Epoch 8:  84% 80/95 [01:00<00:11,  1.32it/s, loss=1.37, v_num=2, val_loss=1.43, val_acc=0.425]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:07,  1.90it/s]\u001b[A\n",
            "Epoch 8:  86% 82/95 [01:01<00:09,  1.34it/s, loss=1.37, v_num=2, val_loss=1.43, val_acc=0.425]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.49it/s]\u001b[A\n",
            "Epoch 8:  88% 84/95 [01:01<00:08,  1.36it/s, loss=1.37, v_num=2, val_loss=1.43, val_acc=0.425]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.07it/s]\u001b[A\n",
            "Epoch 8:  91% 86/95 [01:02<00:06,  1.38it/s, loss=1.37, v_num=2, val_loss=1.43, val_acc=0.425]\n",
            "Validating:  44% 7/16 [00:01<00:02,  4.31it/s]\u001b[A\n",
            "Epoch 8:  93% 88/95 [01:02<00:04,  1.41it/s, loss=1.37, v_num=2, val_loss=1.43, val_acc=0.425]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.44it/s]\u001b[A\n",
            "Epoch 8:  95% 90/95 [01:03<00:03,  1.43it/s, loss=1.37, v_num=2, val_loss=1.43, val_acc=0.425]\n",
            "Validating:  69% 11/16 [00:02<00:01,  4.52it/s]\u001b[A\n",
            "Epoch 8:  97% 92/95 [01:03<00:02,  1.45it/s, loss=1.37, v_num=2, val_loss=1.43, val_acc=0.425]\n",
            "Validating:  81% 13/16 [00:03<00:00,  4.57it/s]\u001b[A\n",
            "Epoch 8:  99% 94/95 [01:03<00:00,  1.47it/s, loss=1.37, v_num=2, val_loss=1.43, val_acc=0.425]\n",
            "Validating:  94% 15/16 [00:03<00:00,  4.57it/s]\u001b[A\n",
            "Epoch 8: 100% 95/95 [01:04<00:00,  1.47it/s, loss=1.37, v_num=2, val_loss=1.42, val_acc=0.43] \n",
            "Epoch 9:  84% 80/95 [01:00<00:11,  1.32it/s, loss=1.33, v_num=2, val_loss=1.42, val_acc=0.43]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:07,  2.08it/s]\u001b[A\n",
            "Epoch 9:  86% 82/95 [01:01<00:09,  1.34it/s, loss=1.33, v_num=2, val_loss=1.42, val_acc=0.43]\n",
            "Validating:  19% 3/16 [00:00<00:03,  3.59it/s]\u001b[A\n",
            "Epoch 9:  88% 84/95 [01:01<00:08,  1.36it/s, loss=1.33, v_num=2, val_loss=1.42, val_acc=0.43]\n",
            "Validating:  31% 5/16 [00:01<00:02,  4.07it/s]\u001b[A\n",
            "Epoch 9:  91% 86/95 [01:02<00:06,  1.38it/s, loss=1.33, v_num=2, val_loss=1.42, val_acc=0.43]\n",
            "Validating:  44% 7/16 [00:01<00:02,  4.32it/s]\u001b[A\n",
            "Epoch 9:  93% 88/95 [01:02<00:04,  1.41it/s, loss=1.33, v_num=2, val_loss=1.42, val_acc=0.43]\n",
            "Validating:  56% 9/16 [00:02<00:01,  4.43it/s]\u001b[A\n",
            "Epoch 9:  95% 90/95 [01:03<00:03,  1.43it/s, loss=1.33, v_num=2, val_loss=1.42, val_acc=0.43]\n",
            "Validating:  69% 11/16 [00:02<00:01,  4.52it/s]\u001b[A\n",
            "Epoch 9:  97% 92/95 [01:03<00:02,  1.45it/s, loss=1.33, v_num=2, val_loss=1.42, val_acc=0.43]\n",
            "Validating:  81% 13/16 [00:03<00:00,  4.56it/s]\u001b[A\n",
            "Epoch 9:  99% 94/95 [01:03<00:00,  1.47it/s, loss=1.33, v_num=2, val_loss=1.42, val_acc=0.43]\n",
            "Validating:  94% 15/16 [00:03<00:00,  4.55it/s]\u001b[A\n",
            "Epoch 9: 100% 95/95 [01:04<00:00,  1.47it/s, loss=1.33, v_num=2, val_loss=1.42, val_acc=0.432]\n",
            "Epoch 9: 100% 95/95 [01:04<00:00,  1.47it/s, loss=1.33, v_num=2, val_loss=1.42, val_acc=0.432]\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "Testing: 100% 16/16 [00:03<00:00,  4.15it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.4219, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training/run_experiment.py --max_epochs=10 --gpus=1 --num_workers=4 --data_class=EMNISTLines --min_overlap=0 --max_overlap=0.33 --model_class=LineCNNLSTM --window_width=28 --window_stride=18 --loss=ctc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9jMnjhPAw8r",
        "outputId": "3af55101-3ab5-4476-bbb7-191e64c228ed"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "EMNISTLinesDataset generating data for train...\n",
            "EMNISTLinesDataset generating data for val...\n",
            "EMNISTLinesDataset generating data for test...\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "\n",
            "   | Name                        | Type               | Params\n",
            "--------------------------------------------------------------------\n",
            "0  | model                       | LineCNNLSTM        | 3.7 M \n",
            "1  | model.line_cnn              | LineCNN            | 1.2 M \n",
            "2  | model.line_cnn.convs        | Sequential         | 895 K \n",
            "3  | model.line_cnn.convs.0      | ConvBlock          | 320   \n",
            "4  | model.line_cnn.convs.0.conv | Conv2d             | 320   \n",
            "5  | model.line_cnn.convs.0.relu | ReLU               | 0     \n",
            "6  | model.line_cnn.convs.1      | ConvBlock          | 9.2 K \n",
            "7  | model.line_cnn.convs.1.conv | Conv2d             | 9.2 K \n",
            "8  | model.line_cnn.convs.1.relu | ReLU               | 0     \n",
            "9  | model.line_cnn.convs.2      | ConvBlock          | 9.2 K \n",
            "10 | model.line_cnn.convs.2.conv | Conv2d             | 9.2 K \n",
            "11 | model.line_cnn.convs.2.relu | ReLU               | 0     \n",
            "12 | model.line_cnn.convs.3      | ConvBlock          | 9.2 K \n",
            "13 | model.line_cnn.convs.3.conv | Conv2d             | 9.2 K \n",
            "14 | model.line_cnn.convs.3.relu | ReLU               | 0     \n",
            "15 | model.line_cnn.convs.4      | ConvBlock          | 18.5 K\n",
            "16 | model.line_cnn.convs.4.conv | Conv2d             | 18.5 K\n",
            "17 | model.line_cnn.convs.4.relu | ReLU               | 0     \n",
            "18 | model.line_cnn.convs.5      | ConvBlock          | 36.9 K\n",
            "19 | model.line_cnn.convs.5.conv | Conv2d             | 36.9 K\n",
            "20 | model.line_cnn.convs.5.relu | ReLU               | 0     \n",
            "21 | model.line_cnn.convs.6      | ConvBlock          | 73.9 K\n",
            "22 | model.line_cnn.convs.6.conv | Conv2d             | 73.9 K\n",
            "23 | model.line_cnn.convs.6.relu | ReLU               | 0     \n",
            "24 | model.line_cnn.convs.7      | ConvBlock          | 147 K \n",
            "25 | model.line_cnn.convs.7.conv | Conv2d             | 147 K \n",
            "26 | model.line_cnn.convs.7.relu | ReLU               | 0     \n",
            "27 | model.line_cnn.convs.8      | ConvBlock          | 590 K \n",
            "28 | model.line_cnn.convs.8.conv | Conv2d             | 590 K \n",
            "29 | model.line_cnn.convs.8.relu | ReLU               | 0     \n",
            "30 | model.line_cnn.fc1          | Linear             | 262 K \n",
            "31 | model.line_cnn.dropout      | Dropout            | 0     \n",
            "32 | model.line_cnn.fc2          | Linear             | 42.6 K\n",
            "33 | model.lstm                  | LSTM               | 2.4 M \n",
            "34 | model.fc                    | Linear             | 42.6 K\n",
            "35 | train_acc                   | Accuracy           | 0     \n",
            "36 | val_acc                     | Accuracy           | 0     \n",
            "37 | test_acc                    | Accuracy           | 0     \n",
            "38 | loss_fn                     | CTCLoss            | 0     \n",
            "39 | val_cer                     | CharacterErrorRate | 0     \n",
            "40 | test_cer                    | CharacterErrorRate | 0     \n",
            "--------------------------------------------------------------------\n",
            "3.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.7 M     Total params\n",
            "Validation sanity check: 0it [00:00, ?it/s]Traceback (most recent call last):\n",
            "  File \"training/run_experiment.py\", line 108, in <module>\n",
            "    main()\n",
            "  File \"training/run_experiment.py\", line 101, in main\n",
            "    trainer.fit(lit_model, datamodule=data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 473, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 66, in train\n",
            "    results = self.train_or_test()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 69, in train_or_test\n",
            "    results = self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 495, in train\n",
            "    self.run_sanity_check(self.get_model())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 693, in run_sanity_check\n",
            "    _, eval_results = self.run_evaluation(test_mode=False, max_batches=self.num_sanity_val_batches)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 609, in run_evaluation\n",
            "    output = self.evaluation_loop.evaluation_step(test_mode, batch, batch_idx, dataloader_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 178, in evaluation_step\n",
            "    output = self.trainer.accelerator_backend.validation_step(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 84, in validation_step\n",
            "    return self._step(self.trainer.model.validation_step, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 76, in _step\n",
            "    output = model_step(*args)\n",
            "  File \"/content/fsdl-text-recognizer-2021-labs/lab3/text_recognizer/lit_models/ctc.py\", line 92, in validation_step\n",
            "    self.val_acc(decoded, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/metric.py\", line 154, in forward\n",
            "    self.update(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/metric.py\", line 200, in wrapped_func\n",
            "    return update(*args, **kwargs)\n",
            "  File \"/content/fsdl-text-recognizer-2021-labs/lab3/text_recognizer/lit_models/base.py\", line 24, in update\n",
            "    preds = torch.nn.functional.softmax(preds, dim=-1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1512, in softmax\n",
            "    ret = input.softmax(dim)\n",
            "RuntimeError: \"host_softmax\" not implemented for 'Int'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/fsdl-text-recognizer-2021-labs/lab4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSSqUIX-B16b",
        "outputId": "08813903-afb7-4010-d155-48b3f8995e9f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fsdl-text-recognizer-2021-labs/lab4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the LineCNN +LSTM model with CTC lost as an 'encoder' of the image and then send it through Transformer decoder layers"
      ],
      "metadata": {
        "id": "tAEIJr4ZCAa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python training/run_experiment.py --max_epochs=40 --gpus=1 --num_workers=16 --data_class=EMNISTLines --min_overlap=0 --max_overlap=0.33 --model_class=LineCNNTransformer --window_width=20 --window_stride=12 --loss=transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X89AjwTxCJ-d",
        "outputId": "4fddf17a-3af7-410b-ddaa-94a9d810219d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "\n",
            "    | Name                                                       | Type                    | Params\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "0   | model                                                      | LineCNNTransformer      | 3.8 M \n",
            "1   | model.line_cnn                                             | LineCNN                 | 1.1 M \n",
            "2   | model.line_cnn.convs                                       | Sequential              | 698 K \n",
            "3   | model.line_cnn.convs.0                                     | ConvBlock               | 320   \n",
            "4   | model.line_cnn.convs.0.conv                                | Conv2d                  | 320   \n",
            "5   | model.line_cnn.convs.0.relu                                | ReLU                    | 0     \n",
            "6   | model.line_cnn.convs.1                                     | ConvBlock               | 9.2 K \n",
            "7   | model.line_cnn.convs.1.conv                                | Conv2d                  | 9.2 K \n",
            "8   | model.line_cnn.convs.1.relu                                | ReLU                    | 0     \n",
            "9   | model.line_cnn.convs.2                                     | ConvBlock               | 9.2 K \n",
            "10  | model.line_cnn.convs.2.conv                                | Conv2d                  | 9.2 K \n",
            "11  | model.line_cnn.convs.2.relu                                | ReLU                    | 0     \n",
            "12  | model.line_cnn.convs.3                                     | ConvBlock               | 9.2 K \n",
            "13  | model.line_cnn.convs.3.conv                                | Conv2d                  | 9.2 K \n",
            "14  | model.line_cnn.convs.3.relu                                | ReLU                    | 0     \n",
            "15  | model.line_cnn.convs.4                                     | ConvBlock               | 18.5 K\n",
            "16  | model.line_cnn.convs.4.conv                                | Conv2d                  | 18.5 K\n",
            "17  | model.line_cnn.convs.4.relu                                | ReLU                    | 0     \n",
            "18  | model.line_cnn.convs.5                                     | ConvBlock               | 36.9 K\n",
            "19  | model.line_cnn.convs.5.conv                                | Conv2d                  | 36.9 K\n",
            "20  | model.line_cnn.convs.5.relu                                | ReLU                    | 0     \n",
            "21  | model.line_cnn.convs.6                                     | ConvBlock               | 73.9 K\n",
            "22  | model.line_cnn.convs.6.conv                                | Conv2d                  | 73.9 K\n",
            "23  | model.line_cnn.convs.6.relu                                | ReLU                    | 0     \n",
            "24  | model.line_cnn.convs.7                                     | ConvBlock               | 147 K \n",
            "25  | model.line_cnn.convs.7.conv                                | Conv2d                  | 147 K \n",
            "26  | model.line_cnn.convs.7.relu                                | ReLU                    | 0     \n",
            "27  | model.line_cnn.convs.8                                     | ConvBlock               | 393 K \n",
            "28  | model.line_cnn.convs.8.conv                                | Conv2d                  | 393 K \n",
            "29  | model.line_cnn.convs.8.relu                                | ReLU                    | 0     \n",
            "30  | model.line_cnn.fc1                                         | Linear                  | 262 K \n",
            "31  | model.line_cnn.dropout                                     | Dropout                 | 0     \n",
            "32  | model.line_cnn.fc2                                         | Linear                  | 131 K \n",
            "33  | model.embedding                                            | Embedding               | 21.2 K\n",
            "34  | model.fc                                                   | Linear                  | 21.3 K\n",
            "35  | model.pos_encoder                                          | PositionalEncoding      | 0     \n",
            "36  | model.pos_encoder.dropout                                  | Dropout                 | 0     \n",
            "37  | model.transformer_decoder                                  | TransformerDecoder      | 2.6 M \n",
            "38  | model.transformer_decoder.layers                           | ModuleList              | 2.6 M \n",
            "39  | model.transformer_decoder.layers.0                         | TransformerDecoderLayer | 659 K \n",
            "40  | model.transformer_decoder.layers.0.self_attn               | MultiheadAttention      | 263 K \n",
            "41  | model.transformer_decoder.layers.0.self_attn.out_proj      | _LinearWithBias         | 65.8 K\n",
            "42  | model.transformer_decoder.layers.0.multihead_attn          | MultiheadAttention      | 263 K \n",
            "43  | model.transformer_decoder.layers.0.multihead_attn.out_proj | _LinearWithBias         | 65.8 K\n",
            "44  | model.transformer_decoder.layers.0.linear1                 | Linear                  | 65.8 K\n",
            "45  | model.transformer_decoder.layers.0.dropout                 | Dropout                 | 0     \n",
            "46  | model.transformer_decoder.layers.0.linear2                 | Linear                  | 65.8 K\n",
            "47  | model.transformer_decoder.layers.0.norm1                   | LayerNorm               | 512   \n",
            "48  | model.transformer_decoder.layers.0.norm2                   | LayerNorm               | 512   \n",
            "49  | model.transformer_decoder.layers.0.norm3                   | LayerNorm               | 512   \n",
            "50  | model.transformer_decoder.layers.0.dropout1                | Dropout                 | 0     \n",
            "51  | model.transformer_decoder.layers.0.dropout2                | Dropout                 | 0     \n",
            "52  | model.transformer_decoder.layers.0.dropout3                | Dropout                 | 0     \n",
            "53  | model.transformer_decoder.layers.1                         | TransformerDecoderLayer | 659 K \n",
            "54  | model.transformer_decoder.layers.1.self_attn               | MultiheadAttention      | 263 K \n",
            "55  | model.transformer_decoder.layers.1.self_attn.out_proj      | _LinearWithBias         | 65.8 K\n",
            "56  | model.transformer_decoder.layers.1.multihead_attn          | MultiheadAttention      | 263 K \n",
            "57  | model.transformer_decoder.layers.1.multihead_attn.out_proj | _LinearWithBias         | 65.8 K\n",
            "58  | model.transformer_decoder.layers.1.linear1                 | Linear                  | 65.8 K\n",
            "59  | model.transformer_decoder.layers.1.dropout                 | Dropout                 | 0     \n",
            "60  | model.transformer_decoder.layers.1.linear2                 | Linear                  | 65.8 K\n",
            "61  | model.transformer_decoder.layers.1.norm1                   | LayerNorm               | 512   \n",
            "62  | model.transformer_decoder.layers.1.norm2                   | LayerNorm               | 512   \n",
            "63  | model.transformer_decoder.layers.1.norm3                   | LayerNorm               | 512   \n",
            "64  | model.transformer_decoder.layers.1.dropout1                | Dropout                 | 0     \n",
            "65  | model.transformer_decoder.layers.1.dropout2                | Dropout                 | 0     \n",
            "66  | model.transformer_decoder.layers.1.dropout3                | Dropout                 | 0     \n",
            "67  | model.transformer_decoder.layers.2                         | TransformerDecoderLayer | 659 K \n",
            "68  | model.transformer_decoder.layers.2.self_attn               | MultiheadAttention      | 263 K \n",
            "69  | model.transformer_decoder.layers.2.self_attn.out_proj      | _LinearWithBias         | 65.8 K\n",
            "70  | model.transformer_decoder.layers.2.multihead_attn          | MultiheadAttention      | 263 K \n",
            "71  | model.transformer_decoder.layers.2.multihead_attn.out_proj | _LinearWithBias         | 65.8 K\n",
            "72  | model.transformer_decoder.layers.2.linear1                 | Linear                  | 65.8 K\n",
            "73  | model.transformer_decoder.layers.2.dropout                 | Dropout                 | 0     \n",
            "74  | model.transformer_decoder.layers.2.linear2                 | Linear                  | 65.8 K\n",
            "75  | model.transformer_decoder.layers.2.norm1                   | LayerNorm               | 512   \n",
            "76  | model.transformer_decoder.layers.2.norm2                   | LayerNorm               | 512   \n",
            "77  | model.transformer_decoder.layers.2.norm3                   | LayerNorm               | 512   \n",
            "78  | model.transformer_decoder.layers.2.dropout1                | Dropout                 | 0     \n",
            "79  | model.transformer_decoder.layers.2.dropout2                | Dropout                 | 0     \n",
            "80  | model.transformer_decoder.layers.2.dropout3                | Dropout                 | 0     \n",
            "81  | model.transformer_decoder.layers.3                         | TransformerDecoderLayer | 659 K \n",
            "82  | model.transformer_decoder.layers.3.self_attn               | MultiheadAttention      | 263 K \n",
            "83  | model.transformer_decoder.layers.3.self_attn.out_proj      | _LinearWithBias         | 65.8 K\n",
            "84  | model.transformer_decoder.layers.3.multihead_attn          | MultiheadAttention      | 263 K \n",
            "85  | model.transformer_decoder.layers.3.multihead_attn.out_proj | _LinearWithBias         | 65.8 K\n",
            "86  | model.transformer_decoder.layers.3.linear1                 | Linear                  | 65.8 K\n",
            "87  | model.transformer_decoder.layers.3.dropout                 | Dropout                 | 0     \n",
            "88  | model.transformer_decoder.layers.3.linear2                 | Linear                  | 65.8 K\n",
            "89  | model.transformer_decoder.layers.3.norm1                   | LayerNorm               | 512   \n",
            "90  | model.transformer_decoder.layers.3.norm2                   | LayerNorm               | 512   \n",
            "91  | model.transformer_decoder.layers.3.norm3                   | LayerNorm               | 512   \n",
            "92  | model.transformer_decoder.layers.3.dropout1                | Dropout                 | 0     \n",
            "93  | model.transformer_decoder.layers.3.dropout2                | Dropout                 | 0     \n",
            "94  | model.transformer_decoder.layers.3.dropout3                | Dropout                 | 0     \n",
            "95  | train_acc                                                  | Accuracy                | 0     \n",
            "96  | val_acc                                                    | Accuracy                | 0     \n",
            "97  | test_acc                                                   | Accuracy                | 0     \n",
            "98  | loss_fn                                                    | CrossEntropyLoss        | 0     \n",
            "99  | val_cer                                                    | CharacterErrorRate      | 0     \n",
            "100 | test_cer                                                   | CharacterErrorRate      | 0     \n",
            "---------------------------------------------------------------------------------------------------------\n",
            "3.8 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.8 M     Total params\n",
            "Epoch 0:  83% 79/95 [01:09<00:14,  1.13it/s, loss=3.09, v_num=0, val_loss=5, val_cer=0.995]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  85% 81/95 [01:12<00:12,  1.12it/s, loss=3.09, v_num=0, val_loss=5, val_cer=0.995]\n",
            "Validating:  12% 2/16 [00:03<00:26,  1.89s/it]\u001b[A\n",
            "Epoch 0:  87% 83/95 [01:15<00:10,  1.10it/s, loss=3.09, v_num=0, val_loss=5, val_cer=0.995]\n",
            "Validating:  25% 4/16 [00:07<00:20,  1.67s/it]\u001b[A\n",
            "Epoch 0:  89% 85/95 [01:18<00:09,  1.08it/s, loss=3.09, v_num=0, val_loss=5, val_cer=0.995]\n",
            "Validating:  38% 6/16 [00:10<00:16,  1.60s/it]\u001b[A\n",
            "Epoch 0:  92% 87/95 [01:21<00:07,  1.07it/s, loss=3.09, v_num=0, val_loss=5, val_cer=0.995]\n",
            "Validating:  50% 8/16 [00:13<00:12,  1.58s/it]\u001b[A\n",
            "Epoch 0:  94% 89/95 [01:24<00:05,  1.05it/s, loss=3.09, v_num=0, val_loss=5, val_cer=0.995]\n",
            "Validating:  62% 10/16 [00:16<00:09,  1.57s/it]\u001b[A\n",
            "Epoch 0:  96% 91/95 [01:27<00:03,  1.04it/s, loss=3.09, v_num=0, val_loss=5, val_cer=0.995]\n",
            "Validating:  75% 12/16 [00:19<00:06,  1.56s/it]\u001b[A\n",
            "Epoch 0:  98% 93/95 [01:30<00:01,  1.02it/s, loss=3.09, v_num=0, val_loss=5, val_cer=0.995]\n",
            "Validating:  88% 14/16 [00:22<00:03,  1.56s/it]\u001b[A\n",
            "Epoch 0: 100% 95/95 [01:34<00:00,  1.01it/s, loss=3.09, v_num=0, val_loss=5, val_cer=0.995]\n",
            "Epoch 0: 100% 95/95 [01:35<00:00,  1.01s/it, loss=3.09, v_num=0, val_loss=2.85, val_cer=0.936]\n",
            "Epoch 1:  84% 80/95 [01:10<00:13,  1.13it/s, loss=2.51, v_num=0, val_loss=2.85, val_cer=0.936]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:38,  2.56s/it]\u001b[A\n",
            "Epoch 1:  86% 82/95 [01:14<00:11,  1.10it/s, loss=2.51, v_num=0, val_loss=2.85, val_cer=0.936]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.78s/it]\u001b[A\n",
            "Epoch 1:  88% 84/95 [01:17<00:10,  1.08it/s, loss=2.51, v_num=0, val_loss=2.85, val_cer=0.936]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.64s/it]\u001b[A\n",
            "Epoch 1:  91% 86/95 [01:20<00:08,  1.06it/s, loss=2.51, v_num=0, val_loss=2.85, val_cer=0.936]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.59s/it]\u001b[A\n",
            "Epoch 1:  93% 88/95 [01:24<00:06,  1.05it/s, loss=2.51, v_num=0, val_loss=2.85, val_cer=0.936]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 1:  95% 90/95 [01:27<00:04,  1.03it/s, loss=2.51, v_num=0, val_loss=2.85, val_cer=0.936]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.56s/it]\u001b[A\n",
            "Epoch 1:  97% 92/95 [01:30<00:02,  1.02it/s, loss=2.51, v_num=0, val_loss=2.85, val_cer=0.936]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.56s/it]\u001b[A\n",
            "Epoch 1:  99% 94/95 [01:33<00:00,  1.01it/s, loss=2.51, v_num=0, val_loss=2.85, val_cer=0.936]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.56s/it]\u001b[A\n",
            "Epoch 1: 100% 95/95 [01:36<00:00,  1.02s/it, loss=2.51, v_num=0, val_loss=2.42, val_cer=0.868]\n",
            "Epoch 2:  84% 80/95 [01:10<00:13,  1.14it/s, loss=2.36, v_num=0, val_loss=2.42, val_cer=0.868]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.48s/it]\u001b[A\n",
            "Epoch 2:  86% 82/95 [01:14<00:11,  1.10it/s, loss=2.36, v_num=0, val_loss=2.42, val_cer=0.868]\n",
            "Validating:  19% 3/16 [00:05<00:22,  1.76s/it]\u001b[A\n",
            "Epoch 2:  88% 84/95 [01:17<00:10,  1.09it/s, loss=2.36, v_num=0, val_loss=2.42, val_cer=0.868]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.64s/it]\u001b[A\n",
            "Epoch 2:  91% 86/95 [01:20<00:08,  1.07it/s, loss=2.36, v_num=0, val_loss=2.42, val_cer=0.868]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.59s/it]\u001b[A\n",
            "Epoch 2:  93% 88/95 [01:23<00:06,  1.05it/s, loss=2.36, v_num=0, val_loss=2.42, val_cer=0.868]\n",
            "Validating:  56% 9/16 [00:14<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 2:  95% 90/95 [01:26<00:04,  1.04it/s, loss=2.36, v_num=0, val_loss=2.42, val_cer=0.868]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 2:  97% 92/95 [01:29<00:02,  1.02it/s, loss=2.36, v_num=0, val_loss=2.42, val_cer=0.868]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.56s/it]\u001b[A\n",
            "Epoch 2:  99% 94/95 [01:32<00:00,  1.01it/s, loss=2.36, v_num=0, val_loss=2.42, val_cer=0.868]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.55s/it]\u001b[A\n",
            "Epoch 2: 100% 95/95 [01:36<00:00,  1.01s/it, loss=2.36, v_num=0, val_loss=2.29, val_cer=0.835]\n",
            "Epoch 3:  84% 80/95 [01:10<00:13,  1.13it/s, loss=2.31, v_num=0, val_loss=2.29, val_cer=0.835]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.49s/it]\u001b[A\n",
            "Epoch 3:  86% 82/95 [01:14<00:11,  1.10it/s, loss=2.31, v_num=0, val_loss=2.29, val_cer=0.835]\n",
            "Validating:  19% 3/16 [00:05<00:22,  1.76s/it]\u001b[A\n",
            "Epoch 3:  88% 84/95 [01:17<00:10,  1.08it/s, loss=2.31, v_num=0, val_loss=2.29, val_cer=0.835]\n",
            "Validating:  31% 5/16 [00:08<00:17,  1.63s/it]\u001b[A\n",
            "Epoch 3:  91% 86/95 [01:20<00:08,  1.06it/s, loss=2.31, v_num=0, val_loss=2.29, val_cer=0.835]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.59s/it]\u001b[A\n",
            "Epoch 3:  93% 88/95 [01:23<00:06,  1.05it/s, loss=2.31, v_num=0, val_loss=2.29, val_cer=0.835]\n",
            "Validating:  56% 9/16 [00:14<00:10,  1.57s/it]\u001b[A\n",
            "Epoch 3:  95% 90/95 [01:26<00:04,  1.03it/s, loss=2.31, v_num=0, val_loss=2.29, val_cer=0.835]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.56s/it]\u001b[A\n",
            "Epoch 3:  97% 92/95 [01:30<00:02,  1.02it/s, loss=2.31, v_num=0, val_loss=2.29, val_cer=0.835]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.56s/it]\u001b[A\n",
            "Epoch 3:  99% 94/95 [01:33<00:00,  1.01it/s, loss=2.31, v_num=0, val_loss=2.29, val_cer=0.835]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.56s/it]\u001b[A\n",
            "Epoch 3: 100% 95/95 [01:36<00:00,  1.01s/it, loss=2.31, v_num=0, val_loss=2.2, val_cer=0.831] \n",
            "Epoch 4:  84% 80/95 [01:10<00:13,  1.14it/s, loss=2.26, v_num=0, val_loss=2.2, val_cer=0.831]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.50s/it]\u001b[A\n",
            "Epoch 4:  86% 82/95 [01:14<00:11,  1.11it/s, loss=2.26, v_num=0, val_loss=2.2, val_cer=0.831]\n",
            "Validating:  19% 3/16 [00:05<00:22,  1.77s/it]\u001b[A\n",
            "Epoch 4:  88% 84/95 [01:17<00:10,  1.09it/s, loss=2.26, v_num=0, val_loss=2.2, val_cer=0.831]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.64s/it]\u001b[A\n",
            "Epoch 4:  91% 86/95 [01:20<00:08,  1.07it/s, loss=2.26, v_num=0, val_loss=2.2, val_cer=0.831]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.59s/it]\u001b[A\n",
            "Epoch 4:  93% 88/95 [01:23<00:06,  1.05it/s, loss=2.26, v_num=0, val_loss=2.2, val_cer=0.831]\n",
            "Validating:  56% 9/16 [00:14<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 4:  95% 90/95 [01:26<00:04,  1.04it/s, loss=2.26, v_num=0, val_loss=2.2, val_cer=0.831]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.56s/it]\u001b[A\n",
            "Epoch 4:  97% 92/95 [01:29<00:02,  1.03it/s, loss=2.26, v_num=0, val_loss=2.2, val_cer=0.831]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.56s/it]\u001b[A\n",
            "Epoch 4:  99% 94/95 [01:32<00:00,  1.01it/s, loss=2.26, v_num=0, val_loss=2.2, val_cer=0.831]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.56s/it]\u001b[A\n",
            "Epoch 4: 100% 95/95 [01:36<00:00,  1.01s/it, loss=2.26, v_num=0, val_loss=2.15, val_cer=0.816]\n",
            "Epoch 5:  84% 80/95 [01:10<00:13,  1.13it/s, loss=2.2, v_num=0, val_loss=2.15, val_cer=0.816]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.53s/it]\u001b[A\n",
            "Epoch 5:  86% 82/95 [01:14<00:11,  1.10it/s, loss=2.2, v_num=0, val_loss=2.15, val_cer=0.816]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.78s/it]\u001b[A\n",
            "Epoch 5:  88% 84/95 [01:17<00:10,  1.08it/s, loss=2.2, v_num=0, val_loss=2.15, val_cer=0.816]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.64s/it]\u001b[A\n",
            "Epoch 5:  91% 86/95 [01:20<00:08,  1.06it/s, loss=2.2, v_num=0, val_loss=2.15, val_cer=0.816]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 5:  93% 88/95 [01:23<00:06,  1.05it/s, loss=2.2, v_num=0, val_loss=2.15, val_cer=0.816]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 5:  95% 90/95 [01:27<00:04,  1.03it/s, loss=2.2, v_num=0, val_loss=2.15, val_cer=0.816]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 5:  97% 92/95 [01:30<00:02,  1.02it/s, loss=2.2, v_num=0, val_loss=2.15, val_cer=0.816]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 5:  99% 94/95 [01:33<00:00,  1.01it/s, loss=2.2, v_num=0, val_loss=2.15, val_cer=0.816]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 5: 100% 95/95 [01:36<00:00,  1.02s/it, loss=2.2, v_num=0, val_loss=2.09, val_cer=0.835]\n",
            "Epoch 6:  84% 80/95 [01:10<00:13,  1.14it/s, loss=2.17, v_num=0, val_loss=2.09, val_cer=0.835]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.49s/it]\u001b[A\n",
            "Epoch 6:  86% 82/95 [01:14<00:11,  1.10it/s, loss=2.17, v_num=0, val_loss=2.09, val_cer=0.835]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.77s/it]\u001b[A\n",
            "Epoch 6:  88% 84/95 [01:17<00:10,  1.08it/s, loss=2.17, v_num=0, val_loss=2.09, val_cer=0.835]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 6:  91% 86/95 [01:20<00:08,  1.06it/s, loss=2.17, v_num=0, val_loss=2.09, val_cer=0.835]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 6:  93% 88/95 [01:23<00:06,  1.05it/s, loss=2.17, v_num=0, val_loss=2.09, val_cer=0.835]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.59s/it]\u001b[A\n",
            "Epoch 6:  95% 90/95 [01:27<00:04,  1.03it/s, loss=2.17, v_num=0, val_loss=2.09, val_cer=0.835]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.58s/it]\u001b[A\n",
            "Epoch 6:  97% 92/95 [01:30<00:02,  1.02it/s, loss=2.17, v_num=0, val_loss=2.09, val_cer=0.835]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 6:  99% 94/95 [01:33<00:00,  1.01it/s, loss=2.17, v_num=0, val_loss=2.09, val_cer=0.835]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 6: 100% 95/95 [01:36<00:00,  1.02s/it, loss=2.17, v_num=0, val_loss=2.06, val_cer=0.814]\n",
            "Epoch 7:  84% 80/95 [01:11<00:13,  1.12it/s, loss=2.14, v_num=0, val_loss=2.06, val_cer=0.814]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.51s/it]\u001b[A\n",
            "Epoch 7:  86% 82/95 [01:15<00:11,  1.09it/s, loss=2.14, v_num=0, val_loss=2.06, val_cer=0.814]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.78s/it]\u001b[A\n",
            "Epoch 7:  88% 84/95 [01:18<00:10,  1.07it/s, loss=2.14, v_num=0, val_loss=2.06, val_cer=0.814]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 7:  91% 86/95 [01:21<00:08,  1.05it/s, loss=2.14, v_num=0, val_loss=2.06, val_cer=0.814]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.61s/it]\u001b[A\n",
            "Epoch 7:  93% 88/95 [01:24<00:06,  1.04it/s, loss=2.14, v_num=0, val_loss=2.06, val_cer=0.814]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.59s/it]\u001b[A\n",
            "Epoch 7:  95% 90/95 [01:27<00:04,  1.02it/s, loss=2.14, v_num=0, val_loss=2.06, val_cer=0.814]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.58s/it]\u001b[A\n",
            "Epoch 7:  97% 92/95 [01:30<00:02,  1.01it/s, loss=2.14, v_num=0, val_loss=2.06, val_cer=0.814]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 7:  99% 94/95 [01:34<00:01,  1.00s/it, loss=2.14, v_num=0, val_loss=2.06, val_cer=0.814]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 7: 100% 95/95 [01:37<00:00,  1.02s/it, loss=2.14, v_num=0, val_loss=2.02, val_cer=0.815]\n",
            "Epoch 8:  84% 80/95 [01:10<00:13,  1.13it/s, loss=2.11, v_num=0, val_loss=2.02, val_cer=0.815]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:38,  2.53s/it]\u001b[A\n",
            "Epoch 8:  86% 82/95 [01:14<00:11,  1.10it/s, loss=2.11, v_num=0, val_loss=2.02, val_cer=0.815]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.79s/it]\u001b[A\n",
            "Epoch 8:  88% 84/95 [01:17<00:10,  1.08it/s, loss=2.11, v_num=0, val_loss=2.02, val_cer=0.815]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 8:  91% 86/95 [01:21<00:08,  1.06it/s, loss=2.11, v_num=0, val_loss=2.02, val_cer=0.815]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 8:  93% 88/95 [01:24<00:06,  1.05it/s, loss=2.11, v_num=0, val_loss=2.02, val_cer=0.815]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 8:  95% 90/95 [01:27<00:04,  1.03it/s, loss=2.11, v_num=0, val_loss=2.02, val_cer=0.815]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 8:  97% 92/95 [01:30<00:02,  1.02it/s, loss=2.11, v_num=0, val_loss=2.02, val_cer=0.815]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 8:  99% 94/95 [01:33<00:00,  1.00it/s, loss=2.11, v_num=0, val_loss=2.02, val_cer=0.815]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 8: 100% 95/95 [01:36<00:00,  1.02s/it, loss=2.11, v_num=0, val_loss=1.99, val_cer=0.806]\n",
            "Epoch 9:  84% 80/95 [01:11<00:13,  1.13it/s, loss=2.09, v_num=0, val_loss=1.99, val_cer=0.806]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:38,  2.60s/it]\u001b[A\n",
            "Epoch 9:  86% 82/95 [01:15<00:11,  1.09it/s, loss=2.09, v_num=0, val_loss=1.99, val_cer=0.806]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.79s/it]\u001b[A\n",
            "Epoch 9:  88% 84/95 [01:18<00:10,  1.07it/s, loss=2.09, v_num=0, val_loss=1.99, val_cer=0.806]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.66s/it]\u001b[A\n",
            "Epoch 9:  91% 86/95 [01:21<00:08,  1.06it/s, loss=2.09, v_num=0, val_loss=1.99, val_cer=0.806]\n",
            "Validating:  44% 7/16 [00:12<00:14,  1.61s/it]\u001b[A\n",
            "Epoch 9:  93% 88/95 [01:24<00:06,  1.04it/s, loss=2.09, v_num=0, val_loss=1.99, val_cer=0.806]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 9:  95% 90/95 [01:27<00:04,  1.03it/s, loss=2.09, v_num=0, val_loss=1.99, val_cer=0.806]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.58s/it]\u001b[A\n",
            "Epoch 9:  97% 92/95 [01:30<00:02,  1.01it/s, loss=2.09, v_num=0, val_loss=1.99, val_cer=0.806]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 9:  99% 94/95 [01:34<00:01,  1.00s/it, loss=2.09, v_num=0, val_loss=1.99, val_cer=0.806]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 9: 100% 95/95 [01:37<00:00,  1.02s/it, loss=2.09, v_num=0, val_loss=1.97, val_cer=0.804]\n",
            "Epoch 10:  84% 80/95 [01:10<00:13,  1.13it/s, loss=2.06, v_num=0, val_loss=1.97, val_cer=0.804]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:36,  2.42s/it]\u001b[A\n",
            "Epoch 10:  86% 82/95 [01:14<00:11,  1.10it/s, loss=2.06, v_num=0, val_loss=1.97, val_cer=0.804]\n",
            "Validating:  19% 3/16 [00:05<00:22,  1.76s/it]\u001b[A\n",
            "Epoch 10:  88% 84/95 [01:17<00:10,  1.08it/s, loss=2.06, v_num=0, val_loss=1.97, val_cer=0.804]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.64s/it]\u001b[A\n",
            "Epoch 10:  91% 86/95 [01:20<00:08,  1.06it/s, loss=2.06, v_num=0, val_loss=1.97, val_cer=0.804]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 10:  93% 88/95 [01:24<00:06,  1.05it/s, loss=2.06, v_num=0, val_loss=1.97, val_cer=0.804]\n",
            "Validating:  56% 9/16 [00:14<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 10:  95% 90/95 [01:27<00:04,  1.03it/s, loss=2.06, v_num=0, val_loss=1.97, val_cer=0.804]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.58s/it]\u001b[A\n",
            "Epoch 10:  97% 92/95 [01:30<00:02,  1.02it/s, loss=2.06, v_num=0, val_loss=1.97, val_cer=0.804]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.58s/it]\u001b[A\n",
            "Epoch 10:  99% 94/95 [01:33<00:00,  1.00it/s, loss=2.06, v_num=0, val_loss=1.97, val_cer=0.804]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 10: 100% 95/95 [01:36<00:00,  1.02s/it, loss=2.06, v_num=0, val_loss=1.97, val_cer=0.814]\n",
            "Epoch 11:  84% 80/95 [01:11<00:13,  1.12it/s, loss=2.03, v_num=0, val_loss=1.97, val_cer=0.814]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:36,  2.44s/it]\u001b[A\n",
            "Epoch 11:  86% 82/95 [01:15<00:11,  1.09it/s, loss=2.03, v_num=0, val_loss=1.97, val_cer=0.814]\n",
            "Validating:  19% 3/16 [00:05<00:22,  1.76s/it]\u001b[A\n",
            "Epoch 11:  88% 84/95 [01:18<00:10,  1.07it/s, loss=2.03, v_num=0, val_loss=1.97, val_cer=0.814]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 11:  91% 86/95 [01:21<00:08,  1.06it/s, loss=2.03, v_num=0, val_loss=1.97, val_cer=0.814]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 11:  93% 88/95 [01:24<00:06,  1.04it/s, loss=2.03, v_num=0, val_loss=1.97, val_cer=0.814]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.59s/it]\u001b[A\n",
            "Epoch 11:  95% 90/95 [01:27<00:04,  1.03it/s, loss=2.03, v_num=0, val_loss=1.97, val_cer=0.814]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.58s/it]\u001b[A\n",
            "Epoch 11:  97% 92/95 [01:30<00:02,  1.01it/s, loss=2.03, v_num=0, val_loss=1.97, val_cer=0.814]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 11:  99% 94/95 [01:34<00:01,  1.00s/it, loss=2.03, v_num=0, val_loss=1.97, val_cer=0.814]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 11: 100% 95/95 [01:37<00:00,  1.02s/it, loss=2.03, v_num=0, val_loss=1.96, val_cer=0.807]\n",
            "Epoch 12:  84% 80/95 [01:10<00:13,  1.13it/s, loss=2.05, v_num=0, val_loss=1.96, val_cer=0.807]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.49s/it]\u001b[A\n",
            "Epoch 12:  86% 82/95 [01:14<00:11,  1.10it/s, loss=2.05, v_num=0, val_loss=1.96, val_cer=0.807]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.78s/it]\u001b[A\n",
            "Epoch 12:  88% 84/95 [01:17<00:10,  1.08it/s, loss=2.05, v_num=0, val_loss=1.96, val_cer=0.807]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 12:  91% 86/95 [01:21<00:08,  1.06it/s, loss=2.05, v_num=0, val_loss=1.96, val_cer=0.807]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 12:  93% 88/95 [01:24<00:06,  1.04it/s, loss=2.05, v_num=0, val_loss=1.96, val_cer=0.807]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.59s/it]\u001b[A\n",
            "Epoch 12:  95% 90/95 [01:27<00:04,  1.03it/s, loss=2.05, v_num=0, val_loss=1.96, val_cer=0.807]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.58s/it]\u001b[A\n",
            "Epoch 12:  97% 92/95 [01:30<00:02,  1.02it/s, loss=2.05, v_num=0, val_loss=1.96, val_cer=0.807]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.58s/it]\u001b[A\n",
            "Epoch 12:  99% 94/95 [01:33<00:00,  1.00it/s, loss=2.05, v_num=0, val_loss=1.96, val_cer=0.807]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 12: 100% 95/95 [01:36<00:00,  1.02s/it, loss=2.05, v_num=0, val_loss=1.93, val_cer=0.807]\n",
            "Epoch 13:  84% 80/95 [01:11<00:13,  1.13it/s, loss=2, v_num=0, val_loss=1.93, val_cer=0.807]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.50s/it]\u001b[A\n",
            "Epoch 13:  86% 82/95 [01:15<00:11,  1.09it/s, loss=2, v_num=0, val_loss=1.93, val_cer=0.807]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.78s/it]\u001b[A\n",
            "Epoch 13:  88% 84/95 [01:18<00:10,  1.07it/s, loss=2, v_num=0, val_loss=1.93, val_cer=0.807]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 13:  91% 86/95 [01:21<00:08,  1.06it/s, loss=2, v_num=0, val_loss=1.93, val_cer=0.807]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 13:  93% 88/95 [01:24<00:06,  1.04it/s, loss=2, v_num=0, val_loss=1.93, val_cer=0.807]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 13:  95% 90/95 [01:27<00:04,  1.03it/s, loss=2, v_num=0, val_loss=1.93, val_cer=0.807]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 13:  97% 92/95 [01:30<00:02,  1.01it/s, loss=2, v_num=0, val_loss=1.93, val_cer=0.807]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 13:  99% 94/95 [01:33<00:00,  1.00it/s, loss=2, v_num=0, val_loss=1.93, val_cer=0.807]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 13: 100% 95/95 [01:37<00:00,  1.02s/it, loss=2, v_num=0, val_loss=1.91, val_cer=0.811]\n",
            "Epoch 14:  84% 80/95 [01:10<00:13,  1.13it/s, loss=2.02, v_num=0, val_loss=1.91, val_cer=0.811]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.51s/it]\u001b[A\n",
            "Epoch 14:  86% 82/95 [01:14<00:11,  1.10it/s, loss=2.02, v_num=0, val_loss=1.91, val_cer=0.811]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.78s/it]\u001b[A\n",
            "Epoch 14:  88% 84/95 [01:17<00:10,  1.08it/s, loss=2.02, v_num=0, val_loss=1.91, val_cer=0.811]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 14:  91% 86/95 [01:21<00:08,  1.06it/s, loss=2.02, v_num=0, val_loss=1.91, val_cer=0.811]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.61s/it]\u001b[A\n",
            "Epoch 14:  93% 88/95 [01:24<00:06,  1.05it/s, loss=2.02, v_num=0, val_loss=1.91, val_cer=0.811]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 14:  95% 90/95 [01:27<00:04,  1.03it/s, loss=2.02, v_num=0, val_loss=1.91, val_cer=0.811]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 14:  97% 92/95 [01:30<00:02,  1.02it/s, loss=2.02, v_num=0, val_loss=1.91, val_cer=0.811]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 14:  99% 94/95 [01:33<00:00,  1.00it/s, loss=2.02, v_num=0, val_loss=1.91, val_cer=0.811]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 14: 100% 95/95 [01:36<00:00,  1.02s/it, loss=2.02, v_num=0, val_loss=1.89, val_cer=0.805]\n",
            "Epoch 15:  84% 80/95 [01:11<00:13,  1.13it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.805]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.52s/it]\u001b[A\n",
            "Epoch 15:  86% 82/95 [01:15<00:11,  1.09it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.805]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.78s/it]\u001b[A\n",
            "Epoch 15:  88% 84/95 [01:18<00:10,  1.07it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.805]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 15:  91% 86/95 [01:21<00:08,  1.06it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.805]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 15:  93% 88/95 [01:24<00:06,  1.04it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.805]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 15:  95% 90/95 [01:27<00:04,  1.03it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.805]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 15:  97% 92/95 [01:30<00:02,  1.01it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.805]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 15:  99% 94/95 [01:33<00:00,  1.00it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.805]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 15: 100% 95/95 [01:36<00:00,  1.02s/it, loss=2, v_num=0, val_loss=1.89, val_cer=0.811]\n",
            "Epoch 16:  84% 80/95 [01:10<00:13,  1.13it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.811]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:36,  2.42s/it]\u001b[A\n",
            "Epoch 16:  86% 82/95 [01:14<00:11,  1.10it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.811]\n",
            "Validating:  19% 3/16 [00:05<00:22,  1.75s/it]\u001b[A\n",
            "Epoch 16:  88% 84/95 [01:17<00:10,  1.08it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.811]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.64s/it]\u001b[A\n",
            "Epoch 16:  91% 86/95 [01:20<00:08,  1.06it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.811]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 16:  93% 88/95 [01:24<00:06,  1.05it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.811]\n",
            "Validating:  56% 9/16 [00:14<00:11,  1.57s/it]\u001b[A\n",
            "Epoch 16:  95% 90/95 [01:27<00:04,  1.03it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.811]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 16:  97% 92/95 [01:30<00:02,  1.02it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.811]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 16:  99% 94/95 [01:33<00:00,  1.01it/s, loss=2, v_num=0, val_loss=1.89, val_cer=0.811]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 16: 100% 95/95 [01:36<00:00,  1.02s/it, loss=2, v_num=0, val_loss=1.88, val_cer=0.812]\n",
            "Epoch 17:  84% 80/95 [01:10<00:13,  1.13it/s, loss=2, v_num=0, val_loss=1.88, val_cer=0.812]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:38,  2.56s/it]\u001b[A\n",
            "Epoch 17:  86% 82/95 [01:14<00:11,  1.10it/s, loss=2, v_num=0, val_loss=1.88, val_cer=0.812]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.79s/it]\u001b[A\n",
            "Epoch 17:  88% 84/95 [01:17<00:10,  1.08it/s, loss=2, v_num=0, val_loss=1.88, val_cer=0.812]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 17:  91% 86/95 [01:21<00:08,  1.06it/s, loss=2, v_num=0, val_loss=1.88, val_cer=0.812]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.61s/it]\u001b[A\n",
            "Epoch 17:  93% 88/95 [01:24<00:06,  1.05it/s, loss=2, v_num=0, val_loss=1.88, val_cer=0.812]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 17:  95% 90/95 [01:27<00:04,  1.03it/s, loss=2, v_num=0, val_loss=1.88, val_cer=0.812]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 17:  97% 92/95 [01:30<00:02,  1.02it/s, loss=2, v_num=0, val_loss=1.88, val_cer=0.812]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.56s/it]\u001b[A\n",
            "Epoch 17:  99% 94/95 [01:33<00:00,  1.00it/s, loss=2, v_num=0, val_loss=1.88, val_cer=0.812]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.56s/it]\u001b[A\n",
            "Epoch 17: 100% 95/95 [01:36<00:00,  1.02s/it, loss=2, v_num=0, val_loss=1.86, val_cer=0.808]\n",
            "Epoch 18:  84% 80/95 [01:10<00:13,  1.13it/s, loss=1.99, v_num=0, val_loss=1.86, val_cer=0.808]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:38,  2.59s/it]\u001b[A\n",
            "Epoch 18:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.99, v_num=0, val_loss=1.86, val_cer=0.808]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.81s/it]\u001b[A\n",
            "Epoch 18:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.99, v_num=0, val_loss=1.86, val_cer=0.808]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.66s/it]\u001b[A\n",
            "Epoch 18:  91% 86/95 [01:21<00:08,  1.06it/s, loss=1.99, v_num=0, val_loss=1.86, val_cer=0.808]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 18:  93% 88/95 [01:24<00:06,  1.05it/s, loss=1.99, v_num=0, val_loss=1.86, val_cer=0.808]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 18:  95% 90/95 [01:27<00:04,  1.03it/s, loss=1.99, v_num=0, val_loss=1.86, val_cer=0.808]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.58s/it]\u001b[A\n",
            "Epoch 18:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.99, v_num=0, val_loss=1.86, val_cer=0.808]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 18:  99% 94/95 [01:33<00:00,  1.00it/s, loss=1.99, v_num=0, val_loss=1.86, val_cer=0.808]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 18: 100% 95/95 [01:36<00:00,  1.02s/it, loss=1.99, v_num=0, val_loss=1.85, val_cer=0.846]\n",
            "Epoch 19:  84% 80/95 [01:10<00:13,  1.13it/s, loss=1.95, v_num=0, val_loss=1.85, val_cer=0.846]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.51s/it]\u001b[A\n",
            "Epoch 19:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.95, v_num=0, val_loss=1.85, val_cer=0.846]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.78s/it]\u001b[A\n",
            "Epoch 19:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.95, v_num=0, val_loss=1.85, val_cer=0.846]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 19:  91% 86/95 [01:20<00:08,  1.06it/s, loss=1.95, v_num=0, val_loss=1.85, val_cer=0.846]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.61s/it]\u001b[A\n",
            "Epoch 19:  93% 88/95 [01:24<00:06,  1.05it/s, loss=1.95, v_num=0, val_loss=1.85, val_cer=0.846]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.59s/it]\u001b[A\n",
            "Epoch 19:  95% 90/95 [01:27<00:04,  1.03it/s, loss=1.95, v_num=0, val_loss=1.85, val_cer=0.846]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.58s/it]\u001b[A\n",
            "Epoch 19:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.95, v_num=0, val_loss=1.85, val_cer=0.846]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.58s/it]\u001b[A\n",
            "Epoch 19:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.95, v_num=0, val_loss=1.85, val_cer=0.846]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.58s/it]\u001b[A\n",
            "Epoch 19: 100% 95/95 [01:36<00:00,  1.02s/it, loss=1.95, v_num=0, val_loss=1.86, val_cer=0.821]\n",
            "Epoch 20:  84% 80/95 [01:11<00:13,  1.13it/s, loss=1.96, v_num=0, val_loss=1.86, val_cer=0.821]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:40,  2.67s/it]\u001b[A\n",
            "Epoch 20:  86% 82/95 [01:15<00:11,  1.09it/s, loss=1.96, v_num=0, val_loss=1.86, val_cer=0.821]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.81s/it]\u001b[A\n",
            "Epoch 20:  88% 84/95 [01:18<00:10,  1.07it/s, loss=1.96, v_num=0, val_loss=1.86, val_cer=0.821]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.66s/it]\u001b[A\n",
            "Epoch 20:  91% 86/95 [01:21<00:08,  1.05it/s, loss=1.96, v_num=0, val_loss=1.86, val_cer=0.821]\n",
            "Validating:  44% 7/16 [00:12<00:14,  1.61s/it]\u001b[A\n",
            "Epoch 20:  93% 88/95 [01:24<00:06,  1.04it/s, loss=1.96, v_num=0, val_loss=1.86, val_cer=0.821]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.59s/it]\u001b[A\n",
            "Epoch 20:  95% 90/95 [01:27<00:04,  1.02it/s, loss=1.96, v_num=0, val_loss=1.86, val_cer=0.821]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.58s/it]\u001b[A\n",
            "Epoch 20:  97% 92/95 [01:30<00:02,  1.01it/s, loss=1.96, v_num=0, val_loss=1.86, val_cer=0.821]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 20:  99% 94/95 [01:34<00:01,  1.00s/it, loss=1.96, v_num=0, val_loss=1.86, val_cer=0.821]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 20: 100% 95/95 [01:37<00:00,  1.02s/it, loss=1.96, v_num=0, val_loss=1.85, val_cer=0.819]\n",
            "Epoch 21:  84% 80/95 [01:10<00:13,  1.13it/s, loss=1.94, v_num=0, val_loss=1.85, val_cer=0.819]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:39,  2.62s/it]\u001b[A\n",
            "Epoch 21:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.94, v_num=0, val_loss=1.85, val_cer=0.819]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.80s/it]\u001b[A\n",
            "Epoch 21:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.94, v_num=0, val_loss=1.85, val_cer=0.819]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 21:  91% 86/95 [01:21<00:08,  1.06it/s, loss=1.94, v_num=0, val_loss=1.85, val_cer=0.819]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 21:  93% 88/95 [01:24<00:06,  1.04it/s, loss=1.94, v_num=0, val_loss=1.85, val_cer=0.819]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 21:  95% 90/95 [01:27<00:04,  1.03it/s, loss=1.94, v_num=0, val_loss=1.85, val_cer=0.819]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 21:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.94, v_num=0, val_loss=1.85, val_cer=0.819]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 21:  99% 94/95 [01:33<00:00,  1.00it/s, loss=1.94, v_num=0, val_loss=1.85, val_cer=0.819]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 21: 100% 95/95 [01:36<00:00,  1.02s/it, loss=1.94, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Epoch 22:  84% 80/95 [01:11<00:13,  1.12it/s, loss=1.95, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:38,  2.54s/it]\u001b[A\n",
            "Epoch 22:  86% 82/95 [01:15<00:11,  1.09it/s, loss=1.95, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.78s/it]\u001b[A\n",
            "Epoch 22:  88% 84/95 [01:18<00:10,  1.07it/s, loss=1.95, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 22:  91% 86/95 [01:21<00:08,  1.06it/s, loss=1.95, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 22:  93% 88/95 [01:24<00:06,  1.04it/s, loss=1.95, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 22:  95% 90/95 [01:27<00:04,  1.03it/s, loss=1.95, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 22:  97% 92/95 [01:30<00:02,  1.01it/s, loss=1.95, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 22:  99% 94/95 [01:34<00:01,  1.00s/it, loss=1.95, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 22: 100% 95/95 [01:36<00:00,  1.02s/it, loss=1.95, v_num=0, val_loss=1.84, val_cer=0.812]\n",
            "Epoch 23:  84% 80/95 [01:10<00:13,  1.13it/s, loss=1.94, v_num=0, val_loss=1.84, val_cer=0.812]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.49s/it]\u001b[A\n",
            "Epoch 23:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.94, v_num=0, val_loss=1.84, val_cer=0.812]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.77s/it]\u001b[A\n",
            "Epoch 23:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.94, v_num=0, val_loss=1.84, val_cer=0.812]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 23:  91% 86/95 [01:20<00:08,  1.06it/s, loss=1.94, v_num=0, val_loss=1.84, val_cer=0.812]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 23:  93% 88/95 [01:24<00:06,  1.05it/s, loss=1.94, v_num=0, val_loss=1.84, val_cer=0.812]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 23:  95% 90/95 [01:27<00:04,  1.03it/s, loss=1.94, v_num=0, val_loss=1.84, val_cer=0.812]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.58s/it]\u001b[A\n",
            "Epoch 23:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.94, v_num=0, val_loss=1.84, val_cer=0.812]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 23:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.94, v_num=0, val_loss=1.84, val_cer=0.812]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 23: 100% 95/95 [01:36<00:00,  1.02s/it, loss=1.94, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Epoch 24:  84% 80/95 [01:10<00:13,  1.14it/s, loss=1.93, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.51s/it]\u001b[A\n",
            "Epoch 24:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.93, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  19% 3/16 [00:05<00:22,  1.77s/it]\u001b[A\n",
            "Epoch 24:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.93, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.64s/it]\u001b[A\n",
            "Epoch 24:  91% 86/95 [01:20<00:08,  1.07it/s, loss=1.93, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 24:  93% 88/95 [01:23<00:06,  1.05it/s, loss=1.93, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  56% 9/16 [00:14<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 24:  95% 90/95 [01:26<00:04,  1.03it/s, loss=1.93, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 24:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.93, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 24:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.93, v_num=0, val_loss=1.83, val_cer=0.811]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 24: 100% 95/95 [01:36<00:00,  1.02s/it, loss=1.93, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Epoch 25:  84% 80/95 [01:10<00:13,  1.14it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.52s/it]\u001b[A\n",
            "Epoch 25:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.77s/it]\u001b[A\n",
            "Epoch 25:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.64s/it]\u001b[A\n",
            "Epoch 25:  91% 86/95 [01:20<00:08,  1.07it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 25:  93% 88/95 [01:23<00:06,  1.05it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 25:  95% 90/95 [01:26<00:04,  1.03it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 25:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 25:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 25: 100% 95/95 [01:36<00:00,  1.01s/it, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Epoch 26:  84% 80/95 [01:10<00:13,  1.14it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:36,  2.44s/it]\u001b[A\n",
            "Epoch 26:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  19% 3/16 [00:05<00:22,  1.76s/it]\u001b[A\n",
            "Epoch 26:  88% 84/95 [01:17<00:10,  1.09it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  31% 5/16 [00:08<00:17,  1.63s/it]\u001b[A\n",
            "Epoch 26:  91% 86/95 [01:20<00:08,  1.07it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.59s/it]\u001b[A\n",
            "Epoch 26:  93% 88/95 [01:23<00:06,  1.05it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  56% 9/16 [00:14<00:11,  1.57s/it]\u001b[A\n",
            "Epoch 26:  95% 90/95 [01:26<00:04,  1.04it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 26:  97% 92/95 [01:29<00:02,  1.02it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.56s/it]\u001b[A\n",
            "Epoch 26:  99% 94/95 [01:32<00:00,  1.01it/s, loss=1.92, v_num=0, val_loss=1.82, val_cer=0.816]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.56s/it]\u001b[A\n",
            "Epoch 26: 100% 95/95 [01:36<00:00,  1.01s/it, loss=1.92, v_num=0, val_loss=1.81, val_cer=0.814]\n",
            "Epoch 27:  84% 80/95 [01:10<00:13,  1.13it/s, loss=1.89, v_num=0, val_loss=1.81, val_cer=0.814]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.50s/it]\u001b[A\n",
            "Epoch 27:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.89, v_num=0, val_loss=1.81, val_cer=0.814]\n",
            "Validating:  19% 3/16 [00:05<00:22,  1.77s/it]\u001b[A\n",
            "Epoch 27:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.89, v_num=0, val_loss=1.81, val_cer=0.814]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.64s/it]\u001b[A\n",
            "Epoch 27:  91% 86/95 [01:20<00:08,  1.06it/s, loss=1.89, v_num=0, val_loss=1.81, val_cer=0.814]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 27:  93% 88/95 [01:24<00:06,  1.05it/s, loss=1.89, v_num=0, val_loss=1.81, val_cer=0.814]\n",
            "Validating:  56% 9/16 [00:14<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 27:  95% 90/95 [01:27<00:04,  1.03it/s, loss=1.89, v_num=0, val_loss=1.81, val_cer=0.814]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 27:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.89, v_num=0, val_loss=1.81, val_cer=0.814]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 27:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.89, v_num=0, val_loss=1.81, val_cer=0.814]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.56s/it]\u001b[A\n",
            "Epoch 27: 100% 95/95 [01:36<00:00,  1.01s/it, loss=1.89, v_num=0, val_loss=1.81, val_cer=0.823]\n",
            "Epoch 28:  84% 80/95 [01:10<00:13,  1.14it/s, loss=1.91, v_num=0, val_loss=1.81, val_cer=0.823]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:36,  2.46s/it]\u001b[A\n",
            "Epoch 28:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.91, v_num=0, val_loss=1.81, val_cer=0.823]\n",
            "Validating:  19% 3/16 [00:05<00:22,  1.76s/it]\u001b[A\n",
            "Epoch 28:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.91, v_num=0, val_loss=1.81, val_cer=0.823]\n",
            "Validating:  31% 5/16 [00:08<00:17,  1.63s/it]\u001b[A\n",
            "Epoch 28:  91% 86/95 [01:20<00:08,  1.07it/s, loss=1.91, v_num=0, val_loss=1.81, val_cer=0.823]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.59s/it]\u001b[A\n",
            "Epoch 28:  93% 88/95 [01:23<00:06,  1.05it/s, loss=1.91, v_num=0, val_loss=1.81, val_cer=0.823]\n",
            "Validating:  56% 9/16 [00:14<00:11,  1.57s/it]\u001b[A\n",
            "Epoch 28:  95% 90/95 [01:26<00:04,  1.04it/s, loss=1.91, v_num=0, val_loss=1.81, val_cer=0.823]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 28:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.91, v_num=0, val_loss=1.81, val_cer=0.823]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.56s/it]\u001b[A\n",
            "Epoch 28:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.91, v_num=0, val_loss=1.81, val_cer=0.823]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.56s/it]\u001b[A\n",
            "Epoch 28: 100% 95/95 [01:36<00:00,  1.01s/it, loss=1.91, v_num=0, val_loss=1.8, val_cer=0.809] \n",
            "Epoch 29:  84% 80/95 [01:10<00:13,  1.14it/s, loss=1.92, v_num=0, val_loss=1.8, val_cer=0.809]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:38,  2.55s/it]\u001b[A\n",
            "Epoch 29:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.92, v_num=0, val_loss=1.8, val_cer=0.809]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.78s/it]\u001b[A\n",
            "Epoch 29:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.92, v_num=0, val_loss=1.8, val_cer=0.809]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 29:  91% 86/95 [01:20<00:08,  1.07it/s, loss=1.92, v_num=0, val_loss=1.8, val_cer=0.809]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 29:  93% 88/95 [01:23<00:06,  1.05it/s, loss=1.92, v_num=0, val_loss=1.8, val_cer=0.809]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 29:  95% 90/95 [01:26<00:04,  1.03it/s, loss=1.92, v_num=0, val_loss=1.8, val_cer=0.809]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 29:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.92, v_num=0, val_loss=1.8, val_cer=0.809]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.56s/it]\u001b[A\n",
            "Epoch 29:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.92, v_num=0, val_loss=1.8, val_cer=0.809]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 29: 100% 95/95 [01:36<00:00,  1.01s/it, loss=1.92, v_num=0, val_loss=1.8, val_cer=0.813]\n",
            "Epoch 30:  84% 80/95 [01:10<00:13,  1.13it/s, loss=1.9, v_num=0, val_loss=1.8, val_cer=0.813]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.48s/it]\u001b[A\n",
            "Epoch 30:  86% 82/95 [01:14<00:11,  1.09it/s, loss=1.9, v_num=0, val_loss=1.8, val_cer=0.813]\n",
            "Validating:  19% 3/16 [00:05<00:22,  1.76s/it]\u001b[A\n",
            "Epoch 30:  88% 84/95 [01:18<00:10,  1.08it/s, loss=1.9, v_num=0, val_loss=1.8, val_cer=0.813]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.64s/it]\u001b[A\n",
            "Epoch 30:  91% 86/95 [01:21<00:08,  1.06it/s, loss=1.9, v_num=0, val_loss=1.8, val_cer=0.813]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.59s/it]\u001b[A\n",
            "Epoch 30:  93% 88/95 [01:24<00:06,  1.04it/s, loss=1.9, v_num=0, val_loss=1.8, val_cer=0.813]\n",
            "Validating:  56% 9/16 [00:14<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 30:  95% 90/95 [01:27<00:04,  1.03it/s, loss=1.9, v_num=0, val_loss=1.8, val_cer=0.813]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 30:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.9, v_num=0, val_loss=1.8, val_cer=0.813]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 30:  99% 94/95 [01:33<00:00,  1.00it/s, loss=1.9, v_num=0, val_loss=1.8, val_cer=0.813]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 30: 100% 95/95 [01:36<00:00,  1.02s/it, loss=1.9, v_num=0, val_loss=1.79, val_cer=0.81]\n",
            "Epoch 31:  84% 80/95 [01:10<00:13,  1.13it/s, loss=1.91, v_num=0, val_loss=1.79, val_cer=0.81]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.52s/it]\u001b[A\n",
            "Epoch 31:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.91, v_num=0, val_loss=1.79, val_cer=0.81]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.78s/it]\u001b[A\n",
            "Epoch 31:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.91, v_num=0, val_loss=1.79, val_cer=0.81]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 31:  91% 86/95 [01:20<00:08,  1.06it/s, loss=1.91, v_num=0, val_loss=1.79, val_cer=0.81]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 31:  93% 88/95 [01:23<00:06,  1.05it/s, loss=1.91, v_num=0, val_loss=1.79, val_cer=0.81]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 31:  95% 90/95 [01:27<00:04,  1.03it/s, loss=1.91, v_num=0, val_loss=1.79, val_cer=0.81]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 31:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.91, v_num=0, val_loss=1.79, val_cer=0.81]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 31:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.91, v_num=0, val_loss=1.79, val_cer=0.81]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.56s/it]\u001b[A\n",
            "Epoch 31: 100% 95/95 [01:36<00:00,  1.02s/it, loss=1.91, v_num=0, val_loss=1.78, val_cer=0.816]\n",
            "Epoch 32:  84% 80/95 [01:10<00:13,  1.13it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.816]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:38,  2.58s/it]\u001b[A\n",
            "Epoch 32:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.816]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.79s/it]\u001b[A\n",
            "Epoch 32:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.816]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.64s/it]\u001b[A\n",
            "Epoch 32:  91% 86/95 [01:21<00:08,  1.06it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.816]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 32:  93% 88/95 [01:24<00:06,  1.05it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.816]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 32:  95% 90/95 [01:27<00:04,  1.03it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.816]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.56s/it]\u001b[A\n",
            "Epoch 32:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.816]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.56s/it]\u001b[A\n",
            "Epoch 32:  99% 94/95 [01:33<00:00,  1.00it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.816]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.56s/it]\u001b[A\n",
            "Epoch 32: 100% 95/95 [01:36<00:00,  1.02s/it, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.815]\n",
            "Epoch 33:  84% 80/95 [01:10<00:13,  1.14it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.815]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.50s/it]\u001b[A\n",
            "Epoch 33:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.815]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.77s/it]\u001b[A\n",
            "Epoch 33:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.815]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 33:  91% 86/95 [01:20<00:08,  1.07it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.815]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 33:  93% 88/95 [01:23<00:06,  1.05it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.815]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 33:  95% 90/95 [01:26<00:04,  1.03it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.815]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.58s/it]\u001b[A\n",
            "Epoch 33:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.815]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 33:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.815]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 33: 100% 95/95 [01:36<00:00,  1.02s/it, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Epoch 34:  84% 80/95 [01:10<00:13,  1.13it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:38,  2.56s/it]\u001b[A\n",
            "Epoch 34:  86% 82/95 [01:14<00:11,  1.09it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.79s/it]\u001b[A\n",
            "Epoch 34:  88% 84/95 [01:18<00:10,  1.08it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 34:  91% 86/95 [01:21<00:08,  1.06it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.61s/it]\u001b[A\n",
            "Epoch 34:  93% 88/95 [01:24<00:06,  1.04it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 34:  95% 90/95 [01:27<00:04,  1.03it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.58s/it]\u001b[A\n",
            "Epoch 34:  97% 92/95 [01:30<00:02,  1.01it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 34:  99% 94/95 [01:33<00:00,  1.00it/s, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 34: 100% 95/95 [01:36<00:00,  1.02s/it, loss=1.89, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Epoch 35:  84% 80/95 [01:10<00:13,  1.14it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.48s/it]\u001b[A\n",
            "Epoch 35:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.77s/it]\u001b[A\n",
            "Epoch 35:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 35:  91% 86/95 [01:20<00:08,  1.07it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 35:  93% 88/95 [01:23<00:06,  1.05it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.59s/it]\u001b[A\n",
            "Epoch 35:  95% 90/95 [01:26<00:04,  1.04it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 35:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 35:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.812]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 35: 100% 95/95 [01:36<00:00,  1.01s/it, loss=1.88, v_num=0, val_loss=1.78, val_cer=0.811]\n",
            "Epoch 36:  84% 80/95 [01:10<00:13,  1.14it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.811]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:39,  2.66s/it]\u001b[A\n",
            "Epoch 36:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.811]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.81s/it]\u001b[A\n",
            "Epoch 36:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.811]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 36:  91% 86/95 [01:20<00:08,  1.06it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.811]\n",
            "Validating:  44% 7/16 [00:12<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 36:  93% 88/95 [01:23<00:06,  1.05it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.811]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 36:  95% 90/95 [01:27<00:04,  1.03it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.811]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 36:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.811]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.56s/it]\u001b[A\n",
            "Epoch 36:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.811]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.56s/it]\u001b[A\n",
            "Epoch 36: 100% 95/95 [01:36<00:00,  1.01s/it, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.806]\n",
            "Epoch 37:  84% 80/95 [01:10<00:13,  1.14it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.806]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:37,  2.47s/it]\u001b[A\n",
            "Epoch 37:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.806]\n",
            "Validating:  19% 3/16 [00:05<00:22,  1.77s/it]\u001b[A\n",
            "Epoch 37:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.806]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 37:  91% 86/95 [01:20<00:08,  1.07it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.806]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 37:  93% 88/95 [01:23<00:06,  1.05it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.806]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.59s/it]\u001b[A\n",
            "Epoch 37:  95% 90/95 [01:26<00:04,  1.03it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.806]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.58s/it]\u001b[A\n",
            "Epoch 37:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.806]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 37:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.87, v_num=0, val_loss=1.78, val_cer=0.806]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.56s/it]\u001b[A\n",
            "Epoch 37: 100% 95/95 [01:36<00:00,  1.02s/it, loss=1.87, v_num=0, val_loss=1.76, val_cer=0.812]\n",
            "Epoch 38:  84% 80/95 [01:10<00:13,  1.14it/s, loss=1.88, v_num=0, val_loss=1.76, val_cer=0.812]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:40,  2.67s/it]\u001b[A\n",
            "Epoch 38:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.88, v_num=0, val_loss=1.76, val_cer=0.812]\n",
            "Validating:  19% 3/16 [00:05<00:23,  1.81s/it]\u001b[A\n",
            "Epoch 38:  88% 84/95 [01:17<00:10,  1.08it/s, loss=1.88, v_num=0, val_loss=1.76, val_cer=0.812]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.65s/it]\u001b[A\n",
            "Epoch 38:  91% 86/95 [01:20<00:08,  1.06it/s, loss=1.88, v_num=0, val_loss=1.76, val_cer=0.812]\n",
            "Validating:  44% 7/16 [00:12<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 38:  93% 88/95 [01:23<00:06,  1.05it/s, loss=1.88, v_num=0, val_loss=1.76, val_cer=0.812]\n",
            "Validating:  56% 9/16 [00:15<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 38:  95% 90/95 [01:27<00:04,  1.03it/s, loss=1.88, v_num=0, val_loss=1.76, val_cer=0.812]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 38:  97% 92/95 [01:30<00:02,  1.02it/s, loss=1.88, v_num=0, val_loss=1.76, val_cer=0.812]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.56s/it]\u001b[A\n",
            "Epoch 38:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.88, v_num=0, val_loss=1.76, val_cer=0.812]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.56s/it]\u001b[A\n",
            "Epoch 38: 100% 95/95 [01:36<00:00,  1.02s/it, loss=1.88, v_num=0, val_loss=1.76, val_cer=0.815]\n",
            "Epoch 39:  84% 80/95 [01:10<00:13,  1.14it/s, loss=1.85, v_num=0, val_loss=1.76, val_cer=0.815]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:02<00:36,  2.43s/it]\u001b[A\n",
            "Epoch 39:  86% 82/95 [01:14<00:11,  1.10it/s, loss=1.85, v_num=0, val_loss=1.76, val_cer=0.815]\n",
            "Validating:  19% 3/16 [00:05<00:22,  1.77s/it]\u001b[A\n",
            "Epoch 39:  88% 84/95 [01:17<00:10,  1.09it/s, loss=1.85, v_num=0, val_loss=1.76, val_cer=0.815]\n",
            "Validating:  31% 5/16 [00:08<00:18,  1.64s/it]\u001b[A\n",
            "Epoch 39:  91% 86/95 [01:20<00:08,  1.07it/s, loss=1.85, v_num=0, val_loss=1.76, val_cer=0.815]\n",
            "Validating:  44% 7/16 [00:11<00:14,  1.60s/it]\u001b[A\n",
            "Epoch 39:  93% 88/95 [01:23<00:06,  1.05it/s, loss=1.85, v_num=0, val_loss=1.76, val_cer=0.815]\n",
            "Validating:  56% 9/16 [00:14<00:11,  1.58s/it]\u001b[A\n",
            "Epoch 39:  95% 90/95 [01:26<00:04,  1.04it/s, loss=1.85, v_num=0, val_loss=1.76, val_cer=0.815]\n",
            "Validating:  69% 11/16 [00:18<00:07,  1.57s/it]\u001b[A\n",
            "Epoch 39:  97% 92/95 [01:29<00:02,  1.02it/s, loss=1.85, v_num=0, val_loss=1.76, val_cer=0.815]\n",
            "Validating:  81% 13/16 [00:21<00:04,  1.57s/it]\u001b[A\n",
            "Epoch 39:  99% 94/95 [01:33<00:00,  1.01it/s, loss=1.85, v_num=0, val_loss=1.76, val_cer=0.815]\n",
            "Validating:  94% 15/16 [00:24<00:01,  1.57s/it]\u001b[A\n",
            "Epoch 39: 100% 95/95 [01:35<00:00,  1.01s/it, loss=1.85, v_num=0, val_loss=1.77, val_cer=0.816]\n",
            "Epoch 39: 100% 95/95 [01:35<00:00,  1.01s/it, loss=1.85, v_num=0, val_loss=1.77, val_cer=0.816]\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "Testing: 100% 16/16 [00:21<00:00,  1.36s/it]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_cer': tensor(0.8138, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah501s8_XCzh",
        "outputId": "53c95f2d-64b7-4894-aedd-f969641b4cf8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.9)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.24)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boltons pytorch_lightning==1.1.4 wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_ufRY-CXG7M",
        "outputId": "156499cb-4f0b-41d6-897b-8096cd7ae92e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: boltons in /usr/local/lib/python3.7/dist-packages (21.0.0)\n",
            "Requirement already satisfied: pytorch_lightning==1.1.4 in /usr/local/lib/python3.7/dist-packages (1.1.4)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.9)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (1.7.1+cu110)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (2021.11.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (4.62.3)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (0.18.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (2.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (3.8.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.3.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.37.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.42.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.1.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.2.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.24)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.1)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (5.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (1.7.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (21.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (2.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy2XnazhXRzD",
        "outputId": "ecb62ea6-6cbb-45cc-8446-6be8bf91e9ed"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\u001b[1mLet's setup this directory for W&B!\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "Enter a name for your first project: fsdl-text-recognizer-2021-labs\n",
            "\u001b[32mThis directory is configured!  Next, track a run:\n",
            "\u001b[0m* In your training script:\n",
            "    \u001b[1mimport wandb\u001b[0m\n",
            "    \u001b[1mwandb.init(project=\"fsdl-text-recognizer-2021-labs\")\u001b[0m\n",
            "* then `\u001b[1mpython <train.py>\u001b[0m`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/fsdl-text-recognizer-2021-labs/lab5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OBEhS9TYKQ1",
        "outputId": "1edc4382-0139-44b5-e6d9-44c03c888978"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fsdl-text-recognizer-2021-labs/lab5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python text_recognizer/data/iam_lines.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXGQ0-ioZN-7",
        "outputId": "59f07991-c472-44b1-a965-040e9d1cab64"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cropping IAM line regions...\n",
            "Downloading raw dataset from https://s3-us-west-2.amazonaws.com/fsdl-public-assets/iam/iamdb.zip to /content/fsdl-text-recognizer-2021-labs/data/downloaded/iam/iamdb.zip...\n",
            "586MB [00:14, 43.3MB/s]               \n",
            "Computing SHA-256...\n",
            "Extracting IAM data\n",
            "Saving images, labels, and statistics...\n",
            "IAM Lines Dataset\n",
            "Num classes: 83\n",
            "Dims: (1, 56, 2048)\n",
            "Output dims: (89, 1)\n",
            "Train/val/test sizes: 9116, 2279, 1958\n",
            "Train Batch x stats: (torch.Size([128, 1, 56, 2048]), torch.float32, tensor(0.), tensor(0.0171), tensor(0.0757), tensor(1.))\n",
            "Train Batch y stats: (torch.Size([128, 89]), torch.int64, tensor(1), tensor(81))\n",
            "Test Batch x stats: (torch.Size([128, 1, 56, 2048]), torch.float32, tensor(0.), tensor(0.0125), tensor(0.0593), tensor(0.9020))\n",
            "Test Batch y stats: (torch.Size([128, 89]), torch.int64, tensor(1), tensor(82))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training/run_experiment.py --wandb --max_epochs=10 --gpus='0,' --num_workers=4 --data_class=EMNISTLines2 --model_class=LineCNNTransformer --loss=transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-aYNR0fae2e",
        "outputId": "65e87ced-d630-4ec1-a06d-fc6d29dcd2dd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamandahydar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mserene-silence-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/amandahydar/fsdl-text-recognizer-2021-labs-lab5_training\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/amandahydar/fsdl-text-recognizer-2021-labs-lab5_training/runs/1akcbr9f\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/fsdl-text-recognizer-2021-labs/lab5/wandb/run-20211220_195604-1akcbr9f\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "EMNISTLines2 generating data for train...\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "tcmalloc: large alloc 2293760000 bytes == 0x55c220a14000 @  0x7fc2dc4e4b6b 0x7fc2dc504379 0x7fc22e5da74e 0x7fc22e5dc7b6 0x7fc2b9b4aed2 0x7fc2b9e35b03 0x7fc2b9e0d137 0x7fc2b9e2820c 0x7fc2b9e046ba 0x7fc2b9e0d137 0x7fc2b9e2820c 0x7fc2b9ef400d 0x7fc2b9b41955 0x7fc2ba067bc7 0x7fc2ba0b6455 0x7fc2b97180ce 0x7fc2b9e31623 0x7fc2b9e0aed2 0x7fc2b97180ce 0x7fc2b9e31623 0x7fc2b9f17b36 0x7fc2c9bd7807 0x55c2048604b0 0x55c204860240 0x55c2048d40f3 0x55c204861afa 0x55c2048cf915 0x55c204861afa 0x55c2048cfc0d 0x55c2048ce9ee 0x55c2047a0eb0\n",
            "EMNISTLines2 generating data for val...\n",
            "EMNISTLines2 generating data for test...\n",
            "EMNISTLines2 loading data from HDF5...\n",
            "\n",
            "    | Name                                                       | Type                    | Params\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "0   | model                                                      | LineCNNTransformer      | 4.3 M \n",
            "1   | model.line_cnn                                             | LineCNN                 | 1.6 M \n",
            "2   | model.line_cnn.convs                                       | Sequential              | 1.2 M \n",
            "3   | model.line_cnn.convs.0                                     | ConvBlock               | 320   \n",
            "4   | model.line_cnn.convs.0.conv                                | Conv2d                  | 320   \n",
            "5   | model.line_cnn.convs.0.relu                                | ReLU                    | 0     \n",
            "6   | model.line_cnn.convs.1                                     | ConvBlock               | 9.2 K \n",
            "7   | model.line_cnn.convs.1.conv                                | Conv2d                  | 9.2 K \n",
            "8   | model.line_cnn.convs.1.relu                                | ReLU                    | 0     \n",
            "9   | model.line_cnn.convs.2                                     | ConvBlock               | 9.2 K \n",
            "10  | model.line_cnn.convs.2.conv                                | Conv2d                  | 9.2 K \n",
            "11  | model.line_cnn.convs.2.relu                                | ReLU                    | 0     \n",
            "12  | model.line_cnn.convs.3                                     | ConvBlock               | 9.2 K \n",
            "13  | model.line_cnn.convs.3.conv                                | Conv2d                  | 9.2 K \n",
            "14  | model.line_cnn.convs.3.relu                                | ReLU                    | 0     \n",
            "15  | model.line_cnn.convs.4                                     | ConvBlock               | 18.5 K\n",
            "16  | model.line_cnn.convs.4.conv                                | Conv2d                  | 18.5 K\n",
            "17  | model.line_cnn.convs.4.relu                                | ReLU                    | 0     \n",
            "18  | model.line_cnn.convs.5                                     | ConvBlock               | 36.9 K\n",
            "19  | model.line_cnn.convs.5.conv                                | Conv2d                  | 36.9 K\n",
            "20  | model.line_cnn.convs.5.relu                                | ReLU                    | 0     \n",
            "21  | model.line_cnn.convs.6                                     | ConvBlock               | 73.9 K\n",
            "22  | model.line_cnn.convs.6.conv                                | Conv2d                  | 73.9 K\n",
            "23  | model.line_cnn.convs.6.relu                                | ReLU                    | 0     \n",
            "24  | model.line_cnn.convs.7                                     | ConvBlock               | 147 K \n",
            "25  | model.line_cnn.convs.7.conv                                | Conv2d                  | 147 K \n",
            "26  | model.line_cnn.convs.7.relu                                | ReLU                    | 0     \n",
            "27  | model.line_cnn.convs.8                                     | ConvBlock               | 918 K \n",
            "28  | model.line_cnn.convs.8.conv                                | Conv2d                  | 918 K \n",
            "29  | model.line_cnn.convs.8.relu                                | ReLU                    | 0     \n",
            "30  | model.line_cnn.fc1                                         | Linear                  | 262 K \n",
            "31  | model.line_cnn.dropout                                     | Dropout                 | 0     \n",
            "32  | model.line_cnn.fc2                                         | Linear                  | 131 K \n",
            "33  | model.embedding                                            | Embedding               | 21.2 K\n",
            "34  | model.fc                                                   | Linear                  | 21.3 K\n",
            "35  | model.pos_encoder                                          | PositionalEncoding      | 0     \n",
            "36  | model.pos_encoder.dropout                                  | Dropout                 | 0     \n",
            "37  | model.transformer_decoder                                  | TransformerDecoder      | 2.6 M \n",
            "38  | model.transformer_decoder.layers                           | ModuleList              | 2.6 M \n",
            "39  | model.transformer_decoder.layers.0                         | TransformerDecoderLayer | 659 K \n",
            "40  | model.transformer_decoder.layers.0.self_attn               | MultiheadAttention      | 263 K \n",
            "41  | model.transformer_decoder.layers.0.self_attn.out_proj      | _LinearWithBias         | 65.8 K\n",
            "42  | model.transformer_decoder.layers.0.multihead_attn          | MultiheadAttention      | 263 K \n",
            "43  | model.transformer_decoder.layers.0.multihead_attn.out_proj | _LinearWithBias         | 65.8 K\n",
            "44  | model.transformer_decoder.layers.0.linear1                 | Linear                  | 65.8 K\n",
            "45  | model.transformer_decoder.layers.0.dropout                 | Dropout                 | 0     \n",
            "46  | model.transformer_decoder.layers.0.linear2                 | Linear                  | 65.8 K\n",
            "47  | model.transformer_decoder.layers.0.norm1                   | LayerNorm               | 512   \n",
            "48  | model.transformer_decoder.layers.0.norm2                   | LayerNorm               | 512   \n",
            "49  | model.transformer_decoder.layers.0.norm3                   | LayerNorm               | 512   \n",
            "50  | model.transformer_decoder.layers.0.dropout1                | Dropout                 | 0     \n",
            "51  | model.transformer_decoder.layers.0.dropout2                | Dropout                 | 0     \n",
            "52  | model.transformer_decoder.layers.0.dropout3                | Dropout                 | 0     \n",
            "53  | model.transformer_decoder.layers.1                         | TransformerDecoderLayer | 659 K \n",
            "54  | model.transformer_decoder.layers.1.self_attn               | MultiheadAttention      | 263 K \n",
            "55  | model.transformer_decoder.layers.1.self_attn.out_proj      | _LinearWithBias         | 65.8 K\n",
            "56  | model.transformer_decoder.layers.1.multihead_attn          | MultiheadAttention      | 263 K \n",
            "57  | model.transformer_decoder.layers.1.multihead_attn.out_proj | _LinearWithBias         | 65.8 K\n",
            "58  | model.transformer_decoder.layers.1.linear1                 | Linear                  | 65.8 K\n",
            "59  | model.transformer_decoder.layers.1.dropout                 | Dropout                 | 0     \n",
            "60  | model.transformer_decoder.layers.1.linear2                 | Linear                  | 65.8 K\n",
            "61  | model.transformer_decoder.layers.1.norm1                   | LayerNorm               | 512   \n",
            "62  | model.transformer_decoder.layers.1.norm2                   | LayerNorm               | 512   \n",
            "63  | model.transformer_decoder.layers.1.norm3                   | LayerNorm               | 512   \n",
            "64  | model.transformer_decoder.layers.1.dropout1                | Dropout                 | 0     \n",
            "65  | model.transformer_decoder.layers.1.dropout2                | Dropout                 | 0     \n",
            "66  | model.transformer_decoder.layers.1.dropout3                | Dropout                 | 0     \n",
            "67  | model.transformer_decoder.layers.2                         | TransformerDecoderLayer | 659 K \n",
            "68  | model.transformer_decoder.layers.2.self_attn               | MultiheadAttention      | 263 K \n",
            "69  | model.transformer_decoder.layers.2.self_attn.out_proj      | _LinearWithBias         | 65.8 K\n",
            "70  | model.transformer_decoder.layers.2.multihead_attn          | MultiheadAttention      | 263 K \n",
            "71  | model.transformer_decoder.layers.2.multihead_attn.out_proj | _LinearWithBias         | 65.8 K\n",
            "72  | model.transformer_decoder.layers.2.linear1                 | Linear                  | 65.8 K\n",
            "73  | model.transformer_decoder.layers.2.dropout                 | Dropout                 | 0     \n",
            "74  | model.transformer_decoder.layers.2.linear2                 | Linear                  | 65.8 K\n",
            "75  | model.transformer_decoder.layers.2.norm1                   | LayerNorm               | 512   \n",
            "76  | model.transformer_decoder.layers.2.norm2                   | LayerNorm               | 512   \n",
            "77  | model.transformer_decoder.layers.2.norm3                   | LayerNorm               | 512   \n",
            "78  | model.transformer_decoder.layers.2.dropout1                | Dropout                 | 0     \n",
            "79  | model.transformer_decoder.layers.2.dropout2                | Dropout                 | 0     \n",
            "80  | model.transformer_decoder.layers.2.dropout3                | Dropout                 | 0     \n",
            "81  | model.transformer_decoder.layers.3                         | TransformerDecoderLayer | 659 K \n",
            "82  | model.transformer_decoder.layers.3.self_attn               | MultiheadAttention      | 263 K \n",
            "83  | model.transformer_decoder.layers.3.self_attn.out_proj      | _LinearWithBias         | 65.8 K\n",
            "84  | model.transformer_decoder.layers.3.multihead_attn          | MultiheadAttention      | 263 K \n",
            "85  | model.transformer_decoder.layers.3.multihead_attn.out_proj | _LinearWithBias         | 65.8 K\n",
            "86  | model.transformer_decoder.layers.3.linear1                 | Linear                  | 65.8 K\n",
            "87  | model.transformer_decoder.layers.3.dropout                 | Dropout                 | 0     \n",
            "88  | model.transformer_decoder.layers.3.linear2                 | Linear                  | 65.8 K\n",
            "89  | model.transformer_decoder.layers.3.norm1                   | LayerNorm               | 512   \n",
            "90  | model.transformer_decoder.layers.3.norm2                   | LayerNorm               | 512   \n",
            "91  | model.transformer_decoder.layers.3.norm3                   | LayerNorm               | 512   \n",
            "92  | model.transformer_decoder.layers.3.dropout1                | Dropout                 | 0     \n",
            "93  | model.transformer_decoder.layers.3.dropout2                | Dropout                 | 0     \n",
            "94  | model.transformer_decoder.layers.3.dropout3                | Dropout                 | 0     \n",
            "95  | train_acc                                                  | Accuracy                | 0     \n",
            "96  | val_acc                                                    | Accuracy                | 0     \n",
            "97  | test_acc                                                   | Accuracy                | 0     \n",
            "98  | loss_fn                                                    | CrossEntropyLoss        | 0     \n",
            "99  | val_cer                                                    | CharacterErrorRate      | 0     \n",
            "100 | test_cer                                                   | CharacterErrorRate      | 0     \n",
            "---------------------------------------------------------------------------------------------------------\n",
            "4.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "4.3 M     Total params\n",
            "Epoch 0:  83% 79/95 [01:57<00:23,  1.49s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  85% 81/95 [02:05<00:21,  1.55s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Validating:  12% 2/16 [00:13<01:34,  6.74s/it]\u001b[A\n",
            "Epoch 0:  87% 83/95 [02:17<00:19,  1.66s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Epoch 0:  88% 84/95 [02:23<00:18,  1.71s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Epoch 0:  89% 85/95 [02:30<00:17,  1.77s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Epoch 0:  91% 86/95 [02:36<00:16,  1.82s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Epoch 0:  92% 87/95 [02:42<00:14,  1.87s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Epoch 0:  93% 88/95 [02:48<00:13,  1.92s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Epoch 0:  94% 89/95 [02:54<00:11,  1.97s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Epoch 0:  95% 90/95 [03:01<00:10,  2.01s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Epoch 0:  96% 91/95 [03:07<00:08,  2.06s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Epoch 0:  97% 92/95 [03:13<00:06,  2.10s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Epoch 0:  98% 93/95 [03:19<00:04,  2.15s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Epoch 0:  99% 94/95 [03:26<00:02,  2.19s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Epoch 0: 100% 95/95 [03:32<00:00,  2.23s/it, loss=3.12, v_num=br9f, val_loss=4.82, val_cer=0.999]\n",
            "Epoch 0: 100% 95/95 [03:36<00:00,  2.28s/it, loss=3.12, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1:  83% 79/95 [01:56<00:23,  1.47s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  85% 81/95 [02:03<00:21,  1.53s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Validating:  12% 2/16 [00:13<01:35,  6.79s/it]\u001b[A\n",
            "Epoch 1:  87% 83/95 [02:16<00:19,  1.64s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1:  88% 84/95 [02:22<00:18,  1.70s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1:  89% 85/95 [02:28<00:17,  1.75s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1:  91% 86/95 [02:34<00:16,  1.80s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1:  92% 87/95 [02:41<00:14,  1.85s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1:  93% 88/95 [02:47<00:13,  1.90s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1:  94% 89/95 [02:53<00:11,  1.95s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1:  95% 90/95 [02:59<00:09,  2.00s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1:  96% 91/95 [03:06<00:08,  2.05s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1:  97% 92/95 [03:12<00:06,  2.09s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1:  98% 93/95 [03:18<00:04,  2.14s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1:  99% 94/95 [03:24<00:02,  2.18s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1: 100% 95/95 [03:31<00:00,  2.22s/it, loss=2.55, v_num=br9f, val_loss=3.05, val_cer=0.968]\n",
            "Epoch 1: 100% 95/95 [03:35<00:00,  2.27s/it, loss=2.55, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "                                               \u001b[A/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Trying to log at a previous step. Use `commit=False` when logging metrics manually.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 157 < 165; dropping {'val_loss': 2.4608731269836426, 'val_cer': 0.8253723382949829, 'epoch': 1}.\n",
            "Epoch 2:  83% 79/95 [01:56<00:23,  1.47s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  85% 81/95 [02:03<00:21,  1.53s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Validating:  12% 2/16 [00:13<01:34,  6.76s/it]\u001b[A\n",
            "Epoch 2:  87% 83/95 [02:16<00:19,  1.64s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Epoch 2:  88% 84/95 [02:22<00:18,  1.70s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Epoch 2:  89% 85/95 [02:28<00:17,  1.75s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Epoch 2:  91% 86/95 [02:34<00:16,  1.80s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Epoch 2:  92% 87/95 [02:41<00:14,  1.85s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Epoch 2:  93% 88/95 [02:47<00:13,  1.90s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Epoch 2:  94% 89/95 [02:53<00:11,  1.95s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Epoch 2:  95% 90/95 [02:59<00:09,  2.00s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Epoch 2:  96% 91/95 [03:06<00:08,  2.05s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Epoch 2:  97% 92/95 [03:12<00:06,  2.09s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Epoch 2:  98% 93/95 [03:18<00:04,  2.14s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Epoch 2:  99% 94/95 [03:24<00:02,  2.18s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Epoch 2: 100% 95/95 [03:31<00:00,  2.22s/it, loss=2.39, v_num=br9f, val_loss=2.46, val_cer=0.825]\n",
            "Epoch 2: 100% 95/95 [03:35<00:00,  2.27s/it, loss=2.39, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3:  83% 79/95 [01:56<00:23,  1.47s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3:  85% 81/95 [02:03<00:21,  1.53s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Validating:  12% 2/16 [00:13<01:34,  6.76s/it]\u001b[A\n",
            "Epoch 3:  87% 83/95 [02:16<00:19,  1.64s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3:  88% 84/95 [02:22<00:18,  1.70s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3:  89% 85/95 [02:28<00:17,  1.75s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3:  91% 86/95 [02:34<00:16,  1.80s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3:  92% 87/95 [02:41<00:14,  1.85s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3:  93% 88/95 [02:47<00:13,  1.90s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3:  94% 89/95 [02:53<00:11,  1.95s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3:  95% 90/95 [02:59<00:09,  2.00s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3:  96% 91/95 [03:06<00:08,  2.05s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3:  97% 92/95 [03:12<00:06,  2.09s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3:  98% 93/95 [03:18<00:04,  2.13s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3:  99% 94/95 [03:24<00:02,  2.18s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3: 100% 95/95 [03:31<00:00,  2.22s/it, loss=2.33, v_num=br9f, val_loss=2.33, val_cer=0.822]\n",
            "Epoch 3: 100% 95/95 [03:35<00:00,  2.27s/it, loss=2.33, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4:  83% 79/95 [01:56<00:23,  1.47s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 4:  85% 81/95 [02:03<00:21,  1.53s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Validating:  12% 2/16 [00:13<01:35,  6.79s/it]\u001b[A\n",
            "Epoch 4:  87% 83/95 [02:16<00:19,  1.64s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4:  88% 84/95 [02:22<00:18,  1.70s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4:  89% 85/95 [02:28<00:17,  1.75s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4:  91% 86/95 [02:34<00:16,  1.80s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4:  92% 87/95 [02:41<00:14,  1.85s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4:  93% 88/95 [02:47<00:13,  1.90s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4:  94% 89/95 [02:53<00:11,  1.95s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4:  95% 90/95 [02:59<00:09,  2.00s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4:  96% 91/95 [03:06<00:08,  2.05s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4:  97% 92/95 [03:12<00:06,  2.09s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4:  98% 93/95 [03:18<00:04,  2.14s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4:  99% 94/95 [03:24<00:02,  2.18s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4: 100% 95/95 [03:31<00:00,  2.22s/it, loss=2.27, v_num=br9f, val_loss=2.21, val_cer=0.825]\n",
            "Epoch 4: 100% 95/95 [03:35<00:00,  2.27s/it, loss=2.27, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  83% 79/95 [01:56<00:23,  1.47s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 5:  85% 81/95 [02:04<00:21,  1.53s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  86% 82/95 [02:15<00:21,  1.65s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  87% 83/95 [02:16<00:19,  1.64s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  88% 84/95 [02:22<00:18,  1.70s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  89% 85/95 [02:28<00:17,  1.75s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  91% 86/95 [02:35<00:16,  1.80s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  92% 87/95 [02:41<00:14,  1.86s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  93% 88/95 [02:47<00:13,  1.90s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  94% 89/95 [02:53<00:11,  1.95s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  95% 90/95 [03:00<00:10,  2.00s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  96% 91/95 [03:06<00:08,  2.05s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  97% 92/95 [03:12<00:06,  2.09s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  98% 93/95 [03:18<00:04,  2.14s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5:  99% 94/95 [03:25<00:02,  2.18s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5: 100% 95/95 [03:31<00:00,  2.22s/it, loss=2.23, v_num=br9f, val_loss=2.16, val_cer=0.783]\n",
            "Epoch 5: 100% 95/95 [03:35<00:00,  2.27s/it, loss=2.23, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6:  83% 79/95 [01:56<00:23,  1.47s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 6:  85% 81/95 [02:03<00:21,  1.53s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Validating:  12% 2/16 [00:13<01:34,  6.74s/it]\u001b[A\n",
            "Epoch 6:  87% 83/95 [02:16<00:19,  1.64s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6:  88% 84/95 [02:22<00:18,  1.69s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6:  89% 85/95 [02:28<00:17,  1.75s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6:  91% 86/95 [02:34<00:16,  1.80s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6:  92% 87/95 [02:40<00:14,  1.85s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6:  93% 88/95 [02:46<00:13,  1.90s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6:  94% 89/95 [02:53<00:11,  1.95s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6:  95% 90/95 [02:59<00:09,  1.99s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6:  96% 91/95 [03:05<00:08,  2.04s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6:  97% 92/95 [03:11<00:06,  2.08s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6:  98% 93/95 [03:18<00:04,  2.13s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6:  99% 94/95 [03:24<00:02,  2.17s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6: 100% 95/95 [03:30<00:00,  2.21s/it, loss=2.18, v_num=br9f, val_loss=2.13, val_cer=0.801]\n",
            "Epoch 6: 100% 95/95 [03:34<00:00,  2.26s/it, loss=2.18, v_num=br9f, val_loss=2.1, val_cer=0.79]  \n",
            "                                               \u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 552 < 565; dropping {'val_loss': 2.1047592163085938, 'val_cer': 0.7901256680488586, 'epoch': 6}.\n",
            "Epoch 7:  83% 79/95 [01:56<00:23,  1.47s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 7:  85% 81/95 [02:03<00:21,  1.53s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7:  86% 82/95 [02:14<00:21,  1.64s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7:  87% 83/95 [02:15<00:19,  1.64s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7:  88% 84/95 [02:22<00:18,  1.69s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7:  89% 85/95 [02:28<00:17,  1.75s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7:  91% 86/95 [02:34<00:16,  1.80s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7:  92% 87/95 [02:40<00:14,  1.85s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7:  93% 88/95 [02:46<00:13,  1.90s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7:  94% 89/95 [02:53<00:11,  1.95s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7:  95% 90/95 [02:59<00:09,  1.99s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7:  96% 91/95 [03:05<00:08,  2.04s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7:  97% 92/95 [03:11<00:06,  2.08s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7:  98% 93/95 [03:18<00:04,  2.13s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7:  99% 94/95 [03:24<00:02,  2.17s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7: 100% 95/95 [03:30<00:00,  2.21s/it, loss=2.14, v_num=br9f, val_loss=2.1, val_cer=0.79]\n",
            "Epoch 7: 100% 95/95 [03:34<00:00,  2.26s/it, loss=2.14, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8:  83% 79/95 [01:56<00:23,  1.47s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 8:  85% 81/95 [02:03<00:21,  1.53s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Validating:  12% 2/16 [00:13<01:35,  6.80s/it]\u001b[A\n",
            "Epoch 8:  87% 83/95 [02:16<00:19,  1.64s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8:  88% 84/95 [02:22<00:18,  1.70s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8:  89% 85/95 [02:28<00:17,  1.75s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8:  91% 86/95 [02:34<00:16,  1.80s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8:  92% 87/95 [02:41<00:14,  1.85s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8:  93% 88/95 [02:47<00:13,  1.90s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8:  94% 89/95 [02:53<00:11,  1.95s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8:  95% 90/95 [02:59<00:09,  2.00s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8:  96% 91/95 [03:06<00:08,  2.05s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8:  97% 92/95 [03:12<00:06,  2.09s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8:  98% 93/95 [03:18<00:04,  2.14s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8:  99% 94/95 [03:24<00:02,  2.18s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8: 100% 95/95 [03:31<00:00,  2.22s/it, loss=2.1, v_num=br9f, val_loss=2.02, val_cer=0.794]\n",
            "Epoch 8: 100% 95/95 [03:35<00:00,  2.27s/it, loss=2.1, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "                                               \u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 710 < 715; dropping {'val_loss': 1.985611081123352, 'val_cer': 0.7745815515518188, 'epoch': 8}.\n",
            "Epoch 9:  83% 79/95 [01:56<00:23,  1.47s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 9:  85% 81/95 [02:03<00:21,  1.53s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Validating:  12% 2/16 [00:13<01:35,  6.80s/it]\u001b[A\n",
            "Epoch 9:  87% 83/95 [02:16<00:19,  1.64s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Epoch 9:  88% 84/95 [02:22<00:18,  1.70s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Epoch 9:  89% 85/95 [02:28<00:17,  1.75s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Epoch 9:  91% 86/95 [02:35<00:16,  1.80s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Epoch 9:  92% 87/95 [02:41<00:14,  1.86s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Epoch 9:  93% 88/95 [02:47<00:13,  1.91s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Epoch 9:  94% 89/95 [02:53<00:11,  1.95s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Epoch 9:  95% 90/95 [03:00<00:10,  2.00s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Epoch 9:  96% 91/95 [03:06<00:08,  2.05s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Epoch 9:  97% 92/95 [03:12<00:06,  2.09s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Epoch 9:  98% 93/95 [03:18<00:04,  2.14s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Epoch 9:  99% 94/95 [03:25<00:02,  2.18s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Epoch 9: 100% 95/95 [03:31<00:00,  2.22s/it, loss=2.07, v_num=br9f, val_loss=1.99, val_cer=0.775]\n",
            "Epoch 9: 100% 95/95 [03:35<00:00,  2.27s/it, loss=2.07, v_num=br9f, val_loss=1.97, val_cer=0.774]\n",
            "Epoch 9: 100% 95/95 [03:35<00:00,  2.27s/it, loss=2.07, v_num=br9f, val_loss=1.97, val_cer=0.774]\n",
            "EMNISTLines2 loading data from HDF5...\n",
            "Testing: 100% 16/16 [01:30<00:00,  5.65s/it]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_cer': tensor(0.7702, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n",
            "Best model saved at: training/logs/fsdl-text-recognizer-2021-labs-lab5_training/1akcbr9f/checkpoints/epoch=009-val_loss=1.967-val_cer=0.774.ckpt\n",
            "Best model also uploaded to W&B\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 11732... (success).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch ▁▁▂▂▃▃▃▃▃▄▄▅▅▅▆▆▆▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_cer ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss █▆▄▄▃▃▃▃▂▂▂▁▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_cer █▃▃▁▂▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     val_loss █▃▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch 9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_cer 0.7702\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss 2.04832\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_cer 0.77415\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     val_loss 1.96669\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 178 media file(s), 0 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mserene-silence-1\u001b[0m: \u001b[34mhttps://wandb.ai/amandahydar/fsdl-text-recognizer-2021-labs-lab5_training/runs/1akcbr9f\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20211220_195604-1akcbr9f/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb sweep training/sweeps/emnist_lines1_line_cnn_transformer.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2YzxR8reeCl",
        "outputId": "39e0b328-4932-4f61-b247-37b751d745d0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Creating sweep from: training/sweeps/emnist_lines1_line_cnn_transformer.yml\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Couldn't open sweep file: training/sweeps/emnist_lines1_line_cnn_transformer.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb sweep training/sweeps/emnist_lines2_line_cnn_transformer.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfn0PBtGenhV",
        "outputId": "091dff5d-b462-4147-8d3f-bc19d72f2b82"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Creating sweep from: training/sweeps/emnist_lines2_line_cnn_transformer.yml\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Created sweep with ID: \u001b[33m4l71a1wm\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: View sweep at: \u001b[34m\u001b[4mhttps://wandb.ai/amandahydar/fsdl-text-recognizer-2021-labs-lab5_training/sweeps/4l71a1wm\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run sweep agent with: \u001b[33mwandb agent amandahydar/fsdl-text-recognizer-2021-labs-lab5_training/4l71a1wm\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb agent amandahydar/fsdl-text-recognizer-2021-labs-lab5_training/4l71a1wm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZExeSwVkOHe",
        "outputId": "0f5c3afc-eb9a-4323-e1a6-00ccad7a15a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 🕵️\n",
            "2021-12-20 20:38:24,977 - wandb.wandb_agent - INFO - Running runs: []\n",
            "2021-12-20 20:38:25,122 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2021-12-20 20:38:25,123 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tconv_dim: 64\n",
            "\tdata_class: EMNISTLines2\n",
            "\tfc_dim: 512\n",
            "\tgpus: -1\n",
            "\tloss: transformer\n",
            "\tlr: 0.001\n",
            "\tmodel_class: LineCNNTransformer\n",
            "\tnum_workers: 20\n",
            "\tprecision: 16\n",
            "\ttf_dim: 128\n",
            "\ttf_fc_dim: 256\n",
            "\ttf_layers: 6\n",
            "\ttf_nhead: 8\n",
            "\twindow_stride: 8\n",
            "\twindow_width: 16\n",
            "2021-12-20 20:38:25,128 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python training/run_experiment.py --wandb --conv_dim=64 --data_class=EMNISTLines2 --fc_dim=512 --gpus=-1 --loss=transformer --lr=0.001 --model_class=LineCNNTransformer --num_workers=20 --precision=16 --tf_dim=128 --tf_fc_dim=256 --tf_layers=6 --tf_nhead=8 --window_stride=8 --window_width=16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamandahydar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2021-12-20 20:38:30,140 - wandb.wandb_agent - INFO - Running runs: ['hdcf4trj']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33mbreezy-sweep-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/amandahydar/fsdl-text-recognizer-2021-labs-lab5_training\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/amandahydar/fsdl-text-recognizer-2021-labs-lab5_training/sweeps/4l71a1wm\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/amandahydar/fsdl-text-recognizer-2021-labs-lab5_training/runs/hdcf4trj\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/fsdl-text-recognizer-2021-labs/lab5/wandb/run-20211220_203827-hdcf4trj\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gpus' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'precision' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_class' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'model_class' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'conv_dim' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'fc_dim' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'window_width' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'window_stride' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tf_dim' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tf_fc_dim' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tf_layers' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tf_nhead' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr' was locked by 'sweep' (ignored update).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loss' was locked by 'sweep' (ignored update).\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "EMNISTLines2 loading data from HDF5...\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Using native 16bit precision.\n",
            "\n",
            "    | Name                                                       | Type                    | Params\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "0   | model                                                      | LineCNNTransformer      | 4.6 M \n",
            "1   | model.line_cnn                                             | LineCNN                 | 3.4 M \n",
            "2   | model.line_cnn.convs                                       | Sequential              | 3.1 M \n",
            "3   | model.line_cnn.convs.0                                     | ConvBlock               | 640   \n",
            "4   | model.line_cnn.convs.0.conv                                | Conv2d                  | 640   \n",
            "5   | model.line_cnn.convs.0.relu                                | ReLU                    | 0     \n",
            "6   | model.line_cnn.convs.1                                     | ConvBlock               | 36.9 K\n",
            "7   | model.line_cnn.convs.1.conv                                | Conv2d                  | 36.9 K\n",
            "8   | model.line_cnn.convs.1.relu                                | ReLU                    | 0     \n",
            "9   | model.line_cnn.convs.2                                     | ConvBlock               | 36.9 K\n",
            "10  | model.line_cnn.convs.2.conv                                | Conv2d                  | 36.9 K\n",
            "11  | model.line_cnn.convs.2.relu                                | ReLU                    | 0     \n",
            "12  | model.line_cnn.convs.3                                     | ConvBlock               | 36.9 K\n",
            "13  | model.line_cnn.convs.3.conv                                | Conv2d                  | 36.9 K\n",
            "14  | model.line_cnn.convs.3.relu                                | ReLU                    | 0     \n",
            "15  | model.line_cnn.convs.4                                     | ConvBlock               | 73.9 K\n",
            "16  | model.line_cnn.convs.4.conv                                | Conv2d                  | 73.9 K\n",
            "17  | model.line_cnn.convs.4.relu                                | ReLU                    | 0     \n",
            "18  | model.line_cnn.convs.5                                     | ConvBlock               | 147 K \n",
            "19  | model.line_cnn.convs.5.conv                                | Conv2d                  | 147 K \n",
            "20  | model.line_cnn.convs.5.relu                                | ReLU                    | 0     \n",
            "21  | model.line_cnn.convs.6                                     | ConvBlock               | 295 K \n",
            "22  | model.line_cnn.convs.6.conv                                | Conv2d                  | 295 K \n",
            "23  | model.line_cnn.convs.6.relu                                | ReLU                    | 0     \n",
            "24  | model.line_cnn.convs.7                                     | ConvBlock               | 590 K \n",
            "25  | model.line_cnn.convs.7.conv                                | Conv2d                  | 590 K \n",
            "26  | model.line_cnn.convs.7.relu                                | ReLU                    | 0     \n",
            "27  | model.line_cnn.convs.8                                     | ConvBlock               | 1.8 M \n",
            "28  | model.line_cnn.convs.8.conv                                | Conv2d                  | 1.8 M \n",
            "29  | model.line_cnn.convs.8.relu                                | ReLU                    | 0     \n",
            "30  | model.line_cnn.fc1                                         | Linear                  | 262 K \n",
            "31  | model.line_cnn.dropout                                     | Dropout                 | 0     \n",
            "32  | model.line_cnn.fc2                                         | Linear                  | 65.7 K\n",
            "33  | model.embedding                                            | Embedding               | 10.6 K\n",
            "34  | model.fc                                                   | Linear                  | 10.7 K\n",
            "35  | model.pos_encoder                                          | PositionalEncoding      | 0     \n",
            "36  | model.pos_encoder.dropout                                  | Dropout                 | 0     \n",
            "37  | model.transformer_decoder                                  | TransformerDecoder      | 1.2 M \n",
            "38  | model.transformer_decoder.layers                           | ModuleList              | 1.2 M \n",
            "39  | model.transformer_decoder.layers.0                         | TransformerDecoderLayer | 198 K \n",
            "40  | model.transformer_decoder.layers.0.self_attn               | MultiheadAttention      | 66.0 K\n",
            "41  | model.transformer_decoder.layers.0.self_attn.out_proj      | _LinearWithBias         | 16.5 K\n",
            "42  | model.transformer_decoder.layers.0.multihead_attn          | MultiheadAttention      | 66.0 K\n",
            "43  | model.transformer_decoder.layers.0.multihead_attn.out_proj | _LinearWithBias         | 16.5 K\n",
            "44  | model.transformer_decoder.layers.0.linear1                 | Linear                  | 33.0 K\n",
            "45  | model.transformer_decoder.layers.0.dropout                 | Dropout                 | 0     \n",
            "46  | model.transformer_decoder.layers.0.linear2                 | Linear                  | 32.9 K\n",
            "47  | model.transformer_decoder.layers.0.norm1                   | LayerNorm               | 256   \n",
            "48  | model.transformer_decoder.layers.0.norm2                   | LayerNorm               | 256   \n",
            "49  | model.transformer_decoder.layers.0.norm3                   | LayerNorm               | 256   \n",
            "50  | model.transformer_decoder.layers.0.dropout1                | Dropout                 | 0     \n",
            "51  | model.transformer_decoder.layers.0.dropout2                | Dropout                 | 0     \n",
            "52  | model.transformer_decoder.layers.0.dropout3                | Dropout                 | 0     \n",
            "53  | model.transformer_decoder.layers.1                         | TransformerDecoderLayer | 198 K \n",
            "54  | model.transformer_decoder.layers.1.self_attn               | MultiheadAttention      | 66.0 K\n",
            "55  | model.transformer_decoder.layers.1.self_attn.out_proj      | _LinearWithBias         | 16.5 K\n",
            "56  | model.transformer_decoder.layers.1.multihead_attn          | MultiheadAttention      | 66.0 K\n",
            "57  | model.transformer_decoder.layers.1.multihead_attn.out_proj | _LinearWithBias         | 16.5 K\n",
            "58  | model.transformer_decoder.layers.1.linear1                 | Linear                  | 33.0 K\n",
            "59  | model.transformer_decoder.layers.1.dropout                 | Dropout                 | 0     \n",
            "60  | model.transformer_decoder.layers.1.linear2                 | Linear                  | 32.9 K\n",
            "61  | model.transformer_decoder.layers.1.norm1                   | LayerNorm               | 256   \n",
            "62  | model.transformer_decoder.layers.1.norm2                   | LayerNorm               | 256   \n",
            "63  | model.transformer_decoder.layers.1.norm3                   | LayerNorm               | 256   \n",
            "64  | model.transformer_decoder.layers.1.dropout1                | Dropout                 | 0     \n",
            "65  | model.transformer_decoder.layers.1.dropout2                | Dropout                 | 0     \n",
            "66  | model.transformer_decoder.layers.1.dropout3                | Dropout                 | 0     \n",
            "67  | model.transformer_decoder.layers.2                         | TransformerDecoderLayer | 198 K \n",
            "68  | model.transformer_decoder.layers.2.self_attn               | MultiheadAttention      | 66.0 K\n",
            "69  | model.transformer_decoder.layers.2.self_attn.out_proj      | _LinearWithBias         | 16.5 K\n",
            "70  | model.transformer_decoder.layers.2.multihead_attn          | MultiheadAttention      | 66.0 K\n",
            "71  | model.transformer_decoder.layers.2.multihead_attn.out_proj | _LinearWithBias         | 16.5 K\n",
            "72  | model.transformer_decoder.layers.2.linear1                 | Linear                  | 33.0 K\n",
            "73  | model.transformer_decoder.layers.2.dropout                 | Dropout                 | 0     \n",
            "74  | model.transformer_decoder.layers.2.linear2                 | Linear                  | 32.9 K\n",
            "75  | model.transformer_decoder.layers.2.norm1                   | LayerNorm               | 256   \n",
            "76  | model.transformer_decoder.layers.2.norm2                   | LayerNorm               | 256   \n",
            "77  | model.transformer_decoder.layers.2.norm3                   | LayerNorm               | 256   \n",
            "78  | model.transformer_decoder.layers.2.dropout1                | Dropout                 | 0     \n",
            "79  | model.transformer_decoder.layers.2.dropout2                | Dropout                 | 0     \n",
            "80  | model.transformer_decoder.layers.2.dropout3                | Dropout                 | 0     \n",
            "81  | model.transformer_decoder.layers.3                         | TransformerDecoderLayer | 198 K \n",
            "82  | model.transformer_decoder.layers.3.self_attn               | MultiheadAttention      | 66.0 K\n",
            "83  | model.transformer_decoder.layers.3.self_attn.out_proj      | _LinearWithBias         | 16.5 K\n",
            "84  | model.transformer_decoder.layers.3.multihead_attn          | MultiheadAttention      | 66.0 K\n",
            "85  | model.transformer_decoder.layers.3.multihead_attn.out_proj | _LinearWithBias         | 16.5 K\n",
            "86  | model.transformer_decoder.layers.3.linear1                 | Linear                  | 33.0 K\n",
            "87  | model.transformer_decoder.layers.3.dropout                 | Dropout                 | 0     \n",
            "88  | model.transformer_decoder.layers.3.linear2                 | Linear                  | 32.9 K\n",
            "89  | model.transformer_decoder.layers.3.norm1                   | LayerNorm               | 256   \n",
            "90  | model.transformer_decoder.layers.3.norm2                   | LayerNorm               | 256   \n",
            "91  | model.transformer_decoder.layers.3.norm3                   | LayerNorm               | 256   \n",
            "92  | model.transformer_decoder.layers.3.dropout1                | Dropout                 | 0     \n",
            "93  | model.transformer_decoder.layers.3.dropout2                | Dropout                 | 0     \n",
            "94  | model.transformer_decoder.layers.3.dropout3                | Dropout                 | 0     \n",
            "95  | model.transformer_decoder.layers.4                         | TransformerDecoderLayer | 198 K \n",
            "96  | model.transformer_decoder.layers.4.self_attn               | MultiheadAttention      | 66.0 K\n",
            "97  | model.transformer_decoder.layers.4.self_attn.out_proj      | _LinearWithBias         | 16.5 K\n",
            "98  | model.transformer_decoder.layers.4.multihead_attn          | MultiheadAttention      | 66.0 K\n",
            "99  | model.transformer_decoder.layers.4.multihead_attn.out_proj | _LinearWithBias         | 16.5 K\n",
            "100 | model.transformer_decoder.layers.4.linear1                 | Linear                  | 33.0 K\n",
            "101 | model.transformer_decoder.layers.4.dropout                 | Dropout                 | 0     \n",
            "102 | model.transformer_decoder.layers.4.linear2                 | Linear                  | 32.9 K\n",
            "103 | model.transformer_decoder.layers.4.norm1                   | LayerNorm               | 256   \n",
            "104 | model.transformer_decoder.layers.4.norm2                   | LayerNorm               | 256   \n",
            "105 | model.transformer_decoder.layers.4.norm3                   | LayerNorm               | 256   \n",
            "106 | model.transformer_decoder.layers.4.dropout1                | Dropout                 | 0     \n",
            "107 | model.transformer_decoder.layers.4.dropout2                | Dropout                 | 0     \n",
            "108 | model.transformer_decoder.layers.4.dropout3                | Dropout                 | 0     \n",
            "109 | model.transformer_decoder.layers.5                         | TransformerDecoderLayer | 198 K \n",
            "110 | model.transformer_decoder.layers.5.self_attn               | MultiheadAttention      | 66.0 K\n",
            "111 | model.transformer_decoder.layers.5.self_attn.out_proj      | _LinearWithBias         | 16.5 K\n",
            "112 | model.transformer_decoder.layers.5.multihead_attn          | MultiheadAttention      | 66.0 K\n",
            "113 | model.transformer_decoder.layers.5.multihead_attn.out_proj | _LinearWithBias         | 16.5 K\n",
            "114 | model.transformer_decoder.layers.5.linear1                 | Linear                  | 33.0 K\n",
            "115 | model.transformer_decoder.layers.5.dropout                 | Dropout                 | 0     \n",
            "116 | model.transformer_decoder.layers.5.linear2                 | Linear                  | 32.9 K\n",
            "117 | model.transformer_decoder.layers.5.norm1                   | LayerNorm               | 256   \n",
            "118 | model.transformer_decoder.layers.5.norm2                   | LayerNorm               | 256   \n",
            "119 | model.transformer_decoder.layers.5.norm3                   | LayerNorm               | 256   \n",
            "120 | model.transformer_decoder.layers.5.dropout1                | Dropout                 | 0     \n",
            "121 | model.transformer_decoder.layers.5.dropout2                | Dropout                 | 0     \n",
            "122 | model.transformer_decoder.layers.5.dropout3                | Dropout                 | 0     \n",
            "123 | train_acc                                                  | Accuracy                | 0     \n",
            "124 | val_acc                                                    | Accuracy                | 0     \n",
            "125 | test_acc                                                   | Accuracy                | 0     \n",
            "126 | loss_fn                                                    | CrossEntropyLoss        | 0     \n",
            "127 | val_cer                                                    | CharacterErrorRate      | 0     \n",
            "128 | test_cer                                                   | CharacterErrorRate      | 0     \n",
            "---------------------------------------------------------------------------------------------------------\n",
            "4.6 M     Trainable params\n",
            "0         Non-trainable params\n",
            "4.6 M     Total params\n",
            "Epoch 0:  83% 79/95 [07:35<01:32,  5.77s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  85% 81/95 [08:42<01:30,  6.45s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0:  86% 82/95 [09:45<01:32,  7.14s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0:  87% 83/95 [10:48<01:33,  7.82s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0:  88% 84/95 [11:52<01:33,  8.48s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0:  89% 85/95 [12:54<01:31,  9.11s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0:  91% 86/95 [13:58<01:27,  9.75s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0:  92% 87/95 [15:00<01:22, 10.36s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0:  93% 88/95 [16:04<01:16, 10.96s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0:  94% 89/95 [17:07<01:09, 11.54s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0:  95% 90/95 [18:10<01:00, 12.12s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0:  96% 91/95 [19:13<00:50, 12.67s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0:  97% 92/95 [20:16<00:39, 13.22s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0:  98% 93/95 [21:19<00:27, 13.76s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0:  99% 94/95 [22:22<00:14, 14.28s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0: 100% 95/95 [23:25<00:00, 14.79s/it, loss=3.1, v_num=4trj, val_loss=4.65, val_cer=1]\n",
            "Epoch 0: 100% 95/95 [24:06<00:00, 15.22s/it, loss=3.1, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  83% 79/95 [07:33<01:31,  5.74s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  85% 81/95 [08:40<01:30,  6.43s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  86% 82/95 [09:43<01:32,  7.12s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  87% 83/95 [10:47<01:33,  7.80s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  88% 84/95 [11:49<01:32,  8.45s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  89% 85/95 [12:53<01:30,  9.10s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  91% 86/95 [13:56<01:27,  9.72s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  92% 87/95 [14:59<01:22, 10.34s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  93% 88/95 [16:02<01:16, 10.93s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  94% 89/95 [17:05<01:09, 11.52s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  95% 90/95 [18:08<01:00, 12.09s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  96% 91/95 [19:11<00:50, 12.65s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  97% 92/95 [20:14<00:39, 13.20s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  98% 93/95 [21:17<00:27, 13.74s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1:  99% 94/95 [22:20<00:14, 14.26s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1: 100% 95/95 [23:23<00:00, 14.78s/it, loss=2.64, v_num=4trj, val_loss=3.07, val_cer=0.968]\n",
            "Epoch 1: 100% 95/95 [24:04<00:00, 15.21s/it, loss=2.64, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "                                               \u001b[A/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Trying to log at a previous step. Use `commit=False` when logging metrics manually.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 157 < 165; dropping {'val_loss': 2.559239387512207, 'val_cer': 0.9149908423423767, 'epoch': 1}.\n",
            "Epoch 2:  83% 79/95 [07:32<01:31,  5.73s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  85% 81/95 [08:39<01:29,  6.41s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2:  86% 82/95 [09:42<01:32,  7.11s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2:  87% 83/95 [10:45<01:33,  7.78s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2:  88% 84/95 [11:48<01:32,  8.44s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2:  89% 85/95 [12:51<01:30,  9.08s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2:  91% 86/95 [13:55<01:27,  9.71s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2:  92% 87/95 [14:57<01:22, 10.32s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2:  93% 88/95 [16:01<01:16, 10.92s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2:  94% 89/95 [17:04<01:09, 11.51s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2:  95% 90/95 [18:07<01:00, 12.08s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2:  96% 91/95 [19:10<00:50, 12.64s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2:  97% 92/95 [20:13<00:39, 13.19s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2:  98% 93/95 [21:16<00:27, 13.72s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2:  99% 94/95 [22:19<00:14, 14.25s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2: 100% 95/95 [23:22<00:00, 14.76s/it, loss=2.47, v_num=4trj, val_loss=2.56, val_cer=0.915]\n",
            "Epoch 2: 100% 95/95 [24:03<00:00, 15.19s/it, loss=2.47, v_num=4trj, val_loss=2.38, val_cer=0.825]\n",
            "Epoch 3:  27% 26/95 [02:36<06:54,  6.00s/it, loss=2.43, v_num=4trj, val_loss=2.38, val_cer=0.825]"
          ]
        }
      ]
    }
  ]
}